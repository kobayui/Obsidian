
# ç¬¬ä¸€ç§

## 1.é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®ç›®æ ‡

åŸºäºç°æœ‰DCSï¼ˆåˆ†å¸ƒå¼æ§åˆ¶ç³»ç»Ÿï¼‰å¼€å‘ä¸€ä¸ªæ™ºèƒ½è¿è¡ŒAgentï¼Œå®ç°ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

- **æ“ä½œç›‘æ§ä¸æŒ‡å¯¼**ï¼šå®æ—¶ç›‘æ§æ“ä½œå‘˜è¡Œä¸ºï¼Œæä¾›æ™ºèƒ½æ“ä½œå»ºè®®
- **æ•°æ®ç›‘æµ‹ä¸åˆ†æ**ï¼šé‡‡é›†ã€å­˜å‚¨ã€åˆ†æå·¥ä¸šè¿‡ç¨‹æ•°æ®
- **è¯Šæ–­ä¸å»ºè®®**ï¼šæ•…éšœè¯Šæ–­ã€å¼‚å¸¸æ£€æµ‹ã€ä¼˜åŒ–å»ºè®®

### 1.2 ç³»ç»Ÿæ¶æ„æ€»è§ˆ

~~~
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ç”¨æˆ·äº¤äº’å±‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Webæ§åˆ¶å°   â”‚  â”‚  ç§»åŠ¨ç«¯APP  â”‚  â”‚  å‘Šè­¦ç»ˆç«¯   â”‚  â”‚  æŠ¥è¡¨ç³»ç»Ÿ   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          AgentæœåŠ¡å±‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   æ“ä½œæŒ‡å¯¼Agent   â”‚  â”‚   æ•°æ®åˆ†æAgent   â”‚  â”‚   è¯Šæ–­å»ºè®®Agent   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                              â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                    Agentç¼–æ’å¼•æ“                               â”‚      â”‚
â”‚  â”‚  (LangChain/LangGraph + RAG + çŸ¥è¯†åº“ + å·¥å…·è°ƒç”¨)              â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          æ•°æ®å¤„ç†å±‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  å®æ—¶æµå¤„ç†  â”‚  â”‚  æ—¶åºæ•°æ®åº“  â”‚  â”‚  ç‰¹å¾å·¥ç¨‹   â”‚  â”‚  æ¨¡å‹æ¨ç†   â”‚    â”‚
â”‚  â”‚  (Flink)    â”‚  â”‚  (TimescaleDB)â”‚ â”‚  (Spark)   â”‚  â”‚  (MLflow)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          æ•°æ®é‡‡é›†å±‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  OPC UAç½‘å…³ â”‚  â”‚  Modbusç½‘å…³ â”‚  â”‚  MQTT Brokerâ”‚  â”‚  è¾¹ç¼˜è®¡ç®—   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           DCSæ§åˆ¶å±‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  æ§åˆ¶å™¨     â”‚  â”‚  I/Oæ¨¡å—    â”‚  â”‚  ç°åœºä»ªè¡¨   â”‚  â”‚  æ‰§è¡Œæœºæ„   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
~~~

## 2.è¯¦ç»†æŠ€æœ¯æ–¹æ¡ˆ

### 2.1 æ•°æ®é‡‡é›†å±‚

#### 2.1.1 OPC UAæ•°æ®é‡‡é›†

#### 2.1.2 å®æ—¶æµå¤„ç†

### 2.2 AgentæœåŠ¡å±‚

#### 2.2.1 Agentæ ¸å¿ƒæ¶æ„

#### 2.2.2 å¤šAgentç¼–æ’

#### 2.2.3 çŸ¥è¯†åº“ä¸RAG

### 2.3 APIæœåŠ¡å±‚

### 2.4 å‰ç«¯ç•Œé¢

## 3. æŠ€æœ¯è·¯çº¿å›¾

### 3.1 é¡¹ç›®é˜¶æ®µè®¡åˆ’

~~~
é˜¶æ®µ1: åŸºç¡€è®¾æ–½æ­å»º (ç¬¬1-2æœˆ)
â”œâ”€â”€ ç¯å¢ƒæ­å»ºä¸åŸºç¡€æ¶æ„éƒ¨ç½²
â”œâ”€â”€ DCSæ•°æ®é‡‡é›†æ¥å£å¼€å‘
â”œâ”€â”€ æ—¶åºæ•°æ®åº“éƒ¨ç½²é…ç½®
â””â”€â”€ åŸºç¡€APIæ¡†æ¶æ­å»º

é˜¶æ®µ2: æ•°æ®å±‚å»ºè®¾ (ç¬¬2-4æœˆ)
â”œâ”€â”€ OPC UA/Modbusæ•°æ®é‡‡é›†
â”œâ”€â”€ å®æ—¶æµå¤„ç†ç®¡é“(Flink)
â”œâ”€â”€ å†å²æ•°æ®å­˜å‚¨ä¸æŸ¥è¯¢
â””â”€â”€ æ•°æ®è´¨é‡ç›‘æ§

é˜¶æ®µ3: Agentæ ¸å¿ƒå¼€å‘ (ç¬¬4-7æœˆ)
â”œâ”€â”€ LLMæ¥å…¥ä¸è°ƒä¼˜
â”œâ”€â”€ æ“ä½œæŒ‡å¯¼Agentå¼€å‘
â”œâ”€â”€ æ•°æ®åˆ†æAgentå¼€å‘
â”œâ”€â”€ è¯Šæ–­å»ºè®®Agentå¼€å‘
â””â”€â”€ å¤šAgentç¼–æ’ç³»ç»Ÿ

é˜¶æ®µ4: çŸ¥è¯†åº“å»ºè®¾ (ç¬¬5-8æœˆ)
â”œâ”€â”€ æ“ä½œæ‰‹å†Œæ•°å­—åŒ–
â”œâ”€â”€ æ•…éšœæ¡ˆä¾‹åº“æ„å»º
â”œâ”€â”€ RAGæ£€ç´¢ç³»ç»Ÿå¼€å‘
â””â”€â”€ çŸ¥è¯†å›¾è°±æ„å»º(å¯é€‰)

é˜¶æ®µ5: é›†æˆä¸æµ‹è¯• (ç¬¬8-10æœˆ)
â”œâ”€â”€ ç³»ç»Ÿé›†æˆæµ‹è¯•
â”œâ”€â”€ æ€§èƒ½ä¼˜åŒ–
â”œâ”€â”€ å®‰å…¨åŠ å›º
â””â”€â”€ ç”¨æˆ·éªŒæ”¶æµ‹è¯•

é˜¶æ®µ6: ä¸Šçº¿ä¸è¿ç»´ (ç¬¬10-12æœˆ)
â”œâ”€â”€ è¯•è¿è¡Œ
â”œâ”€â”€ é—®é¢˜ä¿®å¤
â”œâ”€â”€ æŒç»­ä¼˜åŒ–
â””â”€â”€ è¿ç»´åŸ¹è®­
~~~

### 3.2 æŠ€æœ¯é€‰å‹å¯¹æ¯”

| ç»„ä»¶          | æ¨èæ–¹æ¡ˆ                  | å¤‡é€‰æ–¹æ¡ˆ              | é€‰æ‹©ç†ç”±         |
| ----------- | --------------------- | ----------------- | ------------ |
| **LLM**     | GPT-4/Claude          | æ–‡å¿ƒä¸€è¨€/é€šä¹‰åƒé—®         | ç»¼åˆèƒ½åŠ›å¼ºï¼Œæ”¯æŒå·¥å…·è°ƒç”¨ |
| **Agentæ¡†æ¶** | LangChain + LangGraph | AutoGen/CrewAI    | ç”Ÿæ€æˆç†Ÿï¼Œæ–‡æ¡£å®Œå–„    |
| **å‘é‡æ•°æ®åº“**   | Milvus                | Pinecone/Weaviate | å¼€æºå¯æ§ï¼Œæ€§èƒ½ä¼˜ç§€    |
| **æ—¶åºæ•°æ®åº“**   | TimescaleDB           | InfluxDB/TDengine | SQLå…¼å®¹ï¼Œæ‰©å±•æ€§å¥½   |
| **æµå¤„ç†**     | Apache Flink          | Kafka Streams     | çŠ¶æ€ç®¡ç†å¼ºï¼Œé€‚åˆå¤æ‚è®¡ç®— |
| **æ¶ˆæ¯é˜Ÿåˆ—**    | Apache Kafka          | RabbitMQ          | é«˜ååï¼Œé€‚åˆå·¥ä¸šæ•°æ®   |
| **åç«¯æ¡†æ¶**    | FastAPI               | Flask/Django      | å¼‚æ­¥æ”¯æŒå¥½ï¼Œæ€§èƒ½é«˜    |
| **å‰ç«¯æ¡†æ¶**    | React + TypeScript    | Vue.js            | ç»„ä»¶ç”Ÿæ€ä¸°å¯Œ       |
| **éƒ¨ç½²æ–¹å¼**    | Kubernetes            | Docker Compose    | ç”Ÿäº§çº§ç¼–æ’èƒ½åŠ›      |
## 4.é¢„ç®—

## 5.é£é™©ä¸å¯¹ç­–

| é£é™©ç±»åˆ«     | å…·ä½“é£é™©        | å½±å“ç¨‹åº¦ | åº”å¯¹ç­–ç•¥             |
| -------- | ----------- | ---- | ---------------- |
| **æŠ€æœ¯é£é™©** | LLMå¹»è§‰å¯¼è‡´é”™è¯¯å»ºè®® | é«˜    | å¢åŠ äººå·¥å®¡æ ¸ç¯èŠ‚ï¼Œå…³é”®æ“ä½œéœ€ç¡®è®¤ |
| **æŠ€æœ¯é£é™©** | DCSæ¥å£å…¼å®¹æ€§é—®é¢˜  | ä¸­    | æå‰åšæ¥å£è°ƒç ”ï¼Œå‡†å¤‡å¤šç§é€‚é…æ–¹æ¡ˆ |
| **å®‰å…¨é£é™©** | å·¥æ§ç½‘ç»œå®‰å…¨å¨èƒ    | é«˜    | ç½‘ç»œéš”ç¦»ã€åŠ å¯†ä¼ è¾“ã€å®‰å…¨å®¡è®¡   |
| **æ•°æ®é£é™©** | å†å²æ•°æ®è´¨é‡å·®     | ä¸­    | æ•°æ®æ¸…æ´—ã€è´¨é‡ç›‘æ§ã€å¼‚å¸¸å¤„ç†   |
| **è¿›åº¦é£é™©** | éœ€æ±‚å˜æ›´é¢‘ç¹      | ä¸­    | æ•æ·å¼€å‘ã€é˜¶æ®µäº¤ä»˜ã€æŒç»­æ²Ÿé€š   |
| **äººå‘˜é£é™©** | å…³é”®äººå‘˜æµå¤±      | ä¸­    | çŸ¥è¯†æ–‡æ¡£åŒ–ã€äº¤å‰åŸ¹è®­ã€æ¿€åŠ±æœºåˆ¶  |
## 6. é¢„æœŸæ”¶ç›Š

### 6.1 é‡åŒ–æ”¶ç›Š

|æ”¶ç›Šé¡¹|é¢„æœŸæå‡|å¹´åŒ–ä»·å€¼(ä¸‡å…ƒ)|
|---|---|---|
|å‡å°‘éè®¡åˆ’åœè½¦|30%+|200-500|
|æå‡è¿è¡Œæ•ˆç‡|5-10%|100-300|
|é™ä½èƒ½è€—|3-5%|50-150|
|å‡å°‘æ“ä½œå¤±è¯¯|50%+|100-200|
|ç¼©çŸ­æ•…éšœè¯Šæ–­æ—¶é—´|60%+|50-100|
|**å¹´åŒ–æ€»æ”¶ç›Š**||**500-1250**|
### 6.2 æŠ•èµ„å›æŠ¥åˆ†æ

- **æ€»æŠ•èµ„**: çº¦957ä¸‡å…ƒ
- **é¢„æœŸå¹´æ”¶ç›Š**: 500-1250ä¸‡å…ƒ
- **æŠ•èµ„å›æ”¶æœŸ**: 1-2å¹´
- **5å¹´ROI**: 160%-550%

# ç¬¬äºŒç§ï¼šæœ¬åœ°éƒ¨ç½²

## 1.æœ¬åœ°åŒ–æŠ€æœ¯æ¶æ„è°ƒæ•´

### 1.1 LLMæœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆ

~~~
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         æœ¬åœ°LLMæ¨ç†æœåŠ¡                                   â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Qwen2-72B     â”‚  â”‚   Llama3-70B    â”‚  â”‚   GLM-4-9B      â”‚         â”‚
â”‚  â”‚   (æ¨èä¸»åŠ›)     â”‚  â”‚   (å¤‡é€‰)        â”‚  â”‚   (è½»é‡å¤‡é€‰)    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                              â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚              æ¨ç†å¼•æ“: vLLM / Ollama / TGI                    â”‚      â”‚
â”‚  â”‚         (æ”¯æŒå¤šGPUå¹¶è¡Œã€åŠ¨æ€æ‰¹å¤„ç†ã€KV Cacheä¼˜åŒ–)              â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                              â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚              æœ¬åœ°Embeddingæ¨¡å‹: bge-large-zh-v1.5             â”‚      â”‚
â”‚  â”‚                    (å‘é‡æ£€ç´¢ã€è¯­ä¹‰æœç´¢)                        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
~~~

### 1.2 æ¨èæœ¬åœ°æ¨¡å‹é…ç½®
| ç”¨é€”              | æ¨èæ¨¡å‹                 | æ˜¾å­˜éœ€æ±‚   | éƒ¨ç½²æ–¹å¼               |
| --------------- | -------------------- | ------ | ------------------ |
| **ä¸»åŠ›å¯¹è¯æ¨¡å‹**      | Qwen2-72B-Instruct   | 80GBÃ—2 | vLLMå¤šå¡éƒ¨ç½²           |
| **å·¥å…·è°ƒç”¨æ¨¡å‹**      | Qwen2-72B / GLM-4-9B | åŒä¸Š     | Function Callingæ”¯æŒ |
| **è½»é‡å¤‡ç”¨æ¨¡å‹**      | Qwen2-7B-Instruct    | 16GB   | å•å¡éƒ¨ç½²               |
| **Embeddingæ¨¡å‹** | bge-large-zh-v1. 5   | 2GB    | CPUå¯è¿è¡Œ             |
| **Rerankæ¨¡å‹**    | bge-reranker-large   | 2GB    | RAGæ£€ç´¢é‡æ’            |
## 2.è°ƒæ•´åçš„é¢„ç®—ç»Ÿè®¡

### 2.1 ç¡¬ä»¶æŠ•å…¥ï¼ˆæœ¬åœ°éƒ¨ç½²æ ¸å¿ƒï¼‰
|é¡¹ç›®|è§„æ ¼è¯´æ˜|æ•°é‡|å•ä»·(ä¸‡å…ƒ)|å°è®¡(ä¸‡å…ƒ)|
|---|---|---|---|---|
|**GPUæ¨ç†æœåŠ¡å™¨**|||||
|â”” æ–¹æ¡ˆA(æ¨è)|åŒè·¯CPU + 4Ã—A100 80G + 512Gå†…å­˜ + 4TB NVMe|1å°|85|85|
|â”” æ–¹æ¡ˆB(ç»æµ)|åŒè·¯CPU + 2Ã—A100 80G + 256Gå†…å­˜ + 2TB NVMe|1å°|55|55|
|â”” æ–¹æ¡ˆC(å…¥é—¨)|å•è·¯CPU + 2Ã—RTX 4090 24G + 128Gå†…å­˜ + 1TB|1å°|12|12|
|**åº”ç”¨æœåŠ¡å™¨**|32æ ¸64Gå†…å­˜/1TB SSD (AgentæœåŠ¡)|2å°|6|12|
|**æ•°æ®åº“æœåŠ¡å™¨**|32æ ¸128G/4TB NVMe (æ—¶åºDB+å‘é‡DB)|1å°|12|12|
|**è¾¹ç¼˜è®¡ç®—ç½‘å…³**|å·¥ä¸šçº§ARMç½‘å…³ (æ•°æ®é‡‡é›†)|3å°|1. 2|3. 6|
|**ç½‘ç»œè®¾å¤‡**|å·¥ä¸šäº¤æ¢æœº+é˜²ç«å¢™|1å¥—|4|4|
|**å­˜å‚¨è®¾å¤‡**|NAS 50TB (æ•°æ®å¤‡ä»½)|1å°|5|5|
|**UPSç”µæº**|åœ¨çº¿å¼UPS 10KVA|1å°|2|2|
ç¡¬ä»¶æ–¹æ¡ˆé€‰æ‹©å»ºè®®ï¼š

|æ–¹æ¡ˆ|GPUé…ç½®|å¯è¿è¡Œæ¨¡å‹|æ¨ç†æ€§èƒ½|ç¡¬ä»¶æ€»æˆæœ¬|
|---|---|---|---|---|
|**A-é«˜é…**|4Ã—A100 80G|Qwen2-72Bå…¨ç²¾åº¦|ä¼˜ç§€|**123. 6ä¸‡**|
|**B-ä¸­é…**|2Ã—A100 80G|Qwen2-72B (AWQé‡åŒ–)|è‰¯å¥½|**93.6ä¸‡**|
|**C-å…¥é—¨**|2Ã—RTX 4090|Qwen2-7B / GLM-4-9B|å¯ç”¨|**50.6ä¸‡**|

> ğŸ’¡Â **å»ºè®®**ï¼šæµ‹è¯•é˜¶æ®µå¯é€‰æ–¹æ¡ˆCï¼ŒéªŒè¯å¯è¡Œæ€§åå‡çº§åˆ°æ–¹æ¡ˆBæˆ–A

### 2.2 è½¯ä»¶è´¹ç”¨ï¼ˆå…¨å¼€æºæ–¹æ¡ˆï¼‰
|é¡¹ç›®|è¯´æ˜|è´¹ç”¨(ä¸‡å…ƒ)|
|---|---|---|
|**å¼€æºLLM**|Qwen2/Llama3/GLM-4|0 (å…è´¹)|
|**æ¨ç†å¼•æ“**|vLLM/Ollama/TGI|0 (å¼€æº)|
|**å‘é‡æ•°æ®åº“**|ChromaDB/Milvus Lite|0 (å¼€æº)|
|**æ—¶åºæ•°æ®åº“**|TimescaleDBç¤¾åŒºç‰ˆ|0 (å¼€æº)|
|**æµå¤„ç†å¼•æ“**|Apache Flink|0 (å¼€æº)|
|**æ¶ˆæ¯é˜Ÿåˆ—**|Apache Kafka|0 (å¼€æº)|
|**ç›‘æ§å·¥å…·**|Prometheus + Grafana|0 (å¼€æº)|
|**OPC UAåº“**|python-opcua/asyncua|0 (å¼€æº)|
|**å¼€å‘å·¥å…·**|VS Code/PyCharmç¤¾åŒºç‰ˆ|0 (å…è´¹)|
||**è½¯ä»¶å°è®¡**|**0**|#
### 2.3 äººåŠ›æŠ•å…¥
|è§’è‰²|äººæ•°|æœˆè–ª(ä¸‡å…ƒ)|å‘¨æœŸ(æœˆ)|å°è®¡(ä¸‡å…ƒ)|
|---|---|---|---|---|
|**é¡¹ç›®ç»ç†**|1|3. 5|10|35|
|**AI/MLå·¥ç¨‹å¸ˆ**|2|4|10|80|
|**åç«¯å¼€å‘å·¥ç¨‹å¸ˆ**|2|3|10|60|
|**å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ**|1|2. 5|8|20|
|**DCS/å·¥æ§å·¥ç¨‹å¸ˆ**|1|3. 5|8|28|
|**æµ‹è¯•å·¥ç¨‹å¸ˆ**|1|2. 5|6|15|
||||**äººåŠ›å°è®¡**|**238**|#
### 2.4 å…¶ä»–è´¹ç”¨
|é¡¹ç›®|è¯´æ˜|è´¹ç”¨(ä¸‡å…ƒ)|
|---|---|---|
|**æ¨¡å‹ä¸‹è½½/ä¼ è¾“**|å¤§æ¨¡å‹æ–‡ä»¶æ‹·è´ï¼ˆç¦»çº¿ä»‹è´¨ï¼‰|0.5|
|**åŸ¹è®­è´¹ç”¨**|å†…éƒ¨æŠ€æœ¯åŸ¹è®­|3|
|**çŸ¥è¯†åº“å»ºè®¾**|æ–‡æ¡£æ•´ç†ã€æ•°æ®æ ‡æ³¨|10|
|**æµ‹è¯•ç¯å¢ƒ**|å°è§„æ¨¡ä»¿çœŸç³»ç»Ÿ|8|
|**ä¸å¯é¢„è§è´¹**|10%é¢„ç•™|31|
||**å…¶ä»–å°è®¡**|**52. 5**|
## 3.é¢„ç®—æ±‡æ€»å¯¹æ¯”

### 3.1 ä¸‰ç§ç¡¬ä»¶æ–¹æ¡ˆå¯¹æ¯”
|é¢„ç®—é¡¹ç›®|æ–¹æ¡ˆA(é«˜é…)|æ–¹æ¡ˆB(ä¸­é…)|æ–¹æ¡ˆC(å…¥é—¨æµ‹è¯•)|
|---|---|---|---|
|GPUæ¨ç†æœåŠ¡å™¨|85|55|12|
|åº”ç”¨æœåŠ¡å™¨|12|12|12|
|æ•°æ®åº“æœåŠ¡å™¨|12|12|12|
|è¾¹ç¼˜ç½‘å…³|3.6|3.6|3.6|
|ç½‘ç»œ+å­˜å‚¨+UPS|11|11|11|
|**ç¡¬ä»¶å°è®¡**|**123.6**|**93.6**|**50.6**|
|è½¯ä»¶è´¹ç”¨|0|0|0|
|äººåŠ›æŠ•å…¥|238|238|238|
|å…¶ä»–è´¹ç”¨|52.5|52.5|52.5|
|**æ€»é¢„ç®—**|**414.1ä¸‡**|**384.1ä¸‡**|**341.1ä¸‡**|
### 3.2 ä¸åŸæ–¹æ¡ˆå¯¹æ¯”
|å¯¹æ¯”é¡¹|åŸæ–¹æ¡ˆ(äº‘API)|æœ¬åœ°æ–¹æ¡ˆC|æœ¬åœ°æ–¹æ¡ˆB|æœ¬åœ°æ–¹æ¡ˆA|
|---|---|---|---|---|
|æ€»é¢„ç®—|956.5ä¸‡|341.1ä¸‡|384.1ä¸‡|414.1ä¸‡|
|**èŠ‚çœé‡‘é¢**|-|**615.4ä¸‡**|**572.4ä¸‡**|**542.4ä¸‡**|
|**èŠ‚çœæ¯”ä¾‹**|-|**64%**|**60%**|**57%**|
|LLMèƒ½åŠ›|GPT-4çº§åˆ«|ä¸­ç­‰|è‰¯å¥½|ä¼˜ç§€|
|ç½‘ç»œä¾èµ–|éœ€è¦|æ— |æ— |æ— |
|æ•°æ®å®‰å…¨|ä¸€èˆ¬|é«˜|é«˜|é«˜|
|é•¿æœŸæˆæœ¬|APIæŒç»­ä»˜è´¹|æ— é¢å¤–è´¹ç”¨|æ— é¢å¤–è´¹ç”¨|æ— é¢å¤–è´¹ç”¨|
### 3.3 æ¨èæ–¹æ¡ˆ

~~~
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ’¡ æ¨èï¼šåˆ†é˜¶æ®µå®æ–½ç­–ç•¥                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ç¬¬ä¸€é˜¶æ®µ - æ¦‚å¿µéªŒè¯ (1-3æœˆ)                                     â”‚
â”‚  â”œâ”€â”€ é‡‡ç”¨æ–¹æ¡ˆCå…¥é—¨é…ç½®: 50. 6ä¸‡ç¡¬ä»¶                               â”‚
â”‚  â”œâ”€â”€ éªŒè¯æŠ€æœ¯å¯è¡Œæ€§å’Œä¸šåŠ¡ä»·å€¼                                    â”‚
â”‚  â””â”€â”€ é¢„ç®—: çº¦ 180ä¸‡ (å«3ä¸ªæœˆäººåŠ›+å…¶ä»–)                           â”‚
â”‚                                                                 â”‚
â”‚  ç¬¬äºŒé˜¶æ®µ - æ­£å¼éƒ¨ç½² (4-10æœˆ)                                    â”‚
â”‚  â”œâ”€â”€ æ ¹æ®éªŒè¯ç»“æœå‡çº§åˆ°æ–¹æ¡ˆBæˆ–A                                  â”‚
â”‚  â”œâ”€â”€ å®Œæ•´åŠŸèƒ½å¼€å‘å’Œç³»ç»Ÿé›†æˆ                                      â”‚
â”‚  â””â”€â”€ è¿½åŠ é¢„ç®—: 160-230ä¸‡                                        â”‚
â”‚                                                                 â”‚
â”‚  æ€»é¢„ç®—æ§åˆ¶: 340-410ä¸‡                                          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
~~~

## 4.æœ¬åœ°éƒ¨ç½²è¯¦ç»†é…ç½®

### 4.1 æœåŠ¡å™¨è¯¦ç»†é…ç½®æ¸…å•

#### GPUæ¨ç†æœåŠ¡å™¨ï¼ˆæ–¹æ¡ˆBæ¨èé…ç½®ï¼‰
|ç»„ä»¶|è§„æ ¼|å‚è€ƒä»·æ ¼|
|---|---|---|
|CPU|Intel Xeon Gold 6448Y Ã—2 (32æ ¸Ã—2)|8ä¸‡|
|å†…å­˜|DDR5 ECC 256GB (32GBÃ—8)|4ä¸‡|
|GPU|NVIDIA A100 80GB PCIe Ã—2|36ä¸‡|
|ç³»ç»Ÿç›˜|NVMe SSD 1TB Ã—2 (RAID1)|0.6ä¸‡|
|æ•°æ®ç›˜|NVMe SSD 2TB Ã—2|1.2ä¸‡|
|æœºç®±ç”µæº|4UæœåŠ¡å™¨æœºç®± + 2000Wå†—ä½™ç”µæº|1. 5ä¸‡|
|ç½‘å¡|ä¸‡å…†ç½‘å¡|0.3ä¸‡|
|**åˆè®¡**||**çº¦55ä¸‡**Â (å«ç¨)|
#### å…¥é—¨æµ‹è¯•æ–¹æ¡ˆï¼ˆæ–¹æ¡ˆCé…ç½®ï¼‰
|ç»„ä»¶|è§„æ ¼|å‚è€ƒä»·æ ¼|
|---|---|---|
|CPU|AMD EPYC 7313 (16æ ¸)|1.5ä¸‡|
|å†…å­˜|DDR4 ECC 128GB|1. 2ä¸‡|
|GPU|NVIDIA RTX 4090 24GB Ã—2|3.6ä¸‡|
|å­˜å‚¨|NVMe SSD 2TB|0.8ä¸‡|
|æœºç®±ç”µæº|å·¥ä½œç«™æœºç®± + 1600Wç”µæº|0.6ä¸‡|
|æ•£çƒ­|æ°´å†·æ•£çƒ­ç³»ç»Ÿ|0.3ä¸‡|
|**åˆè®¡**||**çº¦12ä¸‡**Â (å«ç¨æ•´æœº)|
### 4.2 æœ¬åœ°æ¨¡å‹æ€§èƒ½å¯¹æ¯”
|æ¨¡å‹|å‚æ•°é‡|æ˜¾å­˜éœ€æ±‚|æ–¹æ¡ˆCå¯ç”¨|æ–¹æ¡ˆBå¯ç”¨|æ¨ç†é€Ÿåº¦|
|---|---|---|---|---|---|
|Qwen2-72B|72B|150GB (FP16)|âŒ|âœ… (AWQ)|15 tok/s|
|Qwen2-72B-AWQ|72B|40GB|âŒ|âœ…|25 tok/s|
|Qwen2-7B|7B|16GB|âœ…|âœ…|80 tok/s|
|GLM-4-9B|9B|20GB|âœ…|âœ…|60 tok/s|
|Llama3-70B|70B|140GB|âŒ|âœ… (é‡åŒ–)|18 tok/s|
|Llama3-8B|8B|18GB|âœ…|âœ…|70 tok/s|5
## 5.æœ€ç»ˆé¢„ç®—æ¨è

### æ¨èæ–¹æ¡ˆï¼šä¸­é…æœ¬åœ°éƒ¨ç½²ï¼ˆæ–¹æ¡ˆBï¼‰
|ç±»åˆ«|æ˜ç»†|é‡‘é¢(ä¸‡å…ƒ)|
|---|---|---|
|**ç¡¬ä»¶æŠ•å…¥**||**93.6**|
|â”‚|GPUæ¨ç†æœåŠ¡å™¨ (2Ã—A100 80G)|55|
|â”‚|åº”ç”¨æœåŠ¡å™¨ Ã—2|12|
|â”‚|æ•°æ®åº“æœåŠ¡å™¨|12|
|â”‚|è¾¹ç¼˜ç½‘å…³ Ã—3|3. 6|
|â”‚|ç½‘ç»œ+å­˜å‚¨+UPS|11|
|**è½¯ä»¶è´¹ç”¨**|å…¨å¼€æºæ–¹æ¡ˆ|**0**|
|**äººåŠ›æŠ•å…¥**||**238**|
|â”‚|é¡¹ç›®ç»ç† 1äººÃ—10æœˆ|35|
|â”‚|AIå·¥ç¨‹å¸ˆ 2äººÃ—10æœˆ|80|
|â”‚|åç«¯å¼€å‘ 2äººÃ—10æœˆ|60|
|â”‚|å‰ç«¯å¼€å‘ 1äººÃ—8æœˆ|20|
|â”‚|å·¥æ§å·¥ç¨‹å¸ˆ 1äººÃ—8æœˆ|28|
|â”‚|æµ‹è¯•å·¥ç¨‹å¸ˆ 1äººÃ—6æœˆ|15|
|**å…¶ä»–è´¹ç”¨**||**52.5**|
|â”‚|çŸ¥è¯†åº“å»ºè®¾|10|
|â”‚|æµ‹è¯•ç¯å¢ƒ|8|
|â”‚|åŸ¹è®­+å…¶ä»–|3. 5|
|â”‚|é¢„ç•™é‡‘ (10%)|31|
|**â•â•â•â•â•â•â•**|**â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•**|**â•â•â•â•â•â•â•**|
|**æ€»é¢„ç®—**||**384.1ä¸‡å…ƒ**|
### Â å…³é”®ç»“è®º

1. **æˆæœ¬å¤§å¹…é™ä½**ï¼šç›¸æ¯”åŸäº‘æ–¹æ¡ˆèŠ‚çœÂ **572ä¸‡ (60%)**
2. **æ— é•¿æœŸè´¹ç”¨**ï¼šä¸ä¾èµ–APIï¼Œæ— æŒç»­è®¢é˜…æˆæœ¬
3. **æ•°æ®å®‰å…¨**ï¼šå®Œå…¨æœ¬åœ°éƒ¨ç½²ï¼Œæ»¡è¶³å·¥ä¸šå®‰å…¨è¦æ±‚
4. **çµæ´»æ‰©å±•**ï¼šå¯æ ¹æ®éœ€æ±‚å‡çº§GPUé…ç½®
5. **å»ºè®®åˆ†é˜¶æ®µ**ï¼šå…ˆç”¨å…¥é—¨é…ç½®éªŒè¯ï¼Œå†æŒ‰éœ€å‡çº§

# 3. æ•…éšœè¯Šæ–­ä¸é¢„æµ‹

## 1.ç³»ç»Ÿæ¦‚è¿°

### 1.1 åŠŸèƒ½å®šä½

**æ•…éšœè¯Šæ–­ä¸é¢„æµ‹ç³»ç»Ÿ**æ˜¯é¢å‘DCSç³»ç»Ÿçš„æ™ºèƒ½è¿ç»´æ ¸å¿ƒæ¨¡å—ï¼Œæä¾›ï¼š

- ğŸ”Â **å®æ—¶æ•…éšœè¯Šæ–­**ï¼šåŸºäºè§„åˆ™å’ŒAIæ¨¡å‹çš„æ•…éšœè‡ªåŠ¨è¯†åˆ«ä¸å®šä½
- ğŸ¯Â **æ ¹å› åˆ†æï¼ˆRCAï¼‰**ï¼šé€šè¿‡çŸ¥è¯†å›¾è°±å’Œå› æœæ¨ç†å®šä½æ•…éšœæ ¹æœ¬åŸå› 
- ğŸ“ˆÂ **é¢„æµ‹æ€§ç»´æŠ¤**ï¼šåŸºäºæ—¶åºå»ºæ¨¡é¢„æµ‹è®¾å¤‡å‰©ä½™å¯¿å‘½ï¼ˆRULï¼‰å’Œæ•…éšœè¶‹åŠ¿
- âš¡Â **æ™ºèƒ½å‘Šè­¦**ï¼šå‘Šè­¦èšåˆã€é™å™ªã€ä¼˜å…ˆçº§æ’åº
- ğŸ”§Â **å¤„ç½®å»ºè®®**ï¼šè‡ªåŠ¨ç”Ÿæˆæ•…éšœå¤„ç½®æ–¹æ¡ˆå’Œç»´æŠ¤è®¡åˆ’

### 1.2 æ ¸å¿ƒä»·å€¼
|ä»·å€¼ç‚¹|è¯´æ˜|
|---|---|
|å‡å°‘éè®¡åˆ’åœæœº|æå‰é¢„æµ‹æ•…éšœï¼Œå®ç°é¢„é˜²æ€§ç»´æŠ¤|
|ç¼©çŸ­æ•…éšœå¤„ç†æ—¶é—´|è‡ªåŠ¨è¯Šæ–­å®šä½ï¼Œå¿«é€Ÿç»™å‡ºå¤„ç½®å»ºè®®|
|é™ä½ç»´æŠ¤æˆæœ¬|ä»å®šæœŸç»´æŠ¤è½¬å‘æŒ‰éœ€ç»´æŠ¤|
|æå‡è®¾å¤‡å¯é æ€§|æŒç»­ç›‘æµ‹è®¾å¤‡å¥åº·çŠ¶æ€|
|çŸ¥è¯†ç§¯ç´¯|æ•…éšœæ¡ˆä¾‹å’Œè¯Šæ–­ç»éªŒæ•°å­—åŒ–æ²‰æ·€|
## 2. æ•´ä½“æŠ€æœ¯æ¶æ„

~~~
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           æ•…éšœè¯Šæ–­ä¸é¢„æµ‹ç³»ç»ŸæŠ€æœ¯æ¶æ„                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                              åº”ç”¨ä¸å±•ç¤ºå±‚                                        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”‚
â”‚  â”‚  â”‚  è¯Šæ–­çœ‹æ¿     â”‚  â”‚  é¢„æµ‹çœ‹æ¿     â”‚  â”‚  å‘Šè­¦ä¸­å¿ƒ     â”‚  â”‚  Agentäº¤äº’   â”‚        â”‚  â”‚
â”‚  â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚        â”‚  â”‚
â”‚  â”‚  â”‚ â€¢å®æ—¶è¯Šæ–­çŠ¶æ€â”‚  â”‚ â€¢RULé¢„æµ‹æ›²çº¿ â”‚  â”‚ â€¢å‘Šè­¦åˆ—è¡¨    â”‚  â”‚ â€¢è¯Šæ–­é—®ç­”    â”‚        â”‚  â”‚
â”‚  â”‚  â”‚ â€¢æ ¹å› åˆ†æå›¾  â”‚  â”‚ â€¢å¥åº·åº¦è¯„åˆ†  â”‚  â”‚ â€¢å‘Šè­¦ç»Ÿè®¡    â”‚  â”‚ â€¢å¤„ç½®å»ºè®®    â”‚        â”‚  â”‚
â”‚  â”‚  â”‚ â€¢æ•…éšœå†å²    â”‚  â”‚ â€¢ç»´æŠ¤è®¡åˆ’    â”‚  â”‚ â€¢è¶‹åŠ¿åˆ†æ    â”‚  â”‚ â€¢çŸ¥è¯†æ£€ç´¢    â”‚        â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚                                            â”‚
â”‚                                         â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                              APIæœåŠ¡å±‚                                          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  REST API  |  WebSocket(å®æ—¶æ¨é€)  |  gRPC(å†…éƒ¨æœåŠ¡)  |  æ¶ˆæ¯é˜Ÿåˆ—(å¼‚æ­¥)  â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚                                            â”‚
â”‚                                         â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                           è¯Šæ–­ä¸é¢„æµ‹å¼•æ“å±‚                                       â”‚  â”‚
â”‚  â”‚                                                                                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚                         å®æ—¶è¯Šæ–­å¼•æ“                                     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ è§„åˆ™è¯Šæ–­    â”‚  â”‚ MLè¯Šæ–­     â”‚  â”‚ å¼‚å¸¸æ£€æµ‹    â”‚  â”‚ å‘Šè­¦å¤„ç†    â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢ä¸“å®¶è§„åˆ™åº“ â”‚  â”‚â€¢åˆ†ç±»æ¨¡å‹   â”‚  â”‚â€¢ç»Ÿè®¡æ–¹æ³•   â”‚  â”‚â€¢å‘Šè­¦èšåˆ   â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢å†³ç­–æ ‘     â”‚  â”‚â€¢æ·±åº¦å­¦ä¹    â”‚  â”‚â€¢å­¤ç«‹æ£®æ—   â”‚  â”‚â€¢å‘Šè­¦é™å™ª   â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢æ•…éšœæ ‘     â”‚  â”‚â€¢é›†æˆå­¦ä¹    â”‚  â”‚â€¢è‡ªç¼–ç å™¨   â”‚  â”‚â€¢ä¼˜å…ˆçº§æ’åº â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                                                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚                         æ ¹å› åˆ†æå¼•æ“                                     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ çŸ¥è¯†å›¾è°±    â”‚  â”‚ å› æœæ¨ç†    â”‚  â”‚ å…³è”åˆ†æ    â”‚  â”‚ æ¡ˆä¾‹åŒ¹é…    â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢è®¾å¤‡æ‹“æ‰‘   â”‚  â”‚â€¢è´å¶æ–¯ç½‘ç»œ â”‚  â”‚â€¢æ—¶åºå…³è”   â”‚  â”‚â€¢ç›¸ä¼¼æ¡ˆä¾‹   â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢æ•…éšœä¼ æ’­   â”‚  â”‚â€¢å› æœå‘ç°   â”‚  â”‚â€¢æŠ¥è­¦å…³è”   â”‚  â”‚â€¢å†å²ç»éªŒ   â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢ç»„ä»¶ä¾èµ–   â”‚  â”‚â€¢æ ¹å› å®šä½   â”‚  â”‚â€¢å‚æ•°ç›¸å…³   â”‚  â”‚â€¢è§£å†³æ–¹æ¡ˆ   â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                                                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚                         é¢„æµ‹å¼•æ“                                         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ æ—¶åºé¢„æµ‹    â”‚  â”‚ RULé¢„æµ‹    â”‚  â”‚ å¥åº·è¯„ä¼°    â”‚  â”‚ ç»´æŠ¤è§„åˆ’    â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢LSTM      â”‚  â”‚â€¢CNN-LSTM  â”‚  â”‚â€¢å¥åº·æŒ‡æ•°   â”‚  â”‚â€¢ç»´æŠ¤çª—å£   â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢Transformerâ”‚  â”‚â€¢Transformerâ”‚  â”‚â€¢é€€åŒ–æ›²çº¿   â”‚  â”‚â€¢å¤‡ä»¶é¢„æµ‹   â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢Prophet   â”‚  â”‚â€¢ç”Ÿå­˜åˆ†æ   â”‚  â”‚â€¢çŠ¶æ€è¯„åˆ†   â”‚  â”‚â€¢æˆæœ¬ä¼˜åŒ–   â”‚        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                                                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚                         å¤„ç½®å»ºè®®ç”Ÿæˆå™¨                                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ çŸ¥è¯†æ£€ç´¢    â”‚  â”‚ LLMç”Ÿæˆ    â”‚  â”‚ æ–¹æ¡ˆä¼˜åŒ–    â”‚                         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚                         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢RAGæ£€ç´¢   â”‚  â”‚â€¢å»ºè®®ç”Ÿæˆ   â”‚  â”‚â€¢å¯è¡Œæ€§è¯„ä¼° â”‚                         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â”‚â€¢æ¡ˆä¾‹åŒ¹é…   â”‚  â”‚â€¢æ­¥éª¤ç»†åŒ–   â”‚  â”‚â€¢é£é™©è¯„ä¼°   â”‚                         â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚                                            â”‚
â”‚                                         â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                           æ•°æ®ä¸çŸ¥è¯†å±‚                                          â”‚  â”‚
â”‚  â”‚                                                                                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ æ—¶åºæ•°æ®åº“  â”‚  â”‚ çŸ¥è¯†å›¾è°±åº“  â”‚  â”‚ æ¨¡å‹ä»“åº“   â”‚  â”‚ æ•…éšœæ¡ˆä¾‹åº“ â”‚  â”‚ è§„åˆ™åº“   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚  â”‚          â”‚ â”‚  â”‚
â”‚  â”‚  â”‚â€¢InfluxDB  â”‚  â”‚â€¢Neo4j     â”‚  â”‚â€¢MLflow    â”‚  â”‚â€¢å†å²æ¡ˆä¾‹  â”‚  â”‚â€¢è¯Šæ–­è§„åˆ™â”‚ â”‚  â”‚
â”‚  â”‚  â”‚â€¢å†å²æ•°æ®   â”‚  â”‚â€¢è®¾å¤‡å…³ç³»   â”‚  â”‚â€¢æ¨¡å‹ç‰ˆæœ¬  â”‚  â”‚â€¢å¤„ç½®è®°å½•  â”‚  â”‚â€¢é˜ˆå€¼é…ç½®â”‚ â”‚  â”‚
â”‚  â”‚  â”‚â€¢ç‰¹å¾æ•°æ®   â”‚  â”‚â€¢æ•…éšœå…³ç³»   â”‚  â”‚â€¢æ¨¡å‹ç›‘æ§  â”‚  â”‚â€¢ç»éªŒçŸ¥è¯†  â”‚  â”‚â€¢è”é”é€»è¾‘â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚                                            â”‚
â”‚                                         â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                           æ•°æ®é‡‡é›†å±‚                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚  â”‚
â”‚  â”‚  â”‚ DCSæ•°æ®é‡‡é›† â”‚  â”‚ æŠ¥è­¦æ•°æ®    â”‚  â”‚ ç»´æŠ¤è®°å½•   â”‚  â”‚ å¤–éƒ¨æ•°æ®    â”‚               â”‚  â”‚
â”‚  â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚               â”‚  â”‚
â”‚  â”‚  â”‚â€¢OPC UA/DA â”‚  â”‚â€¢æŠ¥è­¦å†å²   â”‚  â”‚â€¢å·¥å•ç³»ç»Ÿ  â”‚  â”‚â€¢ç¯å¢ƒæ•°æ®   â”‚               â”‚  â”‚
â”‚  â”‚  â”‚â€¢Modbus    â”‚  â”‚â€¢äº‹ä»¶æ—¥å¿—   â”‚  â”‚â€¢æ£€ä¿®è®°å½•  â”‚  â”‚â€¢ç”Ÿäº§è®¡åˆ’   â”‚               â”‚  â”‚
â”‚  â”‚  â”‚â€¢MQTT      â”‚  â”‚â€¢æ“ä½œæ—¥å¿—   â”‚  â”‚â€¢å¤‡ä»¶æ›´æ¢  â”‚  â”‚â€¢è´¨é‡æ•°æ®   â”‚               â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
~~~

## 3.æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†

### 3.1 æ•°æ®é‡‡é›†æ¶æ„

~~~
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              æ•°æ®é‡‡é›†æ¶æ„                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚    DCS      â”‚   â”‚   PLC       â”‚   â”‚   ä¼ æ„Ÿå™¨     â”‚   â”‚   å¤–éƒ¨ç³»ç»Ÿ   â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚          â”‚                 â”‚                 â”‚                 â”‚               â”‚
â”‚          â–¼                 â–¼                 â–¼                 â–¼               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                          æ•°æ®é‡‡é›†ç½‘å…³                                    â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚   â”‚  â”‚ OPC UA    â”‚  â”‚ Modbus    â”‚  â”‚ MQTT      â”‚  â”‚ REST API  â”‚            â”‚  â”‚
â”‚   â”‚  â”‚ Connector â”‚  â”‚ Connector â”‚  â”‚ Connector â”‚  â”‚ Connector â”‚            â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚                                         â”‚
â”‚                                      â–¼                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                          æ¶ˆæ¯é˜Ÿåˆ— (Kafka)                                â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚   â”‚  â”‚ raw_data  â”‚  â”‚ alarm_dataâ”‚  â”‚ event_dataâ”‚  â”‚ maint_dataâ”‚            â”‚  â”‚
â”‚   â”‚  â”‚ topic     â”‚  â”‚ topic     â”‚  â”‚ topic     â”‚  â”‚ topic     â”‚            â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚                                         â”‚
â”‚                                      â–¼                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                          æµå¤„ç†å¼•æ“ (Flink/Spark)                        â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚   â”‚  â”‚ æ•°æ®æ¸…æ´—   â”‚  â”‚ ç‰¹å¾è®¡ç®—   â”‚  â”‚ å®æ—¶è¯Šæ–­   â”‚  â”‚ å‘Šè­¦å¤„ç†   â”‚            â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚                                         â”‚
â”‚                                      â–¼                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                          å­˜å‚¨å±‚                                          â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚  â”‚
â”‚   â”‚  â”‚ InfluxDB  â”‚  â”‚ PostgreSQLâ”‚  â”‚ Redis     â”‚                            â”‚  â”‚
â”‚   â”‚  â”‚ (æ—¶åº)    â”‚  â”‚ (å…³ç³»)    â”‚  â”‚ (ç¼“å­˜)    â”‚                            â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
~~~

### 3.2 æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†ä»£ç å®ç°

~~~
# data_collector.py - æ•°æ®é‡‡é›†æ¨¡å—
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import asyncio
import json

class DataQuality(Enum):
    """æ•°æ®è´¨é‡æšä¸¾"""
    GOOD = "good"
    BAD = "bad"
    UNCERTAIN = "uncertain"

@dataclass
class DataPoint:
    """æ•°æ®ç‚¹"""
    tag_name: str
    value: float
    timestamp: datetime
    quality: DataQuality
    unit: str = ""
    metadata: Dict = field(default_factory=dict)

@dataclass
class AlarmEvent:
    """æŠ¥è­¦äº‹ä»¶"""
    alarm_id: str
    tag_name: str
    alarm_type: str          # high, low, highigh, lowlow
    priority: int            # 1-4, 1æœ€é«˜
    message: str
    value: float
    limit: float
    timestamp: datetime
    status: str              # active, acknowledged, cleared
    device_id: str
    area: str

class OPCUACollector:
    """OPC UAæ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self, server_url: str, namespace: str):
        self.server_url = server_url
        self. namespace = namespace
        self.client = None
        self.subscriptions: Dict[str, Any] = {}
    
    async def connect(self):
        """è¿æ¥OPC UAæœåŠ¡å™¨"""
        from asyncua import Client
        self.client = Client(self.server_url)
        await self.client.connect()
    
    async def subscribe_tags(self, tag_names: List[str], 
                             callback, interval_ms: int = 1000):
        """è®¢é˜…æ ‡ç­¾å˜åŒ–"""
        handler = SubscriptionHandler(callback)
        subscription = await self.client.create_subscription(
            interval_ms, handler
        )
        
        for tag_name in tag_names:
            node = self.client. get_node(f"{self.namespace};s={tag_name}")
            await subscription.subscribe_data_change(node)
            self.subscriptions[tag_name] = subscription
    
    async def read_tags_batch(self, tag_names: List[str]) -> List[DataPoint]:
        """æ‰¹é‡è¯»å–æ ‡ç­¾"""
        results = []
        for tag_name in tag_names:
            try:
                node = self.client.get_node(f"{self.namespace};s={tag_name}")
                value = await node.read_value()
                data_point = DataPoint(
                    tag_name=tag_name,
                    value=float(value),
                    timestamp=datetime. now(),
                    quality=DataQuality.GOOD
                )
                results.append(data_point)
            except Exception as e:
                results.append(DataPoint(
                    tag_name=tag_name,
                    value=0.0,
                    timestamp=datetime.now(),
                    quality=DataQuality.BAD,
                    metadata={"error": str(e)}
                ))
        return results


class SubscriptionHandler:
    """OPC UAè®¢é˜…å¤„ç†å™¨"""
    
    def __init__(self, callback):
        self.callback = callback
    
    def datachange_notification(self, node, val, data):
        """æ•°æ®å˜åŒ–å›è°ƒ"""
        data_point = DataPoint(
            tag_name=str(node),
            value=float(val),
            timestamp=datetime.now(),
            quality=DataQuality. GOOD
        )
        asyncio.create_task(self.callback(data_point))


class DataPreprocessor:
    """æ•°æ®é¢„å¤„ç†å™¨"""
    
    def __init__(self, config: Dict):
        self.config = config
        self. tag_configs = config.get("tags", {})
    
    def preprocess(self, data_point: DataPoint) -> Optional[DataPoint]:
        """é¢„å¤„ç†å•ä¸ªæ•°æ®ç‚¹"""
        tag_config = self.tag_configs.get(data_point.tag_name, {})
        
        # 1. æ•°æ®è´¨é‡æ£€æŸ¥
        if data_point. quality == DataQuality.BAD:
            return None
        
        # 2. èŒƒå›´æ£€æŸ¥
        min_val = tag_config. get("min_valid")
        max_val = tag_config. get("max_valid")
        if min_val is not None and data_point.value < min_val:
            data_point.quality = DataQuality. UNCERTAIN
        if max_val is not None and data_point. value > max_val:
            data_point.quality = DataQuality.UNCERTAIN
        
        # 3. å•ä½è½¬æ¢
        if tag_config.get("unit_conversion"):
            factor = tag_config["unit_conversion"]["factor"]
            offset = tag_config["unit_conversion"]. get("offset", 0)
            data_point.value = data_point. value * factor + offset
            data_point.unit = tag_config["unit_conversion"]["target_unit"]
        
        # 4. ç²¾åº¦å¤„ç†
        precision = tag_config. get("precision", 2)
        data_point.value = round(data_point.value, precision)
        
        return data_point
    
    def detect_outliers(self, values: List[float], 
                        method: str = "zscore") -> List[bool]:
        """å¼‚å¸¸å€¼æ£€æµ‹"""
        import numpy as np
        
        values_array = np.array(values)
        
        if method == "zscore":
            # Z-scoreæ–¹æ³•
            mean = np. mean(values_array)
            std = np.std(values_array)
            z_scores = np. abs((values_array - mean) / std)
            return (z_scores > 3).tolist()
        
        elif method == "iqr":
            # IQRæ–¹æ³•
            q1 = np. percentile(values_array, 25)
            q3 = np.percentile(values_array, 75)
            iqr = q3 - q1
            lower = q1 - 1.5 * iqr
            upper = q3 + 1.5 * iqr
            return ((values_array < lower) | (values_array > upper)). tolist()
        
        return [False] * len(values)
    
    def interpolate_missing(self, timestamps: List[datetime], 
                            values: List[Optional[float]],
                            method: str = "linear") -> List[float]:
        """æ’å€¼å¡«å……ç¼ºå¤±å€¼"""
        import numpy as np
        from scipy import interpolate
        
        # è½¬æ¢æ—¶é—´æˆ³ä¸ºæ•°å€¼
        time_nums = [t.timestamp() for t in timestamps]
        
        # æ‰¾å‡ºéç©ºå€¼
        valid_indices = [i for i, v in enumerate(values) if v is not None]
        valid_times = [time_nums[i] for i in valid_indices]
        valid_values = [values[i] for i in valid_indices]
        
        if len(valid_values) < 2:
            return [v if v is not None else 0.0 for v in values]
        
        # æ’å€¼
        if method == "linear":
            f = interpolate.interp1d(valid_times, valid_values, 
                                     fill_value="extrapolate")
        elif method == "spline":
            f = interpolate.UnivariateSpline(valid_times, valid_values)
        
        return f(time_nums). tolist()


class FeatureEngineer:
    """ç‰¹å¾å·¥ç¨‹å™¨"""
    
    def __init__(self):
        self.feature_cache = {}
    
    def compute_statistical_features(self, values: List[float], 
                                     window_size: int = 60) -> Dict[str, float]:
        """è®¡ç®—ç»Ÿè®¡ç‰¹å¾"""
        import numpy as np
        
        if len(values) < window_size:
            values = values + [values[-1]] * (window_size - len(values))
        
        window = values[-window_size:]
        arr = np.array(window)
        
        return {
            "mean": float(np.mean(arr)),
            "std": float(np.std(arr)),
            "min": float(np. min(arr)),
            "max": float(np.max(arr)),
            "range": float(np. max(arr) - np.min(arr)),
            "skewness": float(self._skewness(arr)),
            "kurtosis": float(self._kurtosis(arr)),
            "rms": float(np. sqrt(np.mean(arr**2))),
            "peak_to_peak": float(np.max(arr) - np.min(arr)),
            "crest_factor": float(np.max(np.abs(arr)) / np.sqrt(np.mean(arr**2))) 
                           if np.mean(arr**2) > 0 else 0
        }
    
    def compute_trend_features(self, values: List[float], 
                               timestamps: List[datetime]) -> Dict[str, float]:
        """è®¡ç®—è¶‹åŠ¿ç‰¹å¾"""
        import numpy as np
        from scipy import stats
        
        if len(values) < 2:
            return {"slope": 0, "r_squared": 0, "trend_direction": 0}
        
        # è½¬æ¢æ—¶é—´ä¸ºæ•°å€¼ï¼ˆç§’ï¼‰
        time_nums = np.array([(t - timestamps[0]).total_seconds() 
                              for t in timestamps])
        values_arr = np.array(values)
        
        # çº¿æ€§å›å½’
        slope, intercept, r_value, p_value, std_err = stats.linregress(
            time_nums, values_arr
        )
        
        return {
            "slope": float(slope),
            "intercept": float(intercept),
            "r_squared": float(r_value**2),
            "trend_direction": 1 if slope > 0 else (-1 if slope < 0 else 0),
            "trend_strength": abs(float(slope))
        }
    
    def compute_frequency_features(self, values: List[float], 
                                   sampling_rate: float = 1.0) -> Dict[str, float]:
        """è®¡ç®—é¢‘åŸŸç‰¹å¾"""
        import numpy as np
        from scipy import fft
        
        if len(values) < 4:
            return {"dominant_freq": 0, "spectral_energy": 0}
        
        # FFTå˜æ¢
        n = len(values)
        yf = fft. fft(values)
        xf = fft. fftfreq(n, 1/sampling_rate)[:n//2]
        power = 2. 0/n * np.abs(yf[0:n//2])
        
        # ä¸»é¢‘ç‡
        dominant_idx = np.argmax(power[1:]) + 1
        dominant_freq = xf[dominant_idx] if dominant_idx < len(xf) else 0
        
        return {
            "dominant_freq": float(dominant_freq),
            "spectral_energy": float(np.sum(power**2)),
            "spectral_entropy": float(self._spectral_entropy(power))
        }
    
    def compute_vibration_features(self, values: List[float]) -> Dict[str, float]:
        """è®¡ç®—æŒ¯åŠ¨ç‰¹å¾ï¼ˆé’ˆå¯¹æ—‹è½¬è®¾å¤‡ï¼‰"""
        import numpy as np
        
        arr = np.array(values)
        
        return {
            "rms_velocity": float(np. sqrt(np.mean(arr**2))),
            "peak_velocity": float(np.max(np.abs(arr))),
            "crest_factor": float(np.max(np.abs(arr)) / np.sqrt(np.mean(arr**2)))
                           if np.mean(arr**2) > 0 else 0,
            "shape_factor": float(np.sqrt(np.mean(arr**2)) / np.mean(np.abs(arr)))
                           if np.mean(np.abs(arr)) > 0 else 0,
            "impulse_factor": float(np. max(np.abs(arr)) / np. mean(np.abs(arr)))
                             if np.mean(np.abs(arr)) > 0 else 0
        }
    
    def _skewness(self, arr):
        """è®¡ç®—ååº¦"""
        import numpy as np
        n = len(arr)
        mean = np.mean(arr)
        std = np.std(arr)
        if std == 0:
            return 0
        return np.sum(((arr - mean) / std) ** 3) / n
    
    def _kurtosis(self, arr):
        """è®¡ç®—å³°åº¦"""
        import numpy as np
        n = len(arr)
        mean = np.mean(arr)
        std = np.std(arr)
        if std == 0:
            return 0
        return np. sum(((arr - mean) / std) ** 4) / n - 3
    
    def _spectral_entropy(self, power):
        """è®¡ç®—é¢‘è°±ç†µ"""
        import numpy as np
        power_normalized = power / np. sum(power) if np.sum(power) > 0 else power
        power_normalized = power_normalized[power_normalized > 0]
        return -np.sum(power_normalized * np. log2(power_normalized))
~~~

## 4.å®æ—¶æ•…éšœè¯Šæ–­å¼•æ“

### 4.1 è¯Šæ–­å¼•æ“æ¶æ„

~~~
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           å®æ—¶æ•…éšœè¯Šæ–­å¼•æ“                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚   è¾“å…¥æ•°æ®                                                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚   â”‚  å®æ—¶æ•°æ®    â”‚   â”‚  æŠ¥è­¦æ•°æ®    â”‚   â”‚  ç‰¹å¾æ•°æ®    â”‚                          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚          â”‚                 â”‚                 â”‚                                  â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                            â”‚                                                    â”‚
â”‚                            â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                      è¯Šæ–­è°ƒåº¦å™¨ (Diagnosis Orchestrator)                 â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                                    â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚          â–¼                 â–¼                 â–¼                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚   â”‚  è§„åˆ™è¯Šæ–­    â”‚   â”‚  MLè¯Šæ–­     â”‚   â”‚  å¼‚å¸¸æ£€æµ‹    â”‚                          â”‚
â”‚   â”‚  Engine     â”‚   â”‚  Engine     â”‚   â”‚  Engine     â”‚                          â”‚
â”‚   â”‚             â”‚   â”‚             â”‚   â”‚             â”‚                          â”‚
â”‚   â”‚ â€¢é˜ˆå€¼è§„åˆ™   â”‚   â”‚ â€¢RF/XGBoost â”‚   â”‚ â€¢ç»Ÿè®¡æ–¹æ³•   â”‚                          â”‚
â”‚   â”‚ â€¢é€»è¾‘è§„åˆ™   â”‚   â”‚ â€¢CNN/LSTM   â”‚   â”‚ â€¢å­¤ç«‹æ£®æ—   â”‚                          â”‚
â”‚   â”‚ â€¢æ•…éšœæ ‘     â”‚   â”‚ â€¢Transformerâ”‚   â”‚ â€¢è‡ªç¼–ç å™¨   â”‚                          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚          â”‚                 â”‚                 â”‚                                  â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                            â”‚                                                    â”‚
â”‚                            â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                      è¯Šæ–­ç»“æœèåˆå™¨ (Result Fusion)                      â”‚  â”‚
â”‚   â”‚                                                                         â”‚  â”‚
â”‚   â”‚   â€¢å¤šæºç»“æœåŠ æƒèåˆ    â€¢ç½®ä¿¡åº¦è®¡ç®—    â€¢å†²çªæ¶ˆè§£    â€¢æœ€ç»ˆè¯Šæ–­ç»“è®º          â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                                    â”‚
â”‚                            â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                      è¯Šæ–­ç»“æœ                                            â”‚  â”‚
â”‚   â”‚                                                                         â”‚  â”‚
â”‚   â”‚   â€¢æ•…éšœç±»å‹    â€¢æ•…éšœä½ç½®    â€¢æ•…éšœåŸå›     â€¢ç½®ä¿¡åº¦    â€¢è¯æ®é“¾              â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
~~~

### 4.2 è§„åˆ™è¯Šæ–­å¼•æ“

~~~
# rule_engine.py - è§„åˆ™è¯Šæ–­å¼•æ“
from typing import Dict, List, Optional, Callable, Any
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import json
import operator

class RuleOperator(Enum):
    """è§„åˆ™è¿ç®—ç¬¦"""
    EQ = "=="
    NE = "!="
    GT = ">"
    GE = ">="
    LT = "<"
    LE = "<="
    IN = "in"
    NOT_IN = "not_in"
    BETWEEN = "between"
    CONTAINS = "contains"

class RuleLogic(Enum):
    """è§„åˆ™é€»è¾‘"""
    AND = "and"
    OR = "or"
    NOT = "not"

@dataclass
class Condition:
    """æ¡ä»¶"""
    variable: str              # å˜é‡åï¼ˆæ ‡ç­¾åæˆ–ç‰¹å¾åï¼‰
    operator: RuleOperator     # è¿ç®—ç¬¦
    value: Any                 # æ¯”è¾ƒå€¼
    time_window: int = 0       # æ—¶é—´çª—å£ï¼ˆç§’ï¼‰ï¼Œ0è¡¨ç¤ºå½“å‰å€¼

@dataclass
class Rule:
    """è¯Šæ–­è§„åˆ™"""
    rule_id: str
    name: str
    description: str
    conditions: List[Condition]
    logic: RuleLogic
    conclusion: Dict           # è¯Šæ–­ç»“è®º
    priority: int              # ä¼˜å…ˆçº§ï¼Œæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
    enabled: bool = True
    metadata: Dict = field(default_factory=dict)

@dataclass
class DiagnosisResult:
    """è¯Šæ–­ç»“æœ"""
    fault_id: str
    fault_type: str
    fault_name: str
    device_id: str
    confidence: float
    severity: str              # critical, major, minor, warning
    evidence: List[Dict]       # è¯æ®é“¾
    suggestion: str
    timestamp: datetime
    source: str                # rule, ml, anomaly
    metadata: Dict = field(default_factory=dict)


class RuleDiagnosisEngine:
    """è§„åˆ™è¯Šæ–­å¼•æ“"""
    
    OPERATORS = {
        RuleOperator.EQ: operator.eq,
        RuleOperator.NE: operator.ne,
        RuleOperator.GT: operator.gt,
        RuleOperator. GE: operator. ge,
        RuleOperator.LT: operator.lt,
        RuleOperator.LE: operator.le,
    }
    
    def __init__(self, rule_repository):
        self.rule_repository = rule_repository
        self. rules: List[Rule] = []
        self.custom_functions: Dict[str, Callable] = {}
    
    async def load_rules(self, device_type: str = None):
        """åŠ è½½è§„åˆ™"""
        self.rules = await self.rule_repository.get_rules(device_type)
        self.rules. sort(key=lambda r: r.priority)
    
    def register_function(self, name: str, func: Callable):
        """æ³¨å†Œè‡ªå®šä¹‰å‡½æ•°"""
        self.custom_functions[name] = func
    
    async def diagnose(self, context: Dict) -> List[DiagnosisResult]:
        """æ‰§è¡Œè¯Šæ–­"""
        results = []
        
        for rule in self.rules:
            if not rule.enabled:
                continue
            
            # è¯„ä¼°è§„åˆ™
            matched, evidence = self._evaluate_rule(rule, context)
            
            if matched:
                result = DiagnosisResult(
                    fault_id=f"FAULT-{rule.rule_id}-{datetime.now(). strftime('%Y%m%d%H%M%S')}",
                    fault_type=rule.conclusion. get("fault_type", "unknown"),
                    fault_name=rule.conclusion.get("fault_name", rule.name),
                    device_id=context.get("device_id", ""),
                    confidence=rule.conclusion.get("confidence", 0.9),
                    severity=rule.conclusion. get("severity", "warning"),
                    evidence=evidence,
                    suggestion=rule.conclusion.get("suggestion", ""),
                    timestamp=datetime.now(),
                    source="rule",
                    metadata={"rule_id": rule.rule_id, "rule_name": rule. name}
                )
                results.append(result)
        
        return results
    
    def _evaluate_rule(self, rule: Rule, context: Dict) -> tuple:
        """è¯„ä¼°å•æ¡è§„åˆ™"""
        evidence = []
        condition_results = []
        
        for condition in rule.conditions:
            result, cond_evidence = self._evaluate_condition(condition, context)
            condition_results. append(result)
            if result:
                evidence.append(cond_evidence)
        
        # åº”ç”¨é€»è¾‘è¿ç®—
        if rule.logic == RuleLogic.AND:
            matched = all(condition_results)
        elif rule.logic == RuleLogic.OR:
            matched = any(condition_results)
        elif rule.logic == RuleLogic.NOT:
            matched = not condition_results[0] if condition_results else False
        else:
            matched = all(condition_results)
        
        return matched, evidence
    
    def _evaluate_condition(self, condition: Condition, 
                           context: Dict) -> tuple:
        """è¯„ä¼°å•ä¸ªæ¡ä»¶"""
        # è·å–å˜é‡å€¼
        actual_value = self._get_variable_value(
            condition.variable, 
            context, 
            condition. time_window
        )
        
        if actual_value is None:
            return False, None
        
        # è¯„ä¼°æ¡ä»¶
        expected_value = condition.value
        op = condition.operator
        
        try:
            if op in self.OPERATORS:
                result = self.OPERATORS[op](actual_value, expected_value)
            elif op == RuleOperator. BETWEEN:
                result = expected_value[0] <= actual_value <= expected_value[1]
            elif op == RuleOperator.IN:
                result = actual_value in expected_value
            elif op == RuleOperator.NOT_IN:
                result = actual_value not in expected_value
            elif op == RuleOperator.CONTAINS:
                result = expected_value in str(actual_value)
            else:
                result = False
            
            evidence = {
                "variable": condition.variable,
                "operator": op. value,
                "expected": expected_value,
                "actual": actual_value,
                "matched": result
            }
            
            return result, evidence
            
        except Exception as e:
            return False, {"error": str(e)}
    
    def _get_variable_value(self, variable: str, context: Dict, 
                           time_window: int = 0) -> Optional[Any]:
        """è·å–å˜é‡å€¼"""
        # æ”¯æŒç‚¹å·åˆ†éš”çš„åµŒå¥—è®¿é—®
        parts = variable.split(".")
        value = context
        
        for part in parts:
            if isinstance(value, dict):
                value = value.get(part)
            else:
                return None
            
            if value is None:
                return None
        
        return value


class FaultTreeEngine:
    """æ•…éšœæ ‘è¯Šæ–­å¼•æ“"""
    
    def __init__(self):
        self.fault_trees: Dict[str, Dict] = {}
    
    def load_fault_tree(self, tree_id: str, tree_definition: Dict):
        """åŠ è½½æ•…éšœæ ‘å®šä¹‰"""
        self.fault_trees[tree_id] = tree_definition
    
    def diagnose(self, tree_id: str, context: Dict) -> List[DiagnosisResult]:
        """åŸºäºæ•…éšœæ ‘è¯Šæ–­"""
        tree = self.fault_trees.get(tree_id)
        if not tree:
            return []
        
        # ä»é¡¶äº‹ä»¶å¼€å§‹ï¼Œé€’å½’è¯„ä¼°
        top_event = tree. get("top_event")
        result = self._evaluate_node(top_event, tree. get("nodes", {}), context)
        
        if result["occurred"]:
            return [DiagnosisResult(
                fault_id=f"FT-{tree_id}-{datetime. now().strftime('%Y%m%d%H%M%S')}",
                fault_type=top_event.get("fault_type", "unknown"),
                fault_name=top_event.get("name", ""),
                device_id=context.get("device_id", ""),
                confidence=result["probability"],
                severity=top_event.get("severity", "major"),
                evidence=result["path"],
                suggestion=top_event.get("suggestion", ""),
                timestamp=datetime.now(),
                source="fault_tree",
                metadata={"tree_id": tree_id}
            )]
        
        return []
    
    def _evaluate_node(self, node: Dict, all_nodes: Dict, 
                       context: Dict) -> Dict:
        """è¯„ä¼°æ•…éšœæ ‘èŠ‚ç‚¹"""
        node_type = node.get("type", "basic")
        
        if node_type == "basic":
            # åŸºæœ¬äº‹ä»¶ï¼Œç›´æ¥è¯„ä¼°
            return self._evaluate_basic_event(node, context)
        
        elif node_type == "and":
            # ANDé—¨ï¼Œæ‰€æœ‰å­äº‹ä»¶éƒ½å‘ç”Ÿ
            children_results = []
            for child_id in node.get("children", []):
                child_node = all_nodes. get(child_id, {})
                child_result = self._evaluate_node(child_node, all_nodes, context)
                children_results.append(child_result)
            
            all_occurred = all(r["occurred"] for r in children_results)
            prob = 1.0
            for r in children_results:
                prob *= r["probability"]
            
            path = []
            for r in children_results:
                path.extend(r["path"])
            
            return {
                "occurred": all_occurred,
                "probability": prob if all_occurred else 0,
                "path": path
            }
        
        elif node_type == "or":
            # ORé—¨ï¼Œä»»ä¸€å­äº‹ä»¶å‘ç”Ÿ
            children_results = []
            for child_id in node.get("children", []):
                child_node = all_nodes.get(child_id, {})
                child_result = self._evaluate_node(child_node, all_nodes, context)
                children_results. append(child_result)
            
            any_occurred = any(r["occurred"] for r in children_results)
            # ORé—¨æ¦‚ç‡è®¡ç®—
            prob = 1.0
            for r in children_results:
                prob *= (1 - r["probability"])
            prob = 1 - prob
            
            path = []
            for r in children_results:
                if r["occurred"]:
                    path. extend(r["path"])
            
            return {
                "occurred": any_occurred,
                "probability": prob if any_occurred else 0,
                "path": path
            }
        
        return {"occurred": False, "probability": 0, "path": []}
    
    def _evaluate_basic_event(self, event: Dict, context: Dict) -> Dict:
        """è¯„ä¼°åŸºæœ¬äº‹ä»¶"""
        condition = event.get("condition", {})
        variable = condition.get("variable")
        operator_str = condition.get("operator", "==")
        expected = condition.get("value")
        
        actual = context.get(variable)
        
        op_map = {
            "==": operator.eq, "!=": operator. ne,
            ">": operator.gt, ">=": operator.ge,
            "<": operator.lt, "<=": operator.le
        }
        
        op_func = op_map.get(operator_str, operator.eq)
        
        try:
            occurred = op_func(actual, expected)
            return {
                "occurred": occurred,
                "probability": 1.0 if occurred else 0.0,
                "path": [{
                    "event": event.get("name"),
                    "variable": variable,
                    "expected": expected,
                    "actual": actual,
                    "occurred": occurred
                }] if occurred else []
            }
        except:
            return {"occurred": False, "probability": 0, "path": []}
~~~

### 4.3 æœºå™¨å­¦ä¹ è¯Šæ–­å¼•æ“

~~~
# ml_diagnosis_engine.py - æœºå™¨å­¦ä¹ è¯Šæ–­å¼•æ“
import numpy as np
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import joblib
import json

@dataclass
class MLModelConfig:
    """MLæ¨¡å‹é…ç½®"""
    model_id: str
    model_name: str
    model_type: str           # classification, regression, anomaly
    model_path: str
    feature_names: List[str]
    target_classes: List[str]
    threshold: float
    version: str
    metadata: Dict

class MLDiagnosisEngine:
    """æœºå™¨å­¦ä¹ è¯Šæ–­å¼•æ“"""
    
    def __init__(self, model_registry):
        self. model_registry = model_registry
        self.models: Dict[str, any] = {}
        self.configs: Dict[str, MLModelConfig] = {}
        self. feature_engineer = None
    
    async def load_model(self, model_id: str) -> bool:
        """åŠ è½½æ¨¡å‹"""
        config = await self.model_registry.get_config(model_id)
        if not config:
            return False
        
        try:
            model = joblib.load(config.model_path)
            self. models[model_id] = model
            self.configs[model_id] = config
            return True
        except Exception as e:
            print(f"Failed to load model {model_id}: {e}")
            return False
    
    async def diagnose(self, model_id: str, 
                       features: Dict[str, float]) -> Optional[DiagnosisResult]:
        """ä½¿ç”¨MLæ¨¡å‹è¯Šæ–­"""
        if model_id not in self.models:
            await self.load_model(model_id)
        
        model = self.models. get(model_id)
        config = self.configs. get(model_id)
        
        if not model or not config:
            return None
        
        # å‡†å¤‡ç‰¹å¾å‘é‡
        feature_vector = self._prepare_features(features, config.feature_names)
        
        if config.model_type == "classification":
            return self._classify(model, feature_vector, config, features)
        elif config.model_type == "anomaly":
            return self._detect_anomaly(model, feature_vector, config, features)
        
        return None
    
    def _prepare_features(self, features: Dict[str, float], 
                         feature_names: List[str]) -> np.ndarray:
        """å‡†å¤‡ç‰¹å¾å‘é‡"""
        vector = []
        for name in feature_names:
            value = features.get(name, 0. 0)
            vector.append(value)
        return np.array([vector])
    
    def _classify(self, model, feature_vector: np.ndarray,
                  config: MLModelConfig, 
                  raw_features: Dict) -> Optional[DiagnosisResult]:
        """åˆ†ç±»è¯Šæ–­"""
        # é¢„æµ‹
        prediction = model.predict(feature_vector)[0]
        probabilities = model.predict_proba(feature_vector)[0]
        
        # è·å–é¢„æµ‹ç±»åˆ«å’Œç½®ä¿¡åº¦
        class_idx = int(prediction)
        confidence = float(probabilities[class_idx])
        fault_type = config. target_classes[class_idx]
        
        # å¦‚æœæ˜¯æ­£å¸¸ç±»åˆ«æˆ–ç½®ä¿¡åº¦ä½äºé˜ˆå€¼ï¼Œè¿”å›None
        if fault_type == "normal" or confidence < config.threshold:
            return None
        
        # ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
        evidence = self._extract_evidence(model, feature_vector, 
                                          config. feature_names, raw_features)
        
        return DiagnosisResult(
            fault_id=f"ML-{config.model_id}-{datetime. now().strftime('%Y%m%d%H%M%S')}",
            fault_type=fault_type,
            fault_name=self._get_fault_name(fault_type),
            device_id=raw_features.get("device_id", ""),
            confidence=confidence,
            severity=self._get_severity(fault_type, confidence),
            evidence=evidence,
            suggestion=self._get_suggestion(fault_type),
            timestamp=datetime.now(),
            source="ml_classification",
            metadata={
                "model_id": config.model_id,
                "model_version": config.version,
                "all_probabilities": {
                    config.target_classes[i]: float(probabilities[i])
                    for i in range(len(config.target_classes))
                }
            }
        )
    
    def _detect_anomaly(self, model, feature_vector: np.ndarray,
                        config: MLModelConfig,
                        raw_features: Dict) -> Optional[DiagnosisResult]:
        """å¼‚å¸¸æ£€æµ‹è¯Šæ–­"""
        # å¼‚å¸¸å¾—åˆ†
        if hasattr(model, 'decision_function'):
            anomaly_score = -model.decision_function(feature_vector)[0]
        elif hasattr(model, 'score_samples'):
            anomaly_score = -model.score_samples(feature_vector)[0]
        else:
            prediction = model.predict(feature_vector)[0]
            anomaly_score = 1.0 if prediction == -1 else 0.0
        
        # æ ‡å‡†åŒ–å¾—åˆ†åˆ°0-1
        normalized_score = self._normalize_anomaly_score(anomaly_score)
        
        if normalized_score < config.threshold:
            return None
        
        evidence = self._extract_anomaly_evidence(
            feature_vector, config. feature_names, raw_features
        )
        
        return DiagnosisResult(
            fault_id=f"ANOMALY-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            fault_type="anomaly",
            fault_name="å¼‚å¸¸çŠ¶æ€æ£€æµ‹",
            device_id=raw_features.get("device_id", ""),
            confidence=normalized_score,
            severity=self._get_anomaly_severity(normalized_score),
            evidence=evidence,
            suggestion="æ£€æµ‹åˆ°å¼‚å¸¸è¿è¡ŒçŠ¶æ€ï¼Œå»ºè®®æ£€æŸ¥ç›¸å…³å‚æ•°",
            timestamp=datetime.now(),
            source="ml_anomaly",
            metadata={
                "model_id": config.model_id,
                "anomaly_score": float(anomaly_score),
                "normalized_score": normalized_score
            }
        )
    
    def _extract_evidence(self, model, feature_vector: np.ndarray,
                         feature_names: List[str],
                         raw_features: Dict) -> List[Dict]:
        """æå–ç‰¹å¾è¯æ®"""
        evidence = []
        
        # å°è¯•è·å–ç‰¹å¾é‡è¦æ€§
        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
            sorted_idx = np. argsort(importances)[::-1]
            
            for idx in sorted_idx[:5]:  # Top 5ç‰¹å¾
                evidence.append({
                    "feature": feature_names[idx],
                    "value": float(feature_vector[0][idx]),
                    "importance": float(importances[idx]),
                    "contribution": "high" if importances[idx] > 0.1 else "medium"
                })
        else:
            # ç®€å•åˆ—å‡ºç‰¹å¾å€¼
            for i, name in enumerate(feature_names):
                evidence.append({
                    "feature": name,
                    "value": float(feature_vector[0][i])
                })
        
        return evidence
    
    def _extract_anomaly_evidence(self, feature_vector: np. ndarray,
                                  feature_names: List[str],
                                  raw_features: Dict) -> List[Dict]:
        """æå–å¼‚å¸¸è¯æ®"""
        evidence = []
        
        # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„z-score
        for i, name in enumerate(feature_names):
            value = float(feature_vector[0][i])
            evidence.append({
                "feature": name,
                "value": value,
                "status": "abnormal" if abs(value) > 2 else "normal"
            })
        
        return evidence
    
    def _normalize_anomaly_score(self, score: float) -> float:
        """æ ‡å‡†åŒ–å¼‚å¸¸å¾—åˆ†"""
        # ä½¿ç”¨sigmoidå‡½æ•°æ ‡å‡†åŒ–
        return 1 / (1 + np.exp(-score))
    
    def _get_fault_name(self, fault_type: str) -> str:
        """è·å–æ•…éšœåç§°"""
        fault_names = {
            "bearing_fault": "è½´æ‰¿æ•…éšœ",
            "imbalance": "è½¬å­ä¸å¹³è¡¡",
            "misalignment": "è½´å¯¹ä¸­ä¸è‰¯",
            "looseness": "æœºæ¢°æ¾åŠ¨",
            "overload": "è¿‡è½½è¿è¡Œ",
            "cavitation": "æ°”èš€",
            "blockage": "å µå¡"
        }
        return fault_names. get(fault_type, fault_type)
    
    def _get_severity(self, fault_type: str, confidence: float) -> str:
        """è·å–ä¸¥é‡ç¨‹åº¦"""
        if confidence > 0.9:
            return "critical"
        elif confidence > 0. 7:
            return "major"
        elif confidence > 0.5:
            return "minor"
        return "warning"
    
    def _get_anomaly_severity(self, score: float) -> str:
        """è·å–å¼‚å¸¸ä¸¥é‡ç¨‹åº¦"""
        if score > 0.9:
            return "critical"
        elif score > 0. 7:
            return "major"
        elif score > 0.5:
            return "minor"
        return "warning"
    
    def _get_suggestion(self, fault_type: str) -> str:
        """è·å–å¤„ç½®å»ºè®®"""
        suggestions = {
            "bearing_fault": "å»ºè®®å®‰æ’è½´æ‰¿æ£€æŸ¥å’Œæ›´æ¢",
            "imbalance": "å»ºè®®è¿›è¡ŒåŠ¨å¹³è¡¡æ ¡æ­£",
            "misalignment": "å»ºè®®æ£€æŸ¥å¹¶è°ƒæ•´è½´å¯¹ä¸­",
            "looseness": "å»ºè®®æ£€æŸ¥ç´§å›ºä»¶å¹¶é‡æ–°ç´§å›º",
            "overload": "å»ºè®®é™ä½è´Ÿè½½æˆ–æ£€æŸ¥é©±åŠ¨ç³»ç»Ÿ",
            "cavitation": "å»ºè®®æ£€æŸ¥å…¥å£å‹åŠ›å’Œé˜€é—¨çŠ¶æ€",
            "blockage": "å»ºè®®æ£€æŸ¥å¹¶æ¸…ç†ç®¡è·¯"
        }
        return suggestions.get(fault_type, "å»ºè®®å®‰æ’ä¸“ä¸šæ£€æŸ¥")


class DeepLearningDiagnosisEngine:
    """æ·±åº¦å­¦ä¹ è¯Šæ–­å¼•æ“"""
    
    def __init__(self):
        self.models: Dict[str, any] = {}
    
    async def load_model(self, model_id: str, model_path: str):
        """åŠ è½½æ·±åº¦å­¦ä¹ æ¨¡å‹"""
        import tensorflow as tf
        model = tf.keras.models.load_model(model_path)
        self.models[model_id] = model
    
    async def diagnose_sequence(self, model_id: str,
                                sequence_data: np.ndarray,
                                config: Dict) -> Optional[DiagnosisResult]:
        """åºåˆ—æ•°æ®è¯Šæ–­ï¼ˆå¦‚LSTM/Transformerï¼‰"""
        model = self.models. get(model_id)
        if model is None:
            return None
        
        # ç¡®ä¿è¾“å…¥å½¢çŠ¶æ­£ç¡® [batch, timesteps, features]
        if len(sequence_data. shape) == 2:
            sequence_data = sequence_data.reshape(1, *sequence_data.shape)
        
        # é¢„æµ‹
        predictions = model.predict(sequence_data, verbose=0)
        
        # å¤„ç†é¢„æµ‹ç»“æœ
        if config.get("task_type") == "classification":
            class_idx = np.argmax(predictions[0])
            confidence = float(predictions[0][class_idx])
            fault_type = config["classes"][class_idx]
            
            if fault_type == "normal" or confidence < config.get("threshold", 0.5):
                return None
            
            return DiagnosisResult(
                fault_id=f"DL-{model_id}-{datetime. now().strftime('%Y%m%d%H%M%S')}",
                fault_type=fault_type,
                fault_name=config. get("fault_names", {}).get(fault_type, fault_type),
                device_id=config.get("device_id", ""),
                confidence=confidence,
                severity=self._get_severity(confidence),
                evidence=[{
                    "type": "sequence_analysis",
                    "predictions": predictions[0]. tolist()
                }],
                suggestion=config. get("suggestions", {}).get(fault_type, ""),
                timestamp=datetime.now(),
                source="deep_learning"
            )
        
        return None
    
    def _get_severity(self, confidence: float) -> str:
        if confidence > 0. 9:
            return "critical"
        elif confidence > 0.7:
            return "major"
        elif confidence > 0.5:
            return "minor"
        return "warning"
~~~

### 4.4 å¼‚å¸¸æ£€æµ‹å¼•æ“

~~~
# anomaly_detection. py - å¼‚å¸¸æ£€æµ‹å¼•æ“
import numpy as np
from typing import Dict, List, Optional, Tuple, Union
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from collections import deque
import json

class AnomalyType(Enum):
    """å¼‚å¸¸ç±»å‹"""
    POINT = "point"              # ç‚¹å¼‚å¸¸
    CONTEXTUAL = "contextual"    # ä¸Šä¸‹æ–‡å¼‚å¸¸
    COLLECTIVE = "collective"    # é›†ä½“å¼‚å¸¸
    TREND = "trend"              # è¶‹åŠ¿å¼‚å¸¸
    LEVEL_SHIFT = "level_shift"  # æ°´å¹³åç§»

@dataclass
class AnomalyResult:
    """å¼‚å¸¸æ£€æµ‹ç»“æœ"""
    tag_name: str
    anomaly_type: AnomalyType
    anomaly_score: float         # 0-1ï¼Œè¶Šé«˜è¶Šå¼‚å¸¸
    is_anomaly: bool
    current_value: float
    expected_value: float
    threshold: float
    timestamp: datetime
    context: Dict = field(default_factory=dict)


class StatisticalAnomalyDetector:
    """ç»Ÿè®¡æ–¹æ³•å¼‚å¸¸æ£€æµ‹å™¨"""
    
    def __init__(self, window_size: int = 100):
        self. window_size = window_size
        self.data_buffers: Dict[str, deque] = {}
        self. statistics: Dict[str, Dict] = {}
    
    def update(self, tag_name: str, value: float, timestamp: datetime):
        """æ›´æ–°æ•°æ®ç¼“å†²åŒº"""
        if tag_name not in self. data_buffers:
            self.data_buffers[tag_name] = deque(maxlen=self.window_size)
        
        self.data_buffers[tag_name].append({
            "value": value,
            "timestamp": timestamp
        })
        
        # æ›´æ–°ç»Ÿè®¡é‡
        self._update_statistics(tag_name)
    
    def _update_statistics(self, tag_name: str):
        """æ›´æ–°ç»Ÿè®¡é‡"""
        buffer = self.data_buffers[tag_name]
        if len(buffer) < 10:
            return
        
        values = [item["value"] for item in buffer]
        arr = np.array(values)
        
        self.statistics[tag_name] = {
            "mean": float(np.mean(arr)),
            "std": float(np.std(arr)),
            "median": float(np. median(arr)),
            "q1": float(np.percentile(arr, 25)),
            "q3": float(np.percentile(arr, 75)),
            "min": float(np. min(arr)),
            "max": float(np.max(arr)),
            "count": len(values)
        }
    
    def detect_zscore(self, tag_name: str, value: float,
                      threshold: float = 3.0) -> AnomalyResult:
        """Z-scoreå¼‚å¸¸æ£€æµ‹"""
        stats = self.statistics. get(tag_name)
        
        if not stats or stats["std"] == 0:
            return AnomalyResult(
                tag_name=tag_name,
                anomaly_type=AnomalyType.POINT,
                anomaly_score=0.0,
                is_anomaly=False,
                current_value=value,
                expected_value=value,
                threshold=threshold,
                timestamp=datetime.now()
            )
        
        z_score = abs((value - stats["mean"]) / stats["std"])
        anomaly_score = min(z_score / threshold, 1. 0)
        is_anomaly = z_score > threshold
        
        return AnomalyResult(
            tag_name=tag_name,
            anomaly_type=AnomalyType.POINT,
            anomaly_score=anomaly_score,
            is_anomaly=is_anomaly,
            current_value=value,
            expected_value=stats["mean"],
            threshold=threshold,
            timestamp=datetime. now(),
            context={
                "z_score": float(z_score),
                "mean": stats["mean"],
                "std": stats["std"]
            }
        )
    
    def detect_iqr(self, tag_name: str, value: float,
                   k: float = 1.5) -> AnomalyResult:
        """IQRå¼‚å¸¸æ£€æµ‹"""
        stats = self.statistics.get(tag_name)
        
        if not stats:
            return AnomalyResult(
                tag_name=tag_name,
                anomaly_type=AnomalyType.POINT,
                anomaly_score=0.0,
                is_anomaly=False,
                current_value=value,
                expected_value=value,
                threshold=k,
                timestamp=datetime.now()
            )
        
        iqr = stats["q3"] - stats["q1"]
        lower_bound = stats["q1"] - k * iqr
        upper_bound = stats["q3"] + k * iqr
        
        is_anomaly = value < lower_bound or value > upper_bound
        
        # è®¡ç®—å¼‚å¸¸å¾—åˆ†
        if is_anomaly:
            if value < lower_bound:
                distance = lower_bound - value
            else:
                distance = value - upper_bound
            anomaly_score = min(distance / iqr, 1.0) if iqr > 0 else 1.0
        else:
            anomaly_score = 0.0
        
        return AnomalyResult(
            tag_name=tag_name,
            anomaly_type=AnomalyType.POINT,
            anomaly_score=anomaly_score,
            is_anomaly=is_anomaly,
            current_value=value,
            expected_value=stats["median"],
            threshold=k,
            timestamp=datetime.now(),
            context={
                "lower_bound": lower_bound,
                "upper_bound": upper_bound,
                "iqr": iqr
            }
        )
    
    def detect_moving_average(self, tag_name: str, value: float,
                              window: int = 20,
                              threshold_std: float = 2.0) -> AnomalyResult:
        """ç§»åŠ¨å¹³å‡å¼‚å¸¸æ£€æµ‹"""
        buffer = self.data_buffers.get(tag_name)
        
        if not buffer or len(buffer) < window:
            return AnomalyResult(
                tag_name=tag_name,
                anomaly_type=AnomalyType.POINT,
                anomaly_score=0.0,
                is_anomaly=False,
                current_value=value,
                expected_value=value,
                threshold=threshold_std,
                timestamp=datetime. now()
            )
        
        recent_values = [item["value"] for item in list(buffer)[-window:]]
        ma = np.mean(recent_values)
        ma_std = np. std(recent_values)
        
        if ma_std == 0:
            deviation = 0
        else:
            deviation = abs(value - ma) / ma_std
        
        is_anomaly = deviation > threshold_std
        anomaly_score = min(deviation / threshold_std, 1. 0)
        
        return AnomalyResult(
            tag_name=tag_name,
            anomaly_type=AnomalyType.CONTEXTUAL,
            anomaly_score=anomaly_score,
            is_anomaly=is_anomaly,
            current_value=value,
            expected_value=float(ma),
            threshold=threshold_std,
            timestamp=datetime.now(),
            context={
                "moving_average": float(ma),
                "moving_std": float(ma_std),
                "deviation": float(deviation)
            }
        )


class IsolationForestDetector:
    """å­¤ç«‹æ£®æ—å¼‚å¸¸æ£€æµ‹å™¨"""
    
    def __init__(self, contamination: float = 0.1, n_estimators: int = 100):
        self.contamination = contamination
        self.n_estimators = n_estimators
        self. models: Dict[str, any] = {}
        self.scalers: Dict[str, any] = {}
        self.is_fitted: Dict[str, bool] = {}
        self.training_data: Dict[str, List] = {}
        self.min_samples = 100
    
    def update(self, model_key: str, features: np.ndarray):
        """æ›´æ–°è®­ç»ƒæ•°æ®"""
        if model_key not in self.training_data:
            self.training_data[model_key] = []
        
        self.training_data[model_key].append(features. flatten())
        
        # è¾¾åˆ°æœ€å°æ ·æœ¬æ•°æ—¶è®­ç»ƒæ¨¡å‹
        if len(self.training_data[model_key]) >= self.min_samples:
            if not self.is_fitted.get(model_key, False):
                self._fit_model(model_key)
    
    def _fit_model(self, model_key: str):
        """è®­ç»ƒæ¨¡å‹"""
        from sklearn.ensemble import IsolationForest
        from sklearn.preprocessing import StandardScaler
        
        data = np.array(self.training_data[model_key])
        
        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        data_scaled = scaler.fit_transform(data)
        
        # è®­ç»ƒå­¤ç«‹æ£®æ—
        model = IsolationForest(
            contamination=self.contamination,
            n_estimators=self.n_estimators,
            random_state=42
        )
        model.fit(data_scaled)
        
        self.models[model_key] = model
        self.scalers[model_key] = scaler
        self.is_fitted[model_key] = True
    
    def detect(self, model_key: str, features: np.ndarray) -> AnomalyResult:
        """æ£€æµ‹å¼‚å¸¸"""
        if not self.is_fitted.get(model_key, False):
            # æ¨¡å‹æœªè®­ç»ƒï¼Œå…ˆæ”¶é›†æ•°æ®
            self. update(model_key, features)
            return AnomalyResult(
                tag_name=model_key,
                anomaly_type=AnomalyType.POINT,
                anomaly_score=0. 0,
                is_anomaly=False,
                current_value=float(features[0]) if len(features) > 0 else 0,
                expected_value=0,
                threshold=0. 5,
                timestamp=datetime.now(),
                context={"status": "collecting_data"}
            )
        
        model = self.models[model_key]
        scaler = self.scalers[model_key]
        
        # æ ‡å‡†åŒ–
        features_scaled = scaler.transform(features. reshape(1, -1))
        
        # é¢„æµ‹
        prediction = model.predict(features_scaled)[0]
        anomaly_score = -model.decision_function(features_scaled)[0]
        
        # æ ‡å‡†åŒ–å¾—åˆ†åˆ°0-1
        normalized_score = self._normalize_score(anomaly_score)
        
        is_anomaly = prediction == -1
        
        return AnomalyResult(
            tag_name=model_key,
            anomaly_type=AnomalyType.COLLECTIVE,
            anomaly_score=normalized_score,
            is_anomaly=is_anomaly,
            current_value=float(features[0]) if len(features) > 0 else 0,
            expected_value=0,
            threshold=0.5,
            timestamp=datetime.now(),
            context={
                "raw_score": float(anomaly_score),
                "prediction": int(prediction)
            }
        )
    
    def _normalize_score(self, score: float) -> float:
        """æ ‡å‡†åŒ–å¼‚å¸¸å¾—åˆ†åˆ°0-1"""
        return 1 / (1 + np.exp(-score))


class AutoEncoderDetector:
    """è‡ªç¼–ç å™¨å¼‚å¸¸æ£€æµ‹å™¨"""
    
    def __init__(self, input_dim: int, encoding_dim: int = 16,
                 threshold_percentile: float = 95):
        self.input_dim = input_dim
        self. encoding_dim = encoding_dim
        self.threshold_percentile = threshold_percentile
        self.model = None
        self. threshold = None
        self.is_fitted = False
        self.training_data = []
        self.min_samples = 500
    
    def _build_model(self):
        """æ„å»ºè‡ªç¼–ç å™¨æ¨¡å‹"""
        import tensorflow as tf
        from tensorflow.keras.models import Model
        from tensorflow. keras.layers import Input, Dense
        
        # ç¼–ç å™¨
        input_layer = Input(shape=(self.input_dim,))
        encoded = Dense(64, activation='relu')(input_layer)
        encoded = Dense(32, activation='relu')(encoded)
        encoded = Dense(self.encoding_dim, activation='relu')(encoded)
        
        # è§£ç å™¨
        decoded = Dense(32, activation='relu')(encoded)
        decoded = Dense(64, activation='relu')(decoded)
        decoded = Dense(self. input_dim, activation='linear')(decoded)
        
        self.model = Model(input_layer, decoded)
        self.model. compile(optimizer='adam', loss='mse')
    
    def update(self, features: np.ndarray):
        """æ›´æ–°è®­ç»ƒæ•°æ®"""
        self.training_data. append(features.flatten())
        
        if len(self. training_data) >= self.min_samples and not self.is_fitted:
            self._fit_model()
    
    def _fit_model(self):
        """è®­ç»ƒæ¨¡å‹"""
        self._build_model()
        
        data = np.array(self.training_data)
        
        # æ ‡å‡†åŒ–
        self.mean = np.mean(data, axis=0)
        self. std = np.std(data, axis=0)
        self.std[self.std == 0] = 1
        data_normalized = (data - self.mean) / self.std
        
        # è®­ç»ƒ
        self.model. fit(
            data_normalized, data_normalized,
            epochs=50,
            batch_size=32,
            validation_split=0.1,
            verbose=0
        )
        
        # è®¡ç®—é‡æ„è¯¯å·®é˜ˆå€¼
        reconstructions = self. model.predict(data_normalized, verbose=0)
        mse = np.mean(np.power(data_normalized - reconstructions, 2), axis=1)
        self.threshold = np. percentile(mse, self.threshold_percentile)
        
        self.is_fitted = True
    
    def detect(self, features: np.ndarray) -> AnomalyResult:
        """æ£€æµ‹å¼‚å¸¸"""
        if not self.is_fitted:
            self. update(features)
            return AnomalyResult(
                tag_name="autoencoder",
                anomaly_type=AnomalyType.COLLECTIVE,
                anomaly_score=0. 0,
                is_anomaly=False,
                current_value=0,
                expected_value=0,
                threshold=0.5,
                timestamp=datetime.now(),
                context={"status": "training"}
            )
        
        # æ ‡å‡†åŒ–
        features_normalized = (features. reshape(1, -1) - self.mean) / self.std
        
        # é‡æ„
        reconstruction = self.model. predict(features_normalized, verbose=0)
        
        # è®¡ç®—é‡æ„è¯¯å·®
        mse = np. mean(np.power(features_normalized - reconstruction, 2))
        
        # è®¡ç®—å¼‚å¸¸å¾—åˆ†
        anomaly_score = min(mse / self.threshold, 1.0)
        is_anomaly = mse > self.threshold
        
        return AnomalyResult(
            tag_name="autoencoder",
            anomaly_type=AnomalyType. COLLECTIVE,
            anomaly_score=float(anomaly_score),
            is_anomaly=is_anomaly,
            current_value=float(mse),
            expected_value=float(self.threshold),
            threshold=float(self.threshold),
            timestamp=datetime.now(),
            context={
                "reconstruction_error": float(mse),
                "threshold": float(self.threshold)
            }
        )


class TrendAnomalyDetector:
    """è¶‹åŠ¿å¼‚å¸¸æ£€æµ‹å™¨"""
    
    def __init__(self, window_size: int = 60,
                 trend_threshold: float = 0.1,
                 level_shift_threshold: float = 3.0):
        self.window_size = window_size
        self.trend_threshold = trend_threshold
        self.level_shift_threshold = level_shift_threshold
        self.data_buffers: Dict[str, deque] = {}
    
    def update(self, tag_name: str, value: float, timestamp: datetime):
        """æ›´æ–°æ•°æ®"""
        if tag_name not in self. data_buffers:
            self.data_buffers[tag_name] = deque(maxlen=self.window_size * 2)
        
        self.data_buffers[tag_name].append({
            "value": value,
            "timestamp": timestamp
        })
    
    def detect_trend_change(self, tag_name: str) -> Optional[AnomalyResult]:
        """æ£€æµ‹è¶‹åŠ¿å˜åŒ–"""
        buffer = self.data_buffers.get(tag_name)
        
        if not buffer or len(buffer) < self.window_size:
            return None
        
        data = list(buffer)
        values = np.array([d["value"] for d in data])
        
        # åˆ†æˆä¸¤åŠæ¯”è¾ƒè¶‹åŠ¿
        mid = len(values) // 2
        first_half = values[:mid]
        second_half = values[mid:]
        
        # è®¡ç®—è¶‹åŠ¿æ–œç‡
        first_slope = self._calculate_slope(first_half)
        second_slope = self._calculate_slope(second_half)
        
        # æ£€æµ‹è¶‹åŠ¿å˜åŒ–
        slope_change = abs(second_slope - first_slope)
        
        if slope_change > self.trend_threshold:
            return AnomalyResult(
                tag_name=tag_name,
                anomaly_type=AnomalyType. TREND,
                anomaly_score=min(slope_change / self.trend_threshold, 1.0),
                is_anomaly=True,
                current_value=float(values[-1]),
                expected_value=float(np.mean(first_half)),
                threshold=self.trend_threshold,
                timestamp=datetime.now(),
                context={
                    "first_slope": float(first_slope),
                    "second_slope": float(second_slope),
                    "slope_change": float(slope_change),
                    "trend_direction": "increasing" if second_slope > first_slope else "decreasing"
                }
            )
        
        return None
    
    def detect_level_shift(self, tag_name: str) -> Optional[AnomalyResult]:
        """æ£€æµ‹æ°´å¹³åç§»"""
        buffer = self.data_buffers.get(tag_name)
        
        if not buffer or len(buffer) < self. window_size:
            return None
        
        data = list(buffer)
        values = np.array([d["value"] for d in data])
        
        # åˆ†æˆä¸¤åŠæ¯”è¾ƒå‡å€¼
        mid = len(values) // 2
        first_half = values[:mid]
        second_half = values[mid:]
        
        first_mean = np. mean(first_half)
        first_std = np. std(first_half)
        second_mean = np.mean(second_half)
        
        if first_std == 0:
            return None
        
        # è®¡ç®—æ°´å¹³åç§»
        level_shift = abs(second_mean - first_mean) / first_std
        
        if level_shift > self.level_shift_threshold:
            return AnomalyResult(
                tag_name=tag_name,
                anomaly_type=AnomalyType. LEVEL_SHIFT,
                anomaly_score=min(level_shift / self.level_shift_threshold, 1. 0),
                is_anomaly=True,
                current_value=float(second_mean),
                expected_value=float(first_mean),
                threshold=self.level_shift_threshold,
                timestamp=datetime.now(),
                context={
                    "first_mean": float(first_mean),
                    "second_mean": float(second_mean),
                    "shift_magnitude": float(level_shift),
                    "shift_direction": "up" if second_mean > first_mean else "down"
                }
            )
        
        return None
    
    def _calculate_slope(self, values: np.ndarray) -> float:
        """è®¡ç®—æ–œç‡"""
        if len(values) < 2:
            return 0
        
        x = np.arange(len(values))
        slope, _ = np.polyfit(x, values, 1)
        return slope


class AnomalyDetectionEngine:
    """å¼‚å¸¸æ£€æµ‹æ€»å¼•æ“"""
    
    def __init__(self, config: Dict):
        self.config = config
        
        # åˆå§‹åŒ–å„æ£€æµ‹å™¨
        self.statistical_detector = StatisticalAnomalyDetector(
            window_size=config.get("window_size", 100)
        )
        self.isolation_forest = IsolationForestDetector(
            contamination=config.get("contamination", 0.1)
        )
        self.trend_detector = TrendAnomalyDetector(
            window_size=config.get("trend_window", 60)
        )
        
        # æƒé‡é…ç½®
        self. weights = config.get("weights", {
            "zscore": 0.3,
            "isolation_forest": 0.4,
            "trend": 0.3
        })
    
    def detect(self, tag_name: str, value: float,
               features: np.ndarray = None,
               timestamp: datetime = None) -> Dict:
        """ç»¼åˆå¼‚å¸¸æ£€æµ‹"""
        if timestamp is None:
            timestamp = datetime. now()
        
        results = {}
        
        # 1.  ç»Ÿè®¡æ–¹æ³•æ£€æµ‹
        self. statistical_detector.update(tag_name, value, timestamp)
        results["zscore"] = self. statistical_detector.detect_zscore(tag_name, value)
        results["iqr"] = self.statistical_detector. detect_iqr(tag_name, value)
        results["moving_avg"] = self.statistical_detector.detect_moving_average(
            tag_name, value
        )
        
        # 2.  å­¤ç«‹æ£®æ—æ£€æµ‹ï¼ˆéœ€è¦å¤šç»´ç‰¹å¾ï¼‰
        if features is not None:
            results["isolation_forest"] = self.isolation_forest.detect(
                tag_name, features
            )
        
        # 3.  è¶‹åŠ¿å¼‚å¸¸æ£€æµ‹
        self.trend_detector. update(tag_name, value, timestamp)
        trend_result = self.trend_detector.detect_trend_change(tag_name)
        if trend_result:
            results["trend"] = trend_result
        
        level_shift_result = self.trend_detector.detect_level_shift(tag_name)
        if level_shift_result:
            results["level_shift"] = level_shift_result
        
        # 4. ç»¼åˆè¯„åˆ†
        final_score = self._calculate_final_score(results)
        is_anomaly = final_score > self.config.get("final_threshold", 0.5)
        
        return {
            "tag_name": tag_name,
            "value": value,
            "timestamp": timestamp,
            "is_anomaly": is_anomaly,
            "anomaly_score": final_score,
            "details": results
        }
    
    def _calculate_final_score(self, results: Dict) -> float:
        """è®¡ç®—ç»¼åˆå¼‚å¸¸å¾—åˆ†"""
        weighted_score = 0. 0
        total_weight = 0.0
        
        for method, weight in self. weights.items():
            if method in results and results[method] is not None:
                weighted_score += results[method]. anomaly_score * weight
                total_weight += weight
        
        return weighted_score / total_weight if total_weight > 0 else 0.0
~~~

## 5.æ ¹å› åˆ†æå¼•æ“

### 5.1 æ ¹å› åˆ†ææ¶æ„

~~~
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              æ ¹å› åˆ†æå¼•æ“                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚   è¾“å…¥                                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚   â”‚  æ•…éšœç°è±¡    â”‚   â”‚  æŠ¥è­¦åºåˆ—    â”‚   â”‚  å‚æ•°æ•°æ®    â”‚                          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚          â”‚                 â”‚                 â”‚                                  â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                            â”‚                                                    â”‚
â”‚                            â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                        å¤šæ–¹æ³•å¹¶è¡Œåˆ†æ                                    â”‚  â”‚
â”‚   â”‚                                                                         â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚   â”‚   â”‚ çŸ¥è¯†å›¾è°±æ¨ç† â”‚   â”‚ å› æœæ¨æ–­    â”‚   â”‚ å…³è”è§„åˆ™    â”‚   â”‚ æ¡ˆä¾‹åŒ¹é…   â”‚  â”‚  â”‚
â”‚   â”‚   â”‚             â”‚   â”‚             â”‚   â”‚             â”‚   â”‚           â”‚  â”‚  â”‚
â”‚   â”‚   â”‚â€¢è®¾å¤‡æ‹“æ‰‘    â”‚   â”‚â€¢Granger    â”‚   â”‚â€¢æ—¶åºå…³è”    â”‚   â”‚â€¢ç›¸ä¼¼æ¡ˆä¾‹  â”‚  â”‚  â”‚
â”‚   â”‚   â”‚â€¢æ•…éšœä¼ æ’­    â”‚   â”‚â€¢è´å¶æ–¯ç½‘ç»œ  â”‚   â”‚â€¢æŠ¥è­¦å…³è”    â”‚   â”‚â€¢å†å²ç»éªŒ  â”‚  â”‚  â”‚
â”‚   â”‚   â”‚â€¢ä¾èµ–å…³ç³»    â”‚   â”‚â€¢PCç®—æ³•     â”‚   â”‚â€¢å‚æ•°ç›¸å…³    â”‚   â”‚â€¢è§£å†³æ–¹æ¡ˆ  â”‚  â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚   â”‚          â”‚                 â”‚                 â”‚               â”‚         â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â”‚                 â”‚                 â”‚               â”‚            â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                      â”‚                                        â”‚
â”‚                                      â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                        æ ¹å› å€™é€‰èåˆä¸æ’åº                                â”‚  â”‚
â”‚   â”‚                                                                         â”‚  â”‚
â”‚   â”‚   â€¢å¤šæºè¯æ®åŠ æƒ    â€¢ç½®ä¿¡åº¦è®¡ç®—    â€¢å› æœé“¾æ„å»º    â€¢æ ¹å› æ’åº               â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚                                        â”‚
â”‚                                      â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                           è¾“å‡º                                          â”‚  â”‚
â”‚   â”‚                                                                         â”‚  â”‚
â”‚   â”‚   â€¢æ ¹å› åˆ—è¡¨(å¸¦ç½®ä¿¡åº¦)    â€¢å› æœé“¾è·¯å›¾    â€¢å¤„ç½®å»ºè®®    â€¢ç›¸ä¼¼æ¡ˆä¾‹å‚è€ƒ        â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
~~~

### 5.2 çŸ¥è¯†å›¾è°±æ ¹å› åˆ†æ

~~~
# knowledge_graph_rca.py - çŸ¥è¯†å›¾è°±æ ¹å› åˆ†æ
from typing import Dict, List, Optional, Tuple, Set
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import json

class RelationType(Enum):
    """å…³ç³»ç±»å‹"""
    CAUSES = "CAUSES"                    # Aå¯¼è‡´B
    CAUSED_BY = "CAUSED_BY"              # Aç”±Bå¼•èµ·
    CONNECTED_TO = "CONNECTED_TO"        # ç‰©ç†è¿æ¥
    DEPENDS_ON = "DEPENDS_ON"            # ä¾èµ–å…³ç³»
    PART_OF = "PART_OF"                  # ç»„æˆå…³ç³»
    MONITORS = "MONITORS"                # ç›‘æµ‹å…³ç³»
    AFFECTS = "AFFECTS"                  # å½±å“å…³ç³»
    PRECEDES = "PRECEDES"                # æ—¶åºå…ˆå

@dataclass
class KnowledgeNode:
    """çŸ¥è¯†èŠ‚ç‚¹"""
    node_id: str
    node_type: str              # device, component, parameter, fault, symptom
    name: str
    properties: Dict = field(default_factory=dict)

@dataclass
class KnowledgeEdge:
    """çŸ¥è¯†è¾¹"""
    source_id: str
    target_id: str
    relation_type: RelationType
    weight: float = 1.0
    properties: Dict = field(default_factory=dict)

@dataclass
class RootCauseCandidate:
    """æ ¹å› å€™é€‰"""
    cause_id: str
    cause_name: str
    cause_type: str
    confidence: float
    evidence_chain: List[Dict]
    propagation_path: List[str]
    supporting_facts: List[str]


class KnowledgeGraphRCA:
    """çŸ¥è¯†å›¾è°±æ ¹å› åˆ†æå¼•æ“"""
    
    def __init__(self, graph_connection=None):
        self.graph = graph_connection
        self.nodes: Dict[str, KnowledgeNode] = {}
        self.edges: List[KnowledgeEdge] = []
        self.adjacency: Dict[str, List[Tuple[str, KnowledgeEdge]]] = {}
        self.reverse_adjacency: Dict[str, List[Tuple[str, KnowledgeEdge]]] = {}
    
    def add_node(self, node: KnowledgeNode):
        """æ·»åŠ èŠ‚ç‚¹"""
        self.nodes[node. node_id] = node
        if node.node_id not in self.adjacency:
            self.adjacency[node.node_id] = []
        if node.node_id not in self. reverse_adjacency:
            self.reverse_adjacency[node.node_id] = []
    
    def add_edge(self, edge: KnowledgeEdge):
        """æ·»åŠ è¾¹"""
        self.edges.append(edge)
        
        if edge.source_id not in self.adjacency:
            self.adjacency[edge.source_id] = []
        self.adjacency[edge.source_id]. append((edge.target_id, edge))
        
        if edge.target_id not in self.reverse_adjacency:
            self.reverse_adjacency[edge. target_id] = []
        self. reverse_adjacency[edge.target_id].append((edge. source_id, edge))
    
    async def load_from_neo4j(self, device_id: str = None):
        """ä»Neo4jåŠ è½½çŸ¥è¯†å›¾è°±"""
        if not self.graph:
            return
        
        # åŠ è½½è®¾å¤‡åŠå…¶ç›¸å…³èŠ‚ç‚¹
        query = """
        MATCH (n)
        WHERE n:Device OR n:Component OR n:Parameter OR n:Fault OR n:Symptom
        OPTIONAL MATCH (n)-[r]->(m)
        RETURN n, r, m
        """
        
        results = self.graph.run(query). data()
        
        for record in results:
            # å¤„ç†èŠ‚ç‚¹
            node_data = record['n']
            node = KnowledgeNode(
                node_id=str(node_data. identity),
                node_type=list(node_data. labels)[0],
                name=node_data.get('name', ''),
                properties=dict(node_data)
            )
            self.add_node(node)
            
            # å¤„ç†è¾¹
            if record['r'] and record['m']:
                target_data = record['m']
                target_node = KnowledgeNode(
                    node_id=str(target_data.identity),
                    node_type=list(target_data.labels)[0],
                    name=target_data.get('name', ''),
                    properties=dict(target_data)
                )
                self.add_node(target_node)
                
                edge = KnowledgeEdge(
                    source_id=node.node_id,
                    target_id=target_node.node_id,
                    relation_type=RelationType(type(record['r']).__name__),
                    weight=record['r']. get('weight', 1.0)
                )
                self.add_edge(edge)
    
    def analyze_root_cause(self, fault_symptoms: List[str],
                          context: Dict = None,
                          max_depth: int = 5) -> List[RootCauseCandidate]:
        """åˆ†ææ ¹å› """
        candidates = []
        
        for symptom_id in fault_symptoms:
            # åå‘éå†å› æœé“¾
            causes = self._trace_causes(symptom_id, max_depth)
            candidates.extend(causes)
        
        # åˆå¹¶å’Œæ’åºå€™é€‰æ ¹å› 
        merged_candidates = self._merge_candidates(candidates)
        
        # æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´ç½®ä¿¡åº¦
        if context:
            merged_candidates = self._adjust_by_context(merged_candidates, context)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        merged_candidates.sort(key=lambda x: x.confidence, reverse=True)
        
        return merged_candidates[:10]  # è¿”å›Top 10
    
    def _trace_causes(self, symptom_id: str, max_depth: int,
                     current_depth: int = 0,
                     visited: Set[str] = None,
                     path: List[str] = None) -> List[RootCauseCandidate]:
        """åå‘è¿½è¸ªåŸå› """
        if visited is None:
            visited = set()
        if path is None:
            path = []
        
        if current_depth >= max_depth or symptom_id in visited:
            return []
        
        visited.add(symptom_id)
        path = path + [symptom_id]
        
        candidates = []
        
        # è·å–æ‰€æœ‰å¯èƒ½çš„åŸå› ï¼ˆåå‘è¾¹ï¼‰
        causes = self. reverse_adjacency. get(symptom_id, [])
        
        for cause_id, edge in causes:
            if edge.relation_type in [RelationType. CAUSES, RelationType. AFFECTS]:
                cause_node = self. nodes.get(cause_id)
                
                if cause_node:
                    # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºè¾¹æƒé‡å’Œè·¯å¾„é•¿åº¦ï¼‰
                    confidence = edge.weight * (0.9 ** current_depth)
                    
                    # å¦‚æœæ˜¯æ ¹æœ¬åŸå› ç±»å‹çš„èŠ‚ç‚¹
                    if cause_node.node_type in ['Fault', 'RootCause', 'FailureMode']:
                        candidate = RootCauseCandidate(
                            cause_id=cause_id,
                            cause_name=cause_node.name,
                            cause_type=cause_node. node_type,
                            confidence=confidence,
                            evidence_chain=self._build_evidence_chain(path + [cause_id]),
                            propagation_path=path + [cause_id],
                            supporting_facts=self._get_supporting_facts(cause_id)
                        )
                        candidates.append(candidate)
                    
                    # ç»§ç»­å‘ä¸Šè¿½æº¯
                    deeper_causes = self._trace_causes(
                        cause_id, max_depth, current_depth + 1,
                        visited. copy(), path
                    )
                    candidates.extend(deeper_causes)
        
        return candidates
    
    def _build_evidence_chain(self, path: List[str]) -> List[Dict]:
        """æ„å»ºè¯æ®é“¾"""
        chain = []
        
        for i in range(len(path) - 1):
            source_id = path[i]
            target_id = path[i + 1]
            
            source_node = self. nodes.get(source_id)
            target_node = self.nodes.get(target_id)
            
            # æ‰¾åˆ°è¿æ¥è¾¹
            edge = None
            for tid, e in self.adjacency.get(target_id, []):
                if tid == source_id:
                    edge = e
                    break
            
            if source_node and target_node:
                chain.append({
                    "from": {
                        "id": target_id,
                        "name": target_node. name,
                        "type": target_node. node_type
                    },
                    "to": {
                        "id": source_id,
                        "name": source_node.name,
                        "type": source_node.node_type
                    },
                    "relation": edge.relation_type. value if edge else "UNKNOWN",
                    "confidence": edge.weight if edge else 1. 0
                })
        
        return chain
    
    def _get_supporting_facts(self, cause_id: str) -> List[str]:
        """è·å–æ”¯æŒäº‹å®"""
        facts = []
        cause_node = self. nodes.get(cause_id)
        
        if cause_node:
            # ä»èŠ‚ç‚¹å±æ€§è·å–äº‹å®
            if cause_node.properties.get("description"):
                facts. append(cause_node.properties["description"])
            if cause_node.properties.get("typical_symptoms"):
                facts. append(f"å…¸å‹ç—‡çŠ¶: {cause_node.properties['typical_symptoms']}")
            if cause_node.properties. get("occurrence_rate"):
                facts. append(f"å‘ç”Ÿæ¦‚ç‡: {cause_node.properties['occurrence_rate']}")
        
        return facts
    
    def _merge_candidates(self, candidates: List[RootCauseCandidate]) -> List[RootCauseCandidate]:
        """åˆå¹¶ç›¸åŒçš„å€™é€‰æ ¹å› """
        merged = {}
        
        for candidate in candidates:
            key = candidate.cause_id
            
            if key in merged:
                # åˆå¹¶ç½®ä¿¡åº¦ï¼ˆå–æœ€å¤§å€¼ï¼‰
                if candidate.confidence > merged[key]. confidence:
                    merged[key] = candidate
                # åˆå¹¶è¯æ®é“¾
                existing_paths = set(str(e) for e in merged[key].evidence_chain)
                for evidence in candidate.evidence_chain:
                    if str(evidence) not in existing_paths:
                        merged[key].evidence_chain. append(evidence)
            else:
                merged[key] = candidate
        
        return list(merged.values())
    
    def _adjust_by_context(self, candidates: List[RootCauseCandidate],
                          context: Dict) -> List[RootCauseCandidate]:
        """æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´ç½®ä¿¡åº¦"""
        for candidate in candidates:
            cause_node = self.nodes. get(candidate.cause_id)
            
            if not cause_node:
                continue
            
            # æ ¹æ®å½“å‰å‚æ•°å€¼è°ƒæ•´
            if "current_values" in context:
                related_params = cause_node.properties. get("related_parameters", [])
                for param in related_params:
                    if param in context["current_values"]:
                        # å¦‚æœç›¸å…³å‚æ•°å¼‚å¸¸ï¼Œå¢åŠ ç½®ä¿¡åº¦
                        param_value = context["current_values"][param]
                        if self._is_parameter_abnormal(param, param_value, context):
                            candidate.confidence *= 1.2
            
            # æ ¹æ®æœ€è¿‘ç»´æŠ¤è®°å½•è°ƒæ•´
            if "maintenance_history" in context:
                last_maintenance = context["maintenance_history"]. get(candidate.cause_id)
                if last_maintenance:
                    days_since = (datetime.now() - last_maintenance). days
                    if days_since > 365:  # è¶…è¿‡ä¸€å¹´æœªç»´æŠ¤
                        candidate.confidence *= 1.1
            
            # é™åˆ¶ç½®ä¿¡åº¦ä¸Šé™
            candidate.confidence = min(candidate.confidence, 1.0)
        
        return candidates
    
    def _is_parameter_abnormal(self, param: str, value: float,
                              context: Dict) -> bool:
        """åˆ¤æ–­å‚æ•°æ˜¯å¦å¼‚å¸¸"""
        limits = context.get("parameter_limits", {}). get(param)
        if limits:
            return value < limits.get("low", float('-inf')) or \
                   value > limits.get("high", float('inf'))
        return False


class CausalInferenceRCA:
    """å› æœæ¨æ–­æ ¹å› åˆ†æ"""
    
    def __init__(self):
        self.causal_graph = {}
    
    def granger_causality_test(self, cause_series: List[float],
                               effect_series: List[float],
                               max_lag: int = 5) -> Tuple[bool, float]:
        """Grangerå› æœæ£€éªŒ"""
        from statsmodels.tsa.stattools import grangercausalitytests
        import numpy as np
        import warnings
        
        warnings.filterwarnings('ignore')
        
        if len(cause_series) != len(effect_series) or len(cause_series) < max_lag + 10:
            return False, 0.0
        
        data = np.column_stack([effect_series, cause_series])
        
        try:
            results = grangercausalitytests(data, maxlag=max_lag, verbose=False)
            
            # è·å–æœ€å°på€¼
            min_p_value = 1.0
            for lag in range(1, max_lag + 1):
                p_value = results[lag][0]['ssr_ftest'][1]
                min_p_value = min(min_p_value, p_value)
            
            is_causal = min_p_value < 0.05
            confidence = 1 - min_p_value
            
            return is_causal, confidence
            
        except Exception as e:
            return False, 0. 0
    
    def build_causal_graph(self, time_series_data: Dict[str, List[float]],
                          significance_level: float = 0.05) -> Dict:
        """æ„å»ºå› æœå›¾"""
        variables = list(time_series_data.keys())
        causal_edges = []
        
        for i, var1 in enumerate(variables):
            for j, var2 in enumerate(variables):
                if i != j:
                    is_causal, confidence = self.granger_causality_test(
                        time_series_data[var1],
                        time_series_data[var2]
                    )
                    
                    if is_causal:
                        causal_edges.append({
                            "cause": var1,
                            "effect": var2,
                            "confidence": confidence
                        })
        
        self.causal_graph = {
            "variables": variables,
            "edges": causal_edges
        }
        
        return self.causal_graph
    
    def find_root_causes(self, effect_variable: str,
                        observed_values: Dict[str, float]) -> List[RootCauseCandidate]:
        """åŸºäºå› æœå›¾æ‰¾æ ¹å› """
        if not self.causal_graph:
            return []
        
        candidates = []
        
        # æ‰¾åˆ°æ‰€æœ‰æŒ‡å‘effect_variableçš„è¾¹
        for edge in self.causal_graph["edges"]:
            if edge["effect"] == effect_variable:
                cause_var = edge["cause"]
                confidence = edge["confidence"]
                
                # æ£€æŸ¥causeå˜é‡æ˜¯å¦å¼‚å¸¸
                if cause_var in observed_values:
                    candidate = RootCauseCandidate(
                        cause_id=cause_var,
                        cause_name=cause_var,
                        cause_type="causal_variable",
                        confidence=confidence,
                        evidence_chain=[{
                            "from": cause_var,
                            "to": effect_variable,
                            "relation": "GRANGER_CAUSES",
                            "confidence": confidence
                        }],
                        propagation_path=[cause_var, effect_variable],
                        supporting_facts=[
                            f"Grangerå› æœæ£€éªŒç½®ä¿¡åº¦: {confidence:. 2%}"
                        ]
                    )
                    candidates.append(candidate)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        candidates.sort(key=lambda x: x.confidence, reverse=True)
        
        return candidates
~~~

## 6.é¢„æµ‹å¼•æ“

### 6.1 å‰©ä½™å¯¿å‘½é¢„æµ‹ï¼ˆRULï¼‰

~~~
# rul_prediction.py - å‰©ä½™å¯¿å‘½é¢„æµ‹
import numpy as np
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
import tensorflow as tf
from tensorflow.keras. models import Model, Sequential
from tensorflow.keras.layers import (
    Input, LSTM, Dense, Dropout, Conv1D, MaxPooling1D,
    Flatten, Bidirectional, Attention, MultiHeadAttention,
    LayerNormalization, GlobalAveragePooling1D
)

@dataclass
class RULPrediction:
    """RULé¢„æµ‹ç»“æœ"""
    device_id: str
    predicted_rul: float          # é¢„æµ‹å‰©ä½™å¯¿å‘½ï¼ˆå°æ—¶ï¼‰
    confidence_interval: Tuple[float, float]  # ç½®ä¿¡åŒºé—´
    health_index: float           # å¥åº·æŒ‡æ•° 0-1
    degradation_rate: float       # é€€åŒ–é€Ÿç‡
    prediction_time: datetime
    risk_level: str              # low, medium, high, critical
    recommended_action: str
    model_confidence: float


class LSTMRULPredictor:
    """LSTMå‰©ä½™å¯¿å‘½é¢„æµ‹å™¨"""
    
    def __init__(self, sequence_length: int = 50,
                 n_features: int = 14,
                 lstm_units: int = 64):
        self.sequence_length = sequence_length
        self. n_features = n_features
        self.lstm_units = lstm_units
        self.model = None
        self.scaler = None
        self.is_trained = False
    
    def build_model(self):
        """æ„å»ºLSTMæ¨¡å‹"""
        model = Sequential([
            LSTM(self.lstm_units, return_sequences=True,
                 input_shape=(self.sequence_length, self. n_features)),
            Dropout(0.2),
            LSTM(self. lstm_units // 2, return_sequences=False),
            Dropout(0.2),
            Dense(32, activation='relu'),
            Dense(1, activation='linear')  # è¾“å‡ºRUL
        ])
        
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        
        self.model = model
        return model
    
    def train(self, X_train: np.ndarray, y_train: np.ndarray,
              X_val: np.ndarray = None, y_val: np.ndarray = None,
              epochs: int = 100, batch_size: int = 32):
        """è®­ç»ƒæ¨¡å‹"""
        if self.model is None:
            self. build_model()
        
        # æ•°æ®æ ‡å‡†åŒ–
        from sklearn.preprocessing import StandardScaler
        
        # Reshape for scaling
        n_samples, seq_len, n_features = X_train.shape
        X_train_reshaped = X_train.reshape(-1, n_features)
        
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train_reshaped)
        X_train_scaled = X_train_scaled.reshape(n_samples, seq_len, n_features)
        
        validation_data = None
        if X_val is not None and y_val is not None:
            X_val_reshaped = X_val.reshape(-1, n_features)
            X_val_scaled = self.scaler.transform(X_val_reshaped)
            X_val_scaled = X_val_scaled.reshape(X_val.shape)
            validation_data = (X_val_scaled, y_val)
        
        # è®­ç»ƒ
        history = self. model.fit(
            X_train_scaled, y_train,
            epochs=epochs,
            batch_size=batch_size,
            validation_data=validation_data,
            callbacks=[
                tf.keras. callbacks.EarlyStopping(
                    patience=10, restore_best_weights=True
                ),
                tf. keras.callbacks. ReduceLROnPlateau(
                    factor=0. 5, patience=5
                )
            ],
            verbose=1
        )
        
        self.is_trained = True
        return history
    
    def predict(self, sequence: np.ndarray,
                device_id: str = "") -> RULPrediction:
        """é¢„æµ‹RUL"""
        if not self.is_trained:
            raise ValueError("Model not trained")
        
        # æ ‡å‡†åŒ–
        seq_reshaped = sequence. reshape(-1, self.n_features)
        seq_scaled = self.scaler.transform(seq_reshaped)
        seq_scaled = seq_scaled.reshape(1, self.sequence_length, self.n_features)
        
        # é¢„æµ‹
        predicted_rul = float(self.model. predict(seq_scaled, verbose=0)[0, 0])
        
        # è®¡ç®—ä¸ç¡®å®šæ€§ï¼ˆä½¿ç”¨MC Dropoutï¼‰
        predictions = []
        for _ in range(100):
            pred = self.model(seq_scaled, training=True)  # å¯ç”¨dropout
            predictions.append(float(pred[0, 0]))
        
        mean_pred = np. mean(predictions)
        std_pred = np.std(predictions)
        confidence_interval = (
            max(0, mean_pred - 1.96 * std_pred),
            mean_pred + 1.96 * std_pred
        )
        
        # è®¡ç®—å¥åº·æŒ‡æ•°
        health_index = self._calculate_health_index(sequence)
        
        # è®¡ç®—é€€åŒ–é€Ÿç‡
        degradation_rate = self._calculate_degradation_rate(sequence)
        
        # ç¡®å®šé£é™©ç­‰çº§
        risk_level = self._determine_risk_level(predicted_rul, health_index)
        
        # æ¨èè¡ŒåŠ¨
        recommended_action = self._get_recommended_action(risk_level, predicted_rul)
        
        return RULPrediction(
            device_id=device_id,
            predicted_rul=max(0, predicted_rul),
            confidence_interval=confidence_interval,
            health_index=health_index,
            degradation_rate=degradation_rate,
            prediction_time=datetime.now(),
            risk_level=risk_level,
            recommended_action=recommended_action,
            model_confidence=1 - (std_pred / mean_pred) if mean_pred > 0 else 0
        )
    
    def _calculate_health_index(self, sequence: np.ndarray) -> float:
        """è®¡ç®—å¥åº·æŒ‡æ•°"""
        # åŸºäºç‰¹å¾è®¡ç®—ç»¼åˆå¥åº·æŒ‡æ•°
        latest = sequence[-1]
        
        # å‡è®¾å‰å‡ ä¸ªç‰¹å¾æ˜¯å…³é”®å¥åº·æŒ‡æ ‡
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„è®¡ç®—æ–¹æ³•
        normalized_features = np.clip(latest / np.max(np.abs(sequence), axis=0), 0, 1)
        health_index = float(1 - np.mean(normalized_features[:5]))
        
        return max(0, min(1, health_index))
    
    def _calculate_degradation_rate(self, sequence: np.ndarray) -> float:
        """è®¡ç®—é€€åŒ–é€Ÿç‡"""
        # ä½¿ç”¨çº¿æ€§å›å½’è®¡ç®—è¶‹åŠ¿æ–œç‡
        from scipy import stats
        
        x = np.arange(len(sequence))
        
        # è®¡ç®—ç¬¬ä¸€ä¸ªç‰¹å¾çš„è¶‹åŠ¿
        slope, _, _, _, _ = stats.linregress(x, sequence[:, 0])
        
        return float(slope)
    
    def _determine_risk_level(self, rul: float, health_index: float) -> str:
        """ç¡®å®šé£é™©ç­‰çº§"""
        if rul < 24 or health_index < 0.3:
            return "critical"
        elif rul < 72 or health_index < 0.5:
            return "high"
        elif rul < 168 or health_index < 0.7:
            return "medium"
        else:
            return "low"
    
    def _get_recommended_action(self, risk_level: str, rul: float) -> str:
        """è·å–æ¨èè¡ŒåŠ¨"""
        actions = {
            "critical": f"ç«‹å³å®‰æ’æ£€ä¿®ï¼Œé¢„è®¡å‰©ä½™å¯¿å‘½ä»…{rul:. 0f}å°æ—¶",
            "high": f"å°½å¿«å®‰æ’ç»´æŠ¤ï¼Œé¢„è®¡å‰©ä½™å¯¿å‘½çº¦{rul:.0f}å°æ—¶",
            "medium": f"è®¡åˆ’ä¸‹æ¬¡åœæœºæ—¶ç»´æŠ¤ï¼Œé¢„è®¡å‰©ä½™å¯¿å‘½çº¦{rul:. 0f}å°æ—¶",
            "low": f"ç»§ç»­ç›‘æµ‹ï¼Œè®¾å¤‡çŠ¶æ€è‰¯å¥½ï¼Œé¢„è®¡å‰©ä½™å¯¿å‘½çº¦{rul:.0f}å°æ—¶"
        }
        return actions.get(risk_level, "ç»§ç»­ç›‘æµ‹")


class TransformerRULPredictor:
    """Transformerå‰©ä½™å¯¿å‘½é¢„æµ‹å™¨"""
    
    def __init__(self, sequence_length: int = 50,
                 n_features: int = 14,
                 d_model: int = 64,
                 num_heads: int = 4,
                 num_layers: int = 2):
        self.sequence_length = sequence_length
        self. n_features = n_features
        self.d_model = d_model
        self.num_heads = num_heads
        self.num_layers = num_layers
        self.model = None
        self.scaler = None
        self.is_trained = False
    
    def build_model(self):
        """æ„å»ºTransformeræ¨¡å‹"""
        inputs = Input(shape=(self. sequence_length, self.n_features))
        
        # çº¿æ€§æŠ•å½±åˆ°d_modelç»´åº¦
        x = Dense(self. d_model)(inputs)
        
        # ä½ç½®ç¼–ç 
        positions = tf.range(start=0, limit=self.sequence_length, delta=1)
        position_embedding = self._positional_encoding(
            self.sequence_length, self.d_model
        )
        x = x + position_embedding
        
        # Transformerç¼–ç å™¨å±‚
        for _ in range(self. num_layers):
            # å¤šå¤´è‡ªæ³¨æ„åŠ›
            attention_output = MultiHeadAttention(
                num_heads=self. num_heads,
                key_dim=self. d_model // self.num_heads
            )(x, x)
            x = LayerNormalization()(x + attention_output)
            
            # å‰é¦ˆç½‘ç»œ
            ff_output = Dense(self.d_model * 4, activation='relu')(x)
            ff_output = Dense(self.d_model)(ff_output)
            x = LayerNormalization()(x + ff_output)
        
        # å…¨å±€å¹³å‡æ± åŒ–
        x = GlobalAveragePooling1D()(x)
        
        # è¾“å‡ºå±‚
        x = Dense(32, activation='relu')(x)
        x = Dropout(0.1)(x)
        outputs = Dense(1, activation='linear')(x)
        
        self.model = Model(inputs, outputs)
        self.model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        
        return self.model
    
    def _positional_encoding(self, seq_length: int, d_model: int) -> tf.Tensor:
        """ä½ç½®ç¼–ç """
        positions = np.arange(seq_length)[:, np.newaxis]
        dimensions = np.arange(d_model)[np.newaxis, :]
        
        angles = positions / np.power(10000, (2 * (dimensions // 2)) / d_model)
        
        # å¶æ•°ä½ç½®ä½¿ç”¨sinï¼Œå¥‡æ•°ä½ç½®ä½¿ç”¨cos
        angles[:, 0::2] = np.sin(angles[:, 0::2])
        angles[:, 1::2] = np.cos(angles[:, 1::2])
        
        return tf.constant(angles[np.newaxis, :, :], dtype=tf.float32)
    
    def train(self, X_train: np.ndarray, y_train: np.ndarray,
              epochs: int = 100, batch_size: int = 32):
        """è®­ç»ƒæ¨¡å‹"""
        if self.model is None:
            self.build_model()
        
        from sklearn.preprocessing import StandardScaler
        
        n_samples, seq_len, n_features = X_train. shape
        X_reshaped = X_train.reshape(-1, n_features)
        
        self.scaler = StandardScaler()
        X_scaled = self.scaler.fit_transform(X_reshaped)
        X_scaled = X_scaled.reshape(n_samples, seq_len, n_features)
        
        history = self.model. fit(
            X_scaled, y_train,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=0.1,
            callbacks=[
                tf. keras.callbacks.EarlyStopping(patience=10),
                tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)
            ],
            verbose=1
        )
        
        self.is_trained = True
        return history
    
    def predict(self, sequence: np.ndarray,
                device_id: str = "") -> RULPrediction:
        """é¢„æµ‹RUL"""
        if not self.is_trained:
            raise ValueError("Model not trained")
        
        seq_reshaped = sequence.reshape(-1, self.n_features)
        seq_scaled = self. scaler.transform(seq_reshaped)
        seq_scaled = seq_scaled.reshape(1, self.sequence_length, self.n_features)
        
        predicted_rul = float(self.model. predict(seq_scaled, verbose=0)[0, 0])
        
        # ç®€åŒ–çš„å¥åº·æŒ‡æ•°è®¡ç®—
        health_index = max(0, min(1, predicted_rul / 1000))
        
        risk_level = self._determine_risk_level(predicted_rul)
        
        return RULPrediction(
            device_id=device_id,
            predicted_rul=max(0, predicted_rul),
            confidence_interval=(predicted_rul * 0.8, predicted_rul * 1.2),
            health_index=health_index,
            degradation_rate=0.0,
            prediction_time=datetime.now(),
            risk_level=risk_level,
            recommended_action=self._get_action(risk_level),
            model_confidence=0.85
        )
    
    def _determine_risk_level(self, rul: float) -> str:
        if rul < 24:
            return "critical"
        elif rul < 72:
            return "high"
        elif rul < 168:
            return "medium"
        return "low"
    
    def _get_action(self, risk_level: str) -> str:
        actions = {
            "critical": "ç«‹å³å®‰æ’æ£€ä¿®",
            "high": "å°½å¿«å®‰æ’ç»´æŠ¤",
            "medium": "è®¡åˆ’ç»´æŠ¤",
            "low": "ç»§ç»­ç›‘æµ‹"
        }
        return actions.get(risk_level, "ç»§ç»­ç›‘æµ‹")


class HealthIndexCalculator:
    """å¥åº·æŒ‡æ•°è®¡ç®—å™¨"""
    
    def __init__(self, weights: Dict[str, float] = None):
        self.weights = weights or {}
        self.baseline_values: Dict[str, Dict] = {}
    
    def set_baseline(self, feature_name: str,
                     normal_range: Tuple[float, float],
                     critical_range: Tuple[float, float]):
        """è®¾ç½®åŸºçº¿"""
        self.baseline_values[feature_name] = {
            "normal_min": normal_range[0],
            "normal_max": normal_range[1],
            "critical_min": critical_range[0],
            "critical_max": critical_range[1]
        }
    
    def calculate(self, current_values: Dict[str, float]) -> Dict:
        """è®¡ç®—å¥åº·æŒ‡æ•°"""
        feature_scores = {}
        total_weight = 0
        weighted_sum = 0
        
        for feature, value in current_values. items():
            if feature in self.baseline_values:
                score = self._calculate_feature_score(feature, value)
                feature_scores[feature] = score
                
                weight = self.weights. get(feature, 1.0)
                weighted_sum += score * weight
                total_weight += weight
        
        overall_health = weighted_sum / total_weight if total_weight > 0 else 1.0
        
        return {
            "overall_health
~~~

~~~
# health_index. py - å¥åº·æŒ‡æ•°è®¡ç®—å™¨ï¼ˆç»­ï¼‰
class HealthIndexCalculator:
    """å¥åº·æŒ‡æ•°è®¡ç®—å™¨"""
    
    def __init__(self, weights: Dict[str, float] = None):
        self.weights = weights or {}
        self.baseline_values: Dict[str, Dict] = {}
        self.degradation_models: Dict[str, any] = {}
    
    def set_baseline(self, feature_name: str,
                     normal_range: Tuple[float, float],
                     critical_range: Tuple[float, float]):
        """è®¾ç½®åŸºçº¿"""
        self. baseline_values[feature_name] = {
            "normal_min": normal_range[0],
            "normal_max": normal_range[1],
            "critical_min": critical_range[0],
            "critical_max": critical_range[1]
        }
    
    def calculate(self, current_values: Dict[str, float]) -> Dict:
        """è®¡ç®—å¥åº·æŒ‡æ•°"""
        feature_scores = {}
        total_weight = 0
        weighted_sum = 0
        
        for feature, value in current_values.items():
            if feature in self.baseline_values:
                score = self._calculate_feature_score(feature, value)
                feature_scores[feature] = {
                    "value": value,
                    "score": score,
                    "status": self._get_status(score)
                }
                
                weight = self.weights.get(feature, 1. 0)
                weighted_sum += score * weight
                total_weight += weight
        
        overall_health = weighted_sum / total_weight if total_weight > 0 else 1. 0
        
        # ç¡®å®šæ•´ä½“çŠ¶æ€
        if overall_health >= 0.8:
            overall_status = "healthy"
            risk_level = "low"
        elif overall_health >= 0.6:
            overall_status = "attention"
            risk_level = "medium"
        elif overall_health >= 0.4:
            overall_status = "warning"
            risk_level = "high"
        else:
            overall_status = "critical"
            risk_level = "critical"
        
        return {
            "overall_health": round(overall_health, 4),
            "overall_status": overall_status,
            "risk_level": risk_level,
            "feature_scores": feature_scores,
            "calculation_time": datetime. now().isoformat(),
            "recommendations": self._generate_recommendations(feature_scores, overall_health)
        }
    
    def _calculate_feature_score(self, feature: str, value: float) -> float:
        """è®¡ç®—å•ä¸ªç‰¹å¾å¾—åˆ†"""
        baseline = self.baseline_values[feature]
        
        normal_min = baseline["normal_min"]
        normal_max = baseline["normal_max"]
        critical_min = baseline["critical_min"]
        critical_max = baseline["critical_max"]
        
        # åœ¨æ­£å¸¸èŒƒå›´å†…ï¼Œå¾—åˆ†ä¸º1
        if normal_min <= value <= normal_max:
            return 1.0
        
        # åœ¨æ­£å¸¸å’Œä¸´ç•Œä¹‹é—´ï¼Œçº¿æ€§æ’å€¼
        if value < normal_min:
            if value <= critical_min:
                return 0.0
            return (value - critical_min) / (normal_min - critical_min)
        else:  # value > normal_max
            if value >= critical_max:
                return 0.0
            return (critical_max - value) / (critical_max - normal_max)
    
    def _get_status(self, score: float) -> str:
        """è·å–çŠ¶æ€"""
        if score >= 0.8:
            return "good"
        elif score >= 0.6:
            return "attention"
        elif score >= 0. 4:
            return "warning"
        else:
            return "critical"
    
    def _generate_recommendations(self, feature_scores: Dict,
                                  overall_health: float) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        # æ‰¾å‡ºå¾—åˆ†æœ€ä½çš„ç‰¹å¾
        critical_features = [
            (name, data) for name, data in feature_scores. items()
            if data["score"] < 0.6
        ]
        
        critical_features.sort(key=lambda x: x[1]["score"])
        
        for name, data in critical_features[:3]:  # æœ€å¤š3ä¸ªå»ºè®®
            if data["status"] == "critical":
                recommendations. append(
                    f"ã€ç´§æ€¥ã€‘{name}æŒ‡æ ‡ä¸¥é‡å¼‚å¸¸(å½“å‰å€¼:{data['value']:. 2f})ï¼Œ"
                    f"å»ºè®®ç«‹å³æ£€æŸ¥"
                )
            elif data["status"] == "warning":
                recommendations. append(
                    f"ã€è­¦å‘Šã€‘{name}æŒ‡æ ‡å¼‚å¸¸(å½“å‰å€¼:{data['value']:.2f})ï¼Œ"
                    f"å»ºè®®å°½å¿«æ£€æŸ¥"
                )
            else:
                recommendations.append(
                    f"ã€æ³¨æ„ã€‘{name}æŒ‡æ ‡éœ€è¦å…³æ³¨(å½“å‰å€¼:{data['value']:.2f})"
                )
        
        if overall_health < 0.4:
            recommendations.insert(0, "ã€ç´§æ€¥ã€‘è®¾å¤‡æ•´ä½“å¥åº·çŠ¶æ€ä¸¥é‡ä¸‹é™ï¼Œå»ºè®®ç«‹å³å®‰æ’æ£€ä¿®")
        elif overall_health < 0.6:
            recommendations.insert(0, "ã€è­¦å‘Šã€‘è®¾å¤‡å¥åº·çŠ¶æ€ä¸‹é™ï¼Œå»ºè®®è¿‘æœŸå®‰æ’ç»´æŠ¤")
        
        return recommendations


class DegradationAnalyzer:
    """é€€åŒ–åˆ†æå™¨"""
    
    def __init__(self):
        self.history_data: Dict[str, List[Dict]] = {}
        self.degradation_models: Dict[str, Dict] = {}
    
    def add_data_point(self, device_id: str, health_index: float,
                       timestamp: datetime):
        """æ·»åŠ æ•°æ®ç‚¹"""
        if device_id not in self.history_data:
            self.history_data[device_id] = []
        
        self.history_data[device_id].append({
            "health_index": health_index,
            "timestamp": timestamp
        })
        
        # ä¿ç•™æœ€è¿‘1000ä¸ªç‚¹
        if len(self.history_data[device_id]) > 1000:
            self.history_data[device_id] = self. history_data[device_id][-1000:]
    
    def analyze_degradation(self, device_id: str) -> Dict:
        """åˆ†æé€€åŒ–è¶‹åŠ¿"""
        history = self.history_data.get(device_id, [])
        
        if len(history) < 10:
            return {
                "status": "insufficient_data",
                "message": "æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†æé€€åŒ–è¶‹åŠ¿"
            }
        
        # æå–æ•°æ®
        health_values = [d["health_index"] for d in history]
        timestamps = [d["timestamp"] for d in history]
        
        # è½¬æ¢æ—¶é—´ä¸ºå°æ—¶æ•°
        start_time = timestamps[0]
        hours = [(t - start_time).total_seconds() / 3600 for t in timestamps]
        
        # æ‹Ÿåˆé€€åŒ–æ¨¡å‹
        degradation_model = self._fit_degradation_model(hours, health_values)
        
        # é¢„æµ‹åˆ°è¾¾ä¸´ç•Œå€¼çš„æ—¶é—´
        time_to_threshold = self._predict_time_to_threshold(
            degradation_model, health_values[-1], threshold=0.3
        )
        
        return {
            "status": "analyzed",
            "current_health": health_values[-1],
            "degradation_rate": degradation_model["rate"],
            "degradation_type": degradation_model["type"],
            "time_to_threshold_hours": time_to_threshold,
            "r_squared": degradation_model["r_squared"],
            "trend": "degrading" if degradation_model["rate"] < 0 else "stable",
            "prediction_confidence": degradation_model["confidence"]
        }
    
    def _fit_degradation_model(self, hours: List[float],
                               health_values: List[float]) -> Dict:
        """æ‹Ÿåˆé€€åŒ–æ¨¡å‹"""
        from scipy import stats
        from scipy.optimize import curve_fit
        import numpy as np
        
        hours_arr = np.array(hours)
        health_arr = np. array(health_values)
        
        # å°è¯•çº¿æ€§æ¨¡å‹
        slope, intercept, r_value, p_value, std_err = stats.linregress(
            hours_arr, health_arr
        )
        linear_r2 = r_value ** 2
        
        # å°è¯•æŒ‡æ•°æ¨¡å‹: h(t) = a * exp(-b * t) + c
        try:
            def exp_model(t, a, b, c):
                return a * np.exp(-b * t) + c
            
            popt, pcov = curve_fit(
                exp_model, hours_arr, health_arr,
                p0=[1, 0.001, 0],
                maxfev=5000
            )
            
            exp_predictions = exp_model(hours_arr, *popt)
            ss_res = np. sum((health_arr - exp_predictions) ** 2)
            ss_tot = np.sum((health_arr - np. mean(health_arr)) ** 2)
            exp_r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
            
        except:
            exp_r2 = 0
        
        # é€‰æ‹©æ›´å¥½çš„æ¨¡å‹
        if exp_r2 > linear_r2 and exp_r2 > 0. 7:
            return {
                "type": "exponential",
                "rate": -popt[1],
                "parameters": {"a": popt[0], "b": popt[1], "c": popt[2]},
                "r_squared": exp_r2,
                "confidence": min(exp_r2, 0.95)
            }
        else:
            return {
                "type": "linear",
                "rate": slope,
                "parameters": {"slope": slope, "intercept": intercept},
                "r_squared": linear_r2,
                "confidence": min(linear_r2, 0.95)
            }
    
    def _predict_time_to_threshold(self, model: Dict,
                                   current_health: float,
                                   threshold: float) -> float:
        """é¢„æµ‹åˆ°è¾¾é˜ˆå€¼çš„æ—¶é—´"""
        if model["type"] == "linear":
            slope = model["parameters"]["slope"]
            if slope >= 0:
                return float('inf')  # ä¸ä¼šåˆ°è¾¾é˜ˆå€¼
            
            time_to_threshold = (threshold - current_health) / slope
            return max(0, time_to_threshold)
        
        elif model["type"] == "exponential":
            import numpy as np
            
            a = model["parameters"]["a"]
            b = model["parameters"]["b"]
            c = model["parameters"]["c"]
            
            if threshold <= c:
                return float('inf')
            
            try:
                time_to_threshold = -np.log((threshold - c) / a) / b
                return max(0, time_to_threshold)
            except:
                return float('inf')
        
        return float('inf')
~~~

## 7.å¤„ç½®å»ºè®®ç”Ÿæˆå™¨

~~~
# suggestion_generator.py - å¤„ç½®å»ºè®®ç”Ÿæˆå™¨
from typing import Dict, List, Optional
from dataclasses import dataclass, field
from datetime import datetime
import json

@dataclass
class MaintenanceAction:
    """ç»´æŠ¤è¡ŒåŠ¨"""
    action_id: str
    action_type: str          # inspection, repair, replacement, adjustment
    priority: int             # 1-5, 1æœ€é«˜
    description: str
    detailed_steps: List[str]
    estimated_duration: float  # å°æ—¶
    required_resources: List[str]
    required_skills: List[str]
    safety_precautions: List[str]
    spare_parts: List[Dict]
    estimated_cost: float

@dataclass
class TreatmentSuggestion:
    """å¤„ç½®å»ºè®®"""
    suggestion_id: str
    fault_id: str
    device_id: str
    summary: str
    urgency: str              # immediate, urgent, scheduled, monitor
    actions: List[MaintenanceAction]
    estimated_downtime: float  # å°æ—¶
    risk_if_delayed: str
    similar_cases: List[Dict]
    generated_at: datetime
    confidence: float


class SuggestionGenerator:
    """å¤„ç½®å»ºè®®ç”Ÿæˆå™¨"""
    
    def __init__(self, knowledge_base, llm_client=None):
        self.knowledge_base = knowledge_base
        self.llm_client = llm_client
        self.action_templates: Dict[str, Dict] = {}
        self._load_action_templates()
    
    def _load_action_templates(self):
        """åŠ è½½è¡ŒåŠ¨æ¨¡æ¿"""
        self.action_templates = {
            "bearing_fault": {
                "actions": [
                    {
                        "type": "inspection",
                        "description": "è½´æ‰¿çŠ¶æ€æ£€æŸ¥",
                        "steps": [
                            "åœæœºå¹¶æ‰§è¡Œå®‰å…¨é”å®šç¨‹åº",
                            "æ‹†é™¤é˜²æŠ¤ç½©ï¼Œç›®è§†æ£€æŸ¥è½´æ‰¿å¤–è§‚",
                            "ä½¿ç”¨æµ‹æŒ¯ä»ªæµ‹é‡è½´æ‰¿æŒ¯åŠ¨",
                            "ä½¿ç”¨çº¢å¤–æµ‹æ¸©ä»ªæ£€æµ‹è½´æ‰¿æ¸©åº¦",
                            "æ£€æŸ¥æ¶¦æ»‘æ²¹å“è´¨å’Œæ²¹ä½"
                        ],
                        "duration": 2. 0,
                        "resources": ["æµ‹æŒ¯ä»ª", "çº¢å¤–æµ‹æ¸©ä»ª", "å·¥å…·ç®±"],
                        "skills": ["æœºæ¢°ç»´ä¿®ä¸­çº§"]
                    },
                    {
                        "type": "replacement",
                        "description": "è½´æ‰¿æ›´æ¢",
                        "steps": [
                            "ç¡®è®¤å¤‡ä»¶å‹å·æ­£ç¡®",
                            "æ‹†é™¤æ—§è½´æ‰¿",
                            "æ¸…æ´è½´æ‰¿åº§",
                            "å®‰è£…æ–°è½´æ‰¿",
                            "åŠ æ³¨æ¶¦æ»‘è„‚",
                            "è¯•è¿è¡ŒéªŒè¯"
                        ],
                        "duration": 4.0,
                        "resources": ["è½´æ‰¿æ‹‰æ‹”å™¨", "åŠ çƒ­å™¨", "æ¶¦æ»‘è„‚"],
                        "skills": ["æœºæ¢°ç»´ä¿®é«˜çº§"],
                        "spare_parts": [{"name": "è½´æ‰¿", "quantity": 1}]
                    }
                ],
                "safety": [
                    "ç¡®ä¿è®¾å¤‡å·²åœæœºå¹¶æ–­ç”µ",
                    "æ‚¬æŒ‚è­¦ç¤ºç‰Œ",
                    "ä½©æˆ´é˜²æŠ¤æ‰‹å¥—å’ŒæŠ¤ç›®é•œ"
                ]
            },
            "overheating": {
                "actions": [
                    {
                        "type": "inspection",
                        "description": "å†·å´ç³»ç»Ÿæ£€æŸ¥",
                        "steps": [
                            "æ£€æŸ¥å†·å´æ°´æµé‡å’Œå‹åŠ›",
                            "æ£€æŸ¥å†·å´æ°´æ¸©åº¦",
                            "æ£€æŸ¥æ•£çƒ­å™¨/æ¢çƒ­å™¨æ˜¯å¦å µå¡",
                            "æ£€æŸ¥é£æ‰‡è¿è¡ŒçŠ¶æ€",
                            "æ£€æŸ¥æ¸©åº¦ä¼ æ„Ÿå™¨å‡†ç¡®æ€§"
                        ],
                        "duration": 1.5,
                        "resources": ["æµé‡è®¡", "æ¸©åº¦è®¡"],
                        "skills": ["ä»ªè¡¨ç»´ä¿®åˆçº§"]
                    },
                    {
                        "type": "adjustment",
                        "description": "å†·å´å‚æ•°è°ƒæ•´",
                        "steps": [
                            "å¢åŠ å†·å´æ°´æµé‡",
                            "è°ƒæ•´æ¸©åº¦æ§åˆ¶è®¾å®šå€¼",
                            "æ¸…æ´—æ•£çƒ­å™¨è¡¨é¢"
                        ],
                        "duration": 1.0,
                        "resources": ["æ¸…æ´—è®¾å¤‡"],
                        "skills": ["æ“ä½œå·¥"]
                    }
                ],
                "safety": [
                    "æ³¨æ„é«˜æ¸©çƒ«ä¼¤é£é™©",
                    "ä½©æˆ´éš”çƒ­æ‰‹å¥—"
                ]
            },
            "vibration_high": {
                "actions": [
                    {
                        "type": "inspection",
                        "description": "æŒ¯åŠ¨åŸå› æ’æŸ¥",
                        "steps": [
                            "ä½¿ç”¨é¢‘è°±åˆ†æä»ªé‡‡é›†æŒ¯åŠ¨æ•°æ®",
                            "åˆ†ææŒ¯åŠ¨é¢‘è°±ç‰¹å¾",
                            "æ£€æŸ¥åŸºç¡€èºæ “ç´§å›ºæƒ…å†µ",
                            "æ£€æŸ¥è”è½´å™¨å¯¹ä¸­çŠ¶æ€",
                            "æ£€æŸ¥è½¬å­å¹³è¡¡çŠ¶æ€"
                        ],
                        "duration": 3.0,
                        "resources": ["é¢‘è°±åˆ†æä»ª", "å¯¹ä¸­ä»ª", "åŠ›çŸ©æ‰³æ‰‹"],
                        "skills": ["æŒ¯åŠ¨åˆ†æå¸ˆ"]
                    }
                ],
                "safety": [
                    "åœ¨è®¾å¤‡è¿è¡Œæ—¶ä¿æŒå®‰å…¨è·ç¦»",
                    "ä½©æˆ´å¬åŠ›ä¿æŠ¤è£…ç½®"
                ]
            },
            "leakage": {
                "actions": [
                    {
                        "type": "inspection",
                        "description": "æ³„æ¼ç‚¹å®šä½",
                        "steps": [
                            "ç›®è§†æ£€æŸ¥ç®¡è·¯å’Œè¿æ¥ç‚¹",
                            "ä½¿ç”¨æ£€æ¼ä»ªå®šä½æ³„æ¼ç‚¹",
                            "è¯„ä¼°æ³„æ¼ç¨‹åº¦",
                            "è®°å½•æ³„æ¼ä½ç½®å’Œä»‹è´¨"
                        ],
                        "duration": 1. 0,
                        "resources": ["æ£€æ¼ä»ª", "æ ‡è®°ç¬”"],
                        "skills": ["ç®¡é“å·¥åˆçº§"]
                    },
                    {
                        "type": "repair",
                        "description": "æ³„æ¼ä¿®å¤",
                        "steps": [
                            "éš”ç¦»æ³„æ¼ç®¡æ®µ",
                            "æ³„å‹æ’ç©º",
                            "æ›´æ¢å¯†å°ä»¶æˆ–ä¿®å¤ç®¡é“",
                            "æ¢å¤ç³»ç»Ÿå¹¶è¯•å‹"
                        ],
                        "duration": 2.0,
                        "resources": ["å¯†å°ä»¶", "ç®¡é“å·¥å…·"],
                        "skills": ["ç®¡é“å·¥ä¸­çº§"],
                        "spare_parts": [{"name": "å¯†å°å«", "quantity": 1}]
                    }
                ],
                "safety": [
                    "äº†è§£æ³„æ¼ä»‹è´¨ç‰¹æ€§",
                    "ä½©æˆ´é€‚å½“çš„é˜²æŠ¤è£…å¤‡",
                    "ç¡®ä¿é€šé£è‰¯å¥½"
                ]
            }
        }
    
    async def generate_suggestion(self, diagnosis_result: DiagnosisResult,
                                  context: Dict = None) -> TreatmentSuggestion:
        """ç”Ÿæˆå¤„ç½®å»ºè®®"""
        fault_type = diagnosis_result. fault_type
        device_id = diagnosis_result.device_id
        severity = diagnosis_result. severity
        
        # 1. è·å–åŸºç¡€è¡ŒåŠ¨æ¨¡æ¿
        template = self.action_templates.get(fault_type, {})
        
        # 2. æœç´¢ç›¸ä¼¼æ¡ˆä¾‹
        similar_cases = await self._search_similar_cases(
            fault_type, device_id, diagnosis_result.evidence
        )
        
        # 3. æ„å»ºç»´æŠ¤è¡ŒåŠ¨åˆ—è¡¨
        actions = self._build_actions(template, severity, context)
        
        # 4. ç¡®å®šç´§æ€¥ç¨‹åº¦
        urgency = self._determine_urgency(severity, diagnosis_result.confidence)
        
        # 5. ç”Ÿæˆç»¼åˆå»ºè®®æ‘˜è¦
        summary = await self._generate_summary(
            diagnosis_result, actions, similar_cases
        )
        
        # 6.  è¯„ä¼°å»¶è¿Ÿé£é™©
        risk_if_delayed = self._assess_delay_risk(fault_type, severity)
        
        # 7. è®¡ç®—é¢„è®¡åœæœºæ—¶é—´
        estimated_downtime = sum(a.estimated_duration for a in actions)
        
        return TreatmentSuggestion(
            suggestion_id=f"SUG-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            fault_id=diagnosis_result. fault_id,
            device_id=device_id,
            summary=summary,
            urgency=urgency,
            actions=actions,
            estimated_downtime=estimated_downtime,
            risk_if_delayed=risk_if_delayed,
            similar_cases=similar_cases,
            generated_at=datetime.now(),
            confidence=diagnosis_result.confidence
        )
    
    def _build_actions(self, template: Dict, severity: str,
                       context: Dict = None) -> List[MaintenanceAction]:
        """æ„å»ºç»´æŠ¤è¡ŒåŠ¨"""
        actions = []
        action_templates = template.get("actions", [])
        safety_precautions = template. get("safety", [])
        
        for i, action_template in enumerate(action_templates):
            # æ ¹æ®ä¸¥é‡ç¨‹åº¦è°ƒæ•´ä¼˜å…ˆçº§
            if severity == "critical":
                priority = 1
            elif severity == "major":
                priority = 2
            elif severity == "minor":
                priority = 3
            else:
                priority = 4
            
            action = MaintenanceAction(
                action_id=f"ACT-{i+1:03d}",
                action_type=action_template["type"],
                priority=priority,
                description=action_template["description"],
                detailed_steps=action_template["steps"],
                estimated_duration=action_template["duration"],
                required_resources=action_template. get("resources", []),
                required_skills=action_template.get("skills", []),
                safety_precautions=safety_precautions,
                spare_parts=action_template.get("spare_parts", []),
                estimated_cost=self._estimate_cost(action_template)
            )
            actions.append(action)
        
        return actions
    
    async def _search_similar_cases(self, fault_type: str,
                                    device_id: str,
                                    evidence: List[Dict]) -> List[Dict]:
        """æœç´¢ç›¸ä¼¼æ¡ˆä¾‹"""
        # æ„å»ºæŸ¥è¯¢
        query = f"æ•…éšœç±»å‹:{fault_type} è®¾å¤‡:{device_id}"
        
        # ä»çŸ¥è¯†åº“æœç´¢
        cases = await self.knowledge_base.search(
            query=query,
            knowledge_type="case",
            top_k=5
        )
        
        # æ ¼å¼åŒ–ç»“æœ
        similar_cases = []
        for case in cases:
            similar_cases.append({
                "case_id": case. get("id"),
                "title": case.get("title"),
                "similarity": case.get("score", 0),
                "resolution": case.get("content", {}).get("resolution", ""),
                "lessons_learned": case.get("content", {}). get("lessons_learned", [])
            })
        
        return similar_cases
    
    async def _generate_summary(self, diagnosis: DiagnosisResult,
                                actions: List[MaintenanceAction],
                                similar_cases: List[Dict]) -> str:
        """ç”Ÿæˆå»ºè®®æ‘˜è¦"""
        if self.llm_client:
            # ä½¿ç”¨LLMç”Ÿæˆè‡ªç„¶è¯­è¨€æ‘˜è¦
            prompt = f"""
æ ¹æ®ä»¥ä¸‹è¯Šæ–­ç»“æœç”Ÿæˆå¤„ç½®å»ºè®®æ‘˜è¦ï¼š

æ•…éšœç±»å‹ï¼š{diagnosis.fault_type}
æ•…éšœåç§°ï¼š{diagnosis. fault_name}
ä¸¥é‡ç¨‹åº¦ï¼š{diagnosis.severity}
ç½®ä¿¡åº¦ï¼š{diagnosis.confidence:. 1%}

è¯æ®ï¼š
{json.dumps(diagnosis. evidence, ensure_ascii=False, indent=2)}

å»ºè®®è¡ŒåŠ¨ï¼š
{chr(10).join([f"- {a.description}" for a in actions])}

ç›¸ä¼¼æ¡ˆä¾‹æ•°é‡ï¼š{len(similar_cases)}

è¯·ç”Ÿæˆä¸€æ®µç®€æ´çš„å¤„ç½®å»ºè®®æ‘˜è¦ï¼ˆ100å­—ä»¥å†…ï¼‰ï¼š
"""
            summary = await self.llm_client.generate(prompt)
            return summary. strip()
        else:
            # æ¨¡æ¿åŒ–æ‘˜è¦
            return (
                f"æ£€æµ‹åˆ°{diagnosis.fault_name}ï¼Œä¸¥é‡ç¨‹åº¦ä¸º{diagnosis.severity}ï¼Œ"
                f"ç½®ä¿¡åº¦{diagnosis.confidence:.1%}ã€‚"
                f"å»ºè®®æ‰§è¡Œä»¥ä¸‹{len(actions)}é¡¹ç»´æŠ¤è¡ŒåŠ¨ï¼š"
                f"{', '.join([a.description for a in actions[:3]])}ã€‚"
                f"å‚è€ƒ{len(similar_cases)}ä¸ªç›¸ä¼¼å†å²æ¡ˆä¾‹ã€‚"
            )
    
    def _determine_urgency(self, severity: str, confidence: float) -> str:
        """ç¡®å®šç´§æ€¥ç¨‹åº¦"""
        if severity == "critical" and confidence > 0.8:
            return "immediate"
        elif severity == "critical" or (severity == "major" and confidence > 0.8):
            return "urgent"
        elif severity == "major" or severity == "minor":
            return "scheduled"
        else:
            return "monitor"
    
    def _assess_delay_risk(self, fault_type: str, severity: str) -> str:
        """è¯„ä¼°å»¶è¿Ÿé£é™©"""
        risk_matrix = {
            ("bearing_fault", "critical"): "å¯èƒ½å¯¼è‡´è½´æ‰¿æŠ±æ­»ï¼Œé€ æˆè®¾å¤‡ä¸¥é‡æŸåå’Œé•¿æ—¶é—´åœæœº",
            ("bearing_fault", "major"): "è½´æ‰¿ç£¨æŸåŠ å‰§ï¼Œå¯èƒ½å‘å±•ä¸ºä¸¥é‡æ•…éšœ",
            ("overheating", "critical"): "å¯èƒ½å¯¼è‡´è®¾å¤‡æŸåã€ç«ç¾é£é™©",
            ("overheating", "major"): "åŠ é€Ÿè®¾å¤‡è€åŒ–ï¼Œç¼©çŸ­ä½¿ç”¨å¯¿å‘½",
            ("vibration_high", "critical"): "å¯èƒ½å¯¼è‡´ç»“æ„æŸåã€å®‰å…¨äº‹æ•…",
            ("vibration_high", "major"): "åŠ é€Ÿéƒ¨ä»¶ç£¨æŸï¼Œå¢åŠ ç»´ä¿®æˆæœ¬",
            ("leakage", "critical"): "å¯èƒ½å¯¼è‡´ç¯å¢ƒæ±¡æŸ“ã€å®‰å…¨äº‹æ•…",
            ("leakage", "major"): "ä»‹è´¨æŸå¤±å¢åŠ ï¼Œå¯èƒ½å½±å“ç”Ÿäº§"
        }
        
        return risk_matrix.get(
            (fault_type, severity),
            "å»¶è¿Ÿå¤„ç†å¯èƒ½å¯¼è‡´é—®é¢˜æ¶åŒ–ï¼Œå»ºè®®å°½å¿«å®‰æ’ç»´æŠ¤"
        )
    
    def _estimate_cost(self, action_template: Dict) -> float:
        """ä¼°ç®—æˆæœ¬"""
        # åŸºäºå·¥æ—¶ä¼°ç®—äººå·¥æˆæœ¬
        labor_rate = 100  # å…ƒ/å°æ—¶
        labor_cost = action_template["duration"] * labor_rate
        
        # å¤‡ä»¶æˆæœ¬ï¼ˆç®€åŒ–ä¼°ç®—ï¼‰
        parts_cost = 0
        for part in action_template.get("spare_parts", []):
            parts_cost += part. get("estimated_price", 500) * part.get("quantity", 1)
        
        return labor_cost + parts_cost
~~~

## 8.è¯Šæ–­è°ƒåº¦å™¨ä¸APIæ¥å£

### 8.1 è¯Šæ–­è°ƒåº¦å™¨

~~~
# diagnosis_orchestrator.py - è¯Šæ–­è°ƒåº¦å™¨
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import asyncio
from enum import Enum

class DiagnosisMode(Enum):
    """è¯Šæ–­æ¨¡å¼"""
    REALTIME = "realtime"      # å®æ—¶è¯Šæ–­
    SCHEDULED = "scheduled"    # å®šæ—¶è¯Šæ–­
    ON_DEMAND = "on_demand"    # æŒ‰éœ€è¯Šæ–­

@dataclass
class DiagnosisTask:
    """è¯Šæ–­ä»»åŠ¡"""
    task_id: str
    device_id: str
    mode: DiagnosisMode
    priority: int
    created_at: datetime
    status: str
    result: Optional[Dict] = None


class DiagnosisOrchestrator:
    """è¯Šæ–­è°ƒåº¦å™¨"""
    
    def __init__(self, config: Dict):
        self.config = config
        
        # åˆå§‹åŒ–å„å¼•æ“
        self.rule_engine = RuleDiagnosisEngine(config. get("rule_repository"))
        self. ml_engine = MLDiagnosisEngine(config.get("model_registry"))
        self. anomaly_engine = AnomalyDetectionEngine(config. get("anomaly_config", {}))
        self.rca_engine = KnowledgeGraphRCA(config.get("graph_connection"))
        self. rul_predictor = LSTMRULPredictor()
        self.health_calculator = HealthIndexCalculator()
        self.suggestion_generator = SuggestionGenerator(
            config.get("knowledge_base"),
            config.get("llm_client")
        )
        
        # ä»»åŠ¡é˜Ÿåˆ—
        self.task_queue: asyncio.Queue = asyncio.Queue()
        self.results_cache: Dict[str, Dict] = {}
        
        # è¿è¡ŒçŠ¶æ€
        self. is_running = False
    
    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        self.is_running = True
        
        # å¯åŠ¨å·¥ä½œåç¨‹
        asyncio.create_task(self._process_tasks())
        asyncio.create_task(self._realtime_monitor())
    
    async def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self.is_running = False
    
    async def submit_task(self, device_id: str,
                         mode: DiagnosisMode = DiagnosisMode.ON_DEMAND,
                         priority: int = 5) -> str:
        """æäº¤è¯Šæ–­ä»»åŠ¡"""
        task = DiagnosisTask(
            task_id=f"TASK-{datetime.now().strftime('%Y%m%d%H%M%S%f')}",
            device_id=device_id,
            mode=mode,
            priority=priority,
            created_at=datetime.now(),
            status="pending"
        )
        
        await self.task_queue.put((priority, task))
        return task.task_id
    
    async def _process_tasks(self):
        """å¤„ç†ä»»åŠ¡é˜Ÿåˆ—"""
        while self.is_running:
            try:
                # è·å–ä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼‰
                priority, task = await asyncio. wait_for(
                    self.task_queue.get(),
                    timeout=1.0
                )
                
                # æ‰§è¡Œè¯Šæ–­
                result = await self._execute_diagnosis(task)
                
                # ç¼“å­˜ç»“æœ
                self.results_cache[task.task_id] = result
                
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                print(f"Task processing error: {e}")
    
    async def _realtime_monitor(self):
        """å®æ—¶ç›‘æ§"""
        while self. is_running:
            try:
                # è·å–æ‰€æœ‰è®¾å¤‡çš„å®æ—¶æ•°æ®
                # è¿™é‡Œéœ€è¦ä¸DCSæ•°æ®é‡‡é›†æ¨¡å—é›†æˆ
                await asyncio.sleep(1)  # 1ç§’é—´éš”
                
            except Exception as e:
                print(f"Realtime monitor error: {e}")
    
    async def _execute_diagnosis(self, task: DiagnosisTask) -> Dict:
        """æ‰§è¡Œè¯Šæ–­"""
        device_id = task. device_id
        
        # 1. è·å–è®¾å¤‡æ•°æ®
        device_data = await self._get_device_data(device_id)
        
        # 2. å¹¶è¡Œæ‰§è¡Œå¤šç§è¯Šæ–­
        diagnosis_tasks = [
            self._run_rule_diagnosis(device_data),
            self._run_ml_diagnosis(device_data),
            self._run_anomaly_detection(device_data),
            self._run_health_assessment(device_data),
            self._run_rul_prediction(device_data)
        ]
        
        results = await asyncio. gather(*diagnosis_tasks, return_exceptions=True)
        
        rule_results, ml_results, anomaly_results, health_result, rul_result = results
        
        # 3.  èåˆè¯Šæ–­ç»“æœ
        fused_results = self._fuse_results(
            rule_results if not isinstance(rule_results, Exception) else [],
            ml_results if not isinstance(ml_results, Exception) else [],
            anomaly_results if not isinstance(anomaly_results, Exception) else {}
        )
        
        # 4. æ ¹å› åˆ†æï¼ˆå¦‚æœæœ‰æ•…éšœï¼‰
        root_causes = []
        if fused_results:
            symptoms = [r.fault_type for r in fused_results]
            root_causes = self. rca_engine.analyze_root_cause(
                symptoms, context=device_data
            )
        
        # 5.  ç”Ÿæˆå¤„ç½®å»ºè®®
        suggestions = []
        for diagnosis in fused_results:
            suggestion = await self. suggestion_generator.generate_suggestion(
                diagnosis, context=device_data
            )
            suggestions.append(suggestion)
        
        return {
            "task_id": task. task_id,
            "device_id": device_id,
            "timestamp": datetime.now(). isoformat(),
            "diagnosis_results": [self._serialize_result(r) for r in fused_results],
            "root_cause_analysis": [self._serialize_rca(r) for r in root_causes],
            "health_assessment": health_result if not isinstance(health_result, Exception) else None,
            "rul_prediction": self._serialize_rul(rul_result) if not isinstance(rul_result, Exception) else None,
            "suggestions": [self._serialize_suggestion(s) for s in suggestions],
            "status": "completed"
        }
    
    async def _get_device_data(self, device_id: str) -> Dict:
        """è·å–è®¾å¤‡æ•°æ®"""
        # è¿™é‡Œéœ€è¦ä¸DCSæ•°æ®é‡‡é›†æ¨¡å—é›†æˆ
        # è¿”å›æ¨¡æ‹Ÿæ•°æ®
        return {
            "device_id": device_id,
            "current_values": {
                "vibration": 5.2,
                "temperature": 72.5,
                "pressure": 2.3,
                "flow_rate": 120. 5,
                "current": 45.2
            },
            "features": {
                "vibration_rms": 5.2,
                "vibration_peak": 8.1,
                "temperature_trend": 0.5,
                "pressure_variance": 0.02
            },
            "sequence_data": None,  # æ—¶åºæ•°æ®
            "alarms": [],
            "maintenance_history": {}
        }
    
    async def _run_rule_diagnosis(self, data: Dict) -> List[DiagnosisResult]:
        """è¿è¡Œè§„åˆ™è¯Šæ–­"""
        return await self.rule_engine.diagnose(data)
    
    async def _run_ml_diagnosis(self, data: Dict) -> List[DiagnosisResult]:
        """è¿è¡ŒMLè¯Šæ–­"""
        results = []
        features = data.get("features", {})
        
        if features:
            feature_array = np.array(list(features.values()))
            result = await self.ml_engine.diagnose("default_model", features)
            if result:
                results.append(result)
        
        return results
    
    async def _run_anomaly_detection(self, data: Dict) -> Dict:
        """è¿è¡Œå¼‚å¸¸æ£€æµ‹"""
        results = {}
        current_values = data.get("current_values", {})
        features = data.get("features", {})
        
        for tag, value in current_values.items():
            feature_array = np.array(list(features.values())) if features else None
            result = self.anomaly_engine.detect(
                tag, value, feature_array, datetime.now()
            )
            results[tag] = result
        
        return results
    
    async def _run_health_assessment(self, data: Dict) -> Dict:
        """è¿è¡Œå¥åº·è¯„ä¼°"""
        current_values = data. get("current_values", {})
        return self.health_calculator. calculate(current_values)
    
    async def _run_rul_prediction(self, data: Dict) -> Optional[RULPrediction]:
        """è¿è¡ŒRULé¢„æµ‹"""
        sequence_data = data. get("sequence_data")
        
        if sequence_data is not None and self.rul_predictor.is_trained:
            return self.rul_predictor.predict(
                sequence_data,
                device_id=data. get("device_id", "")
            )
        
        return None
    
    def _fuse_results(self, rule_results: List,
                     ml_results: List,
                     anomaly_results: Dict) -> List[DiagnosisResult]:
        """èåˆè¯Šæ–­ç»“æœ"""
        all_results = []
        
        # æ·»åŠ è§„åˆ™è¯Šæ–­ç»“æœ
        all_results.extend(rule_results)
        
        # æ·»åŠ MLè¯Šæ–­ç»“æœ
        all_results.extend(ml_results)
        
        # å¦‚æœæœ‰å¤šä¸ªå¼‚å¸¸ï¼Œåˆ›å»ºç»¼åˆå¼‚å¸¸è¯Šæ–­
        anomaly_tags = [
            tag for tag, result in anomaly_results. items()
            if result. get("is_anomaly", False)
        ]
        
        if len(anomaly_tags) >= 2:
            # å¤šå‚æ•°å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯ç³»ç»Ÿæ€§é—®é¢˜
            combined_score = np.mean([
                anomaly_results[tag]["anomaly_score"]
                for tag in anomaly_tags
            ])
            
            all_results.append(DiagnosisResult(
                fault_id=f"ANOMALY-MULTI-{datetime.now().strftime('%Y%m%d%H%M%S')}",
                fault_type="multiple_anomaly",
                fault_name="å¤šå‚æ•°å¼‚å¸¸",
                device_id="",
                confidence=combined_score,
                severity="major" if combined_score > 0.7 else "minor",
                evidence=[{"anomaly_tags": anomaly_tags}],
                suggestion="æ£€æµ‹åˆ°å¤šä¸ªå‚æ•°å¼‚å¸¸ï¼Œå»ºè®®ç»¼åˆæ£€æŸ¥",
                timestamp=datetime.now(),
                source="anomaly_fusion"
            ))
        
        # å»é‡å’Œæ’åº
        unique_results = self._deduplicate_results(all_results)
        unique_results. sort(key=lambda x: x.confidence, reverse=True)
        
        return unique_results
    
    def _deduplicate_results(self, results: List[DiagnosisResult]) -> List[DiagnosisResult]:
        """ç»“æœå»é‡"""
        seen = set()
        unique = []
        
        for result in results:
            key = (result.fault_type, result. device_id)
            if key not in seen:
                seen. add(key)
                unique.append(result)
            else:
                # ä¿ç•™ç½®ä¿¡åº¦æ›´é«˜çš„
                for i, existing in enumerate(unique):
                    if (existing.fault_type, existing.device_id) == key:
                        if result.confidence > existing.confidence:
                            unique[i] = result
                        break
        
        return unique
    
    def _serialize_result(self, result: DiagnosisResult) -> Dict:
        """åºåˆ—åŒ–è¯Šæ–­ç»“æœ"""
        return {
            "fault_id": result.fault_id,
            "fault_type": result.fault_type,
            "fault_name": result.fault_name,
            "device_id": result.device_id,
            "confidence": result.confidence,
            "severity": result.severity,
            "evidence": result.evidence,
            "suggestion": result.suggestion,
            "timestamp": result.timestamp. isoformat(),
            "source": result.source
        }
    
    def _serialize_rca(self, rca: RootCauseCandidate) -> Dict:
        """åºåˆ—åŒ–æ ¹å› åˆ†æç»“æœ"""
        return {
            "cause_id": rca.cause_id,
            "cause_name": rca.cause_name,
            "cause_type": rca.cause_type,
            "confidence": rca.confidence,
            "evidence_chain": rca.evidence_chain,
            "propagation_path": rca.propagation_path,
            "supporting_facts": rca.supporting_facts
        }
    
    def _serialize_rul(self, rul: RULPrediction) -> Dict:
        """åºåˆ—åŒ–RULé¢„æµ‹ç»“æœ"""
        return {
            "device_id": rul.device_id,
            "predicted_rul_hours": rul.predicted_rul,
            "confidence_interval": rul.confidence_interval,
            "health_index": rul.health_index,
            "degradation_rate": rul.degradation_rate,
            "risk_level": rul.risk_level,
            "recommended_action": rul.recommended_action,
            "prediction_time": rul.prediction_time. isoformat()
        }
    
    def _serialize_suggestion(self, suggestion: TreatmentSuggestion) -> Dict:
        """åºåˆ—åŒ–å¤„ç½®å»ºè®®"""
        return {
            "suggestion_id": suggestion.suggestion_id,
            "summary": suggestion.summary,
            "urgency": suggestion.urgency,
            "actions": [
                {
                    "action_id": a.action_id,
                    "action_type": a. action_type,
                    "priority": a.priority,
                    "description": a.description,
                    "steps": a.detailed_steps,
                    "duration_hours": a.estimated_duration,
                    "resources": a.required_resources,
                    "safety": a.safety_precautions
                }
                for a in suggestion.actions
            ],
            "estimated_downtime_hours": suggestion.estimated_downtime,
            "risk_if_delayed": suggestion.risk_if_delayed,
            "similar_cases": suggestion. similar_cases[:3]
        }
~~~

### 8.2 APIæ¥å£

~~~
# api/diagnosis_api.py - è¯Šæ–­APIæ¥å£
from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict
from datetime import datetime
import asyncio

app = FastAPI(
    title="DCSæ•…éšœè¯Šæ–­ä¸é¢„æµ‹API",
    description="æä¾›å®æ—¶æ•…éšœè¯Šæ–­ã€æ ¹å› åˆ†æã€RULé¢„æµ‹ç­‰æœåŠ¡",
    version="1.0. 0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€è¯Šæ–­è°ƒåº¦å™¨å®ä¾‹
orchestrator: DiagnosisOrchestrator = None

# ============ è¯·æ±‚/å“åº”æ¨¡å‹ ============

class DiagnosisRequest(BaseModel):
    """è¯Šæ–­è¯·æ±‚"""
    device_id: str = Field(..., description="è®¾å¤‡ID")
    mode: str = Field("on_demand", description="è¯Šæ–­æ¨¡å¼: realtime, scheduled, on_demand")
    priority: int = Field(5, ge=1, le=10, description="ä¼˜å…ˆçº§, 1æœ€é«˜")
    context: Optional[Dict] = Field(None, description="é™„åŠ ä¸Šä¸‹æ–‡")

class DiagnosisResponse(BaseModel):
    """è¯Šæ–­å“åº”"""
    task_id: str
    status: str
    message: str

class DiagnosisResultResponse(BaseModel):
    """è¯Šæ–­ç»“æœå“åº”"""
    task_id: str
    device_id: str
    timestamp: str
    status: str
    diagnosis_results: List[Dict]
    root_cause_analysis: List[Dict]
    health_assessment: Optional[Dict]
    rul_prediction: Optional[Dict]
    suggestions: List[Dict]

class HealthCheckRequest(BaseModel):
    """å¥åº·æ£€æŸ¥è¯·æ±‚"""
    device_id: str
    current_values: Dict[str, float]

class HealthCheckResponse(BaseModel):
    """å¥åº·æ£€æŸ¥å“åº”"""
    device_id: str
    overall_health: float
    overall_status: str
    risk_level: str
    feature_scores: Dict
    recommendations: List[str]

class RULPredictionRequest(BaseModel):
    """RULé¢„æµ‹è¯·æ±‚"""
    device_id: str
    sequence_data: List[List[float]] = Field(... , description="æ—¶åºç‰¹å¾æ•°æ®")

class RULPredictionResponse(BaseModel):
    """RULé¢„æµ‹å“åº”"""
    device_id: str
    predicted_rul_hours: float
    confidence_interval: List[float]
    health_index: float
    risk_level: str
    recommended_action: str

class AlarmAnalysisRequest(BaseModel):
    """æŠ¥è­¦åˆ†æè¯·æ±‚"""
    device_id: str
    alarms: List[Dict]
    time_window_minutes: int = 30

class AlarmAnalysisResponse(BaseModel):
    """æŠ¥è­¦åˆ†æå“åº”"""
    device_id: str
    alarm_count: int
    root_causes: List[Dict]
    suggestions: List[str]

# ============ APIç«¯ç‚¹ ============

@app.on_event("startup")
async def startup():
    """åº”ç”¨å¯åŠ¨"""
    global orchestrator
    
    config = {
        "rule_repository": None,  # å®é™…é¡¹ç›®ä¸­æ³¨å…¥
        "model_registry": None,
        "graph_connection": None,
        "knowledge_base": None,
        "llm_client": None,
        "anomaly_config": {
            "window_size": 100,
            "contamination": 0.1
        }
    }
    
    orchestrator = DiagnosisOrchestrator(config)
    await orchestrator.start()

@app. on_event("shutdown")
async def shutdown():
    """åº”ç”¨å…³é—­"""
    if orchestrator:
        await orchestrator.stop()

@app. get("/health")
async def health_check():
    """æœåŠ¡å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime. now().isoformat(),
        "version": "1.0.0"
    }

@app. post("/api/v1/diagnosis/submit", response_model=DiagnosisResponse)
async def submit_diagnosis(request: DiagnosisRequest,
                          background_tasks: BackgroundTasks):
    """æäº¤è¯Šæ–­ä»»åŠ¡"""
    try:
        mode = DiagnosisMode(request.mode)
    except ValueError:
        mode = DiagnosisMode.ON_DEMAND
    
    task_id = await orchestrator.submit_task(
        device_id=request. device_id,
        mode=mode,
        priority=request.priority
    )
    
    return DiagnosisResponse(
        task_id=task_id,
        status="submitted",
        message=f"è¯Šæ–­ä»»åŠ¡å·²æäº¤ï¼Œä»»åŠ¡ID: {task_id}"
    )

@app.get("/api/v1/diagnosis/result/{task_id}", response_model=DiagnosisResultResponse)
async def get_diagnosis_result(task_id: str):
    """è·å–è¯Šæ–­ç»“æœ"""
    result = orchestrator.results_cache.get(task_id)
    
    if not result:
        raise HTTPException(
            status_code=404,
            detail=f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨æˆ–å°šæœªå®Œæˆ"
        )
    
    return DiagnosisResultResponse(**result)

@app.post("/api/v1/diagnosis/realtime")
async def realtime_diagnosis(request: DiagnosisRequest):
    """å®æ—¶è¯Šæ–­ï¼ˆåŒæ­¥è¿”å›ç»“æœï¼‰"""
    # æäº¤ä»»åŠ¡
    task_id = await orchestrator.submit_task(
        device_id=request.device_id,
        mode=DiagnosisMode.ON_DEMAND,
        priority=1  # æœ€é«˜ä¼˜å…ˆçº§
    )
    
    # ç­‰å¾…ç»“æœï¼ˆæœ€å¤š30ç§’ï¼‰
    for _ in range(30):
        result = orchestrator.results_cache.get(task_id)
        if result and result.get("status") == "completed":
            return result
        await asyncio.sleep(1)
    
    raise HTTPException(
        status_code=408,
        detail="è¯Šæ–­è¶…æ—¶ï¼Œè¯·ç¨åæŸ¥è¯¢ç»“æœ"
    )

@app.post("/api/v1/health/check", response_model=HealthCheckResponse)
async def check_device_health(request: HealthCheckRequest):
    """è®¾å¤‡å¥åº·æ£€æŸ¥"""
    result = orchestrator.health_calculator.calculate(request.current_values)
    
    return HealthCheckResponse(
        device_id=request.device_id,
        overall_health=result["overall_health"],
        overall_status=result["overall_status"],
        risk_level=result["risk_level"],
        feature_scores=result["feature_scores"],
        recommendations=result["recommendations"]
    )

@app. post("/api/v1/prediction/rul", response_model=RULPredictionResponse)
async def predict_rul(request: RULPredictionRequest):
    """RULé¢„æµ‹"""
    import numpy as np
    
    sequence = np.array(request. sequence_data)
    
    if not orchestrator.rul_predictor.is_trained:
        raise HTTPException(
            status_code=400,
            detail="RULæ¨¡å‹å°šæœªè®­ç»ƒ"
        )
    
    result = orchestrator. rul_predictor. predict(
        sequence,
        device_id=request.device_id
    )
    
    return RULPredictionResponse(
        device_id=result.device_id,
        predicted_rul_hours=result. predicted_rul,
        confidence_interval=list(result.confidence_interval),
        health_index=result. health_index,
        risk_level=result.risk_level,
        recommended_action=result.recommended_action
    )

@app.post("/api/v1/alarm/analyze", response_model=AlarmAnalysisResponse)
async def analyze_alarms(request: AlarmAnalysisRequest):
    """æŠ¥è­¦åˆ†æ"""
    # æå–æŠ¥è­¦ç—‡çŠ¶
    symptoms = [alarm.get("alarm_type", "") for alarm in request. alarms]
    
    # æ ¹å› åˆ†æ
    root_causes = orchestrator.rca_engine.analyze_root_cause(
        symptoms,
        context={"device_id": request.device_id}
    )
    
    # ç”Ÿæˆå»ºè®®
    suggestions = []
    for rca in root_causes[:3]:
        suggestions.append(
            f"å¯èƒ½åŸå› : {rca. cause_name} (ç½®ä¿¡åº¦: {rca.confidence:.1%})"
        )
    
    return AlarmAnalysisResponse(
        device_id=request. device_id,
        alarm_count=len(request.alarms),
        root_causes=[orchestrator._serialize_rca(r) for r in root_causes[:5]],
        suggestions=suggestions
    )

@app.get("/api/v1/devices/{device_id}/status")
async def get_device_status(device_id: str):
    """è·å–è®¾å¤‡çŠ¶æ€"""
    # è·å–æœ€è¿‘çš„è¯Šæ–­ç»“æœ
    recent_results = [
        result for task_id, result in orchestrator.results_cache.items()
        if result.get("device_id") == device_id
    ]
    
    if not recent_results:
        return {
            "device_id": device_id,
            "status": "unknown",
            "message": "æš‚æ— è¯Šæ–­æ•°æ®"
        }
    
    # è·å–æœ€æ–°ç»“æœ
    latest = sorted(recent_results, key=lambda x: x.get("timestamp", ""), reverse=True)[0]
    
    # ç¡®å®šçŠ¶æ€
    has_faults = len(latest.get("diagnosis_results", [])) > 0
    health = latest.get("health_assessment", {})
    
    return {
        "device_id": device_id,
        "status": "fault" if has_faults else health.get("overall_status", "unknown"),
        "health_index": health.get("overall_health", None),
        "risk_level": health. get("risk_level", "unknown"),
        "active_faults": len(latest.get("diagnosis_results", [])),
        "last_diagnosis": latest.get("timestamp"),
        "rul_prediction": latest.get("rul_prediction")
    }

@app.get("/api/v1/statistics/overview")
async def get_statistics_overview():
    """è·å–ç»Ÿè®¡æ¦‚è§ˆ"""
    all_results = list(orchestrator.results_cache.values())
    
    total_diagnoses = len(all_results)
    total_faults = sum(
        len(r.get("diagnosis_results", []))
        for r in all_results
    )
    
    # æŒ‰æ•…éšœç±»å‹ç»Ÿè®¡
    fault_types = {}
    for result in all_results:
        for diagnosis in result.get("diagnosis_results", []):
            ft = diagnosis.get("fault_type", "unknown")
            fault_types[ft] = fault_types. get(ft, 0) + 1
    
    return {
        "total_diagnoses": total_diagnoses,
        "total_faults_detected": total_faults,
        "fault_type_distribution": fault_types,
        "cache_size": len(orchestrator.results_cache),
        "timestamp": datetime.now(). isoformat()
    }
~~~

## 9.è½åœ°å®æ–½æ–¹æ¡ˆ

### 9.1 å®æ–½è·¯çº¿å›¾

~~~
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ•…éšœè¯Šæ–­ä¸é¢„æµ‹ç³»ç»Ÿå®æ–½è·¯çº¿å›¾                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  Phase 1: åŸºç¡€å»ºè®¾ (ç¬¬1-4å‘¨)                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Week 1-2: ç¯å¢ƒæ­å»ºä¸æ•°æ®å¯¹æ¥                                             â”‚   â”‚
â”‚  â”‚ â€¢ éƒ¨ç½²å¼€å‘/æµ‹è¯•ç¯å¢ƒ                                                      â”‚   â”‚
â”‚  â”‚ â€¢ DCSæ•°æ®é‡‡é›†é€šé“å¯¹æ¥ï¼ˆOPC UA/Modbusï¼‰                                   â”‚   â”‚
â”‚  â”‚ â€¢ æ—¶åºæ•°æ®åº“éƒ¨ç½²ï¼ˆInfluxDBï¼‰                                             â”‚   â”‚
â”‚  â”‚ â€¢ æ•°æ®è´¨é‡è¯„ä¼°                                                           â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚ Week 3-4: æ•°æ®é¢„å¤„ç†ä¸ç‰¹å¾å·¥ç¨‹                                           â”‚   â”‚
â”‚  â”‚ â€¢ æ•°æ®æ¸…æ´—æ¨¡å—å¼€å‘                                                       â”‚   â”‚
â”‚  â”‚ â€¢ ç‰¹å¾è®¡ç®—æ¨¡å—å¼€å‘                                                       â”‚   â”‚
â”‚  â”‚ â€¢ å†å²æ•°æ®å¯¼å…¥                                                           â”‚   â”‚
â”‚  â”‚ â€¢ ç‰¹å¾åº“å»ºè®¾                                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                        â”‚
â”‚                                       â–¼                                        â”‚
â”‚  Phase 2: è¯Šæ–­èƒ½åŠ›å»ºè®¾ (ç¬¬5-10å‘¨)                                               â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Week 5-6: è§„åˆ™è¯Šæ–­å¼•æ“                                                   â”‚   â”‚
â”‚  â”‚ â€¢ è¯Šæ–­è§„åˆ™æ¢³ç†ä¸å»ºæ¨¡                                                     â”‚   â”‚
â”‚  â”‚ â€¢ è§„åˆ™å¼•æ“å¼€å‘                                                           â”‚   â”‚
â”‚  â”‚ â€¢ æ•…éšœæ ‘å»ºæ¨¡                                                             â”‚   â”‚
â”‚  â”‚ â€¢ è§„åˆ™æµ‹è¯•ä¸éªŒè¯                                                         â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚ Week 7-8: æœºå™¨å­¦ä¹ è¯Šæ–­                                                   â”‚   â”‚
â”‚  â”‚ â€¢ å†å²æ•…éšœæ•°æ®æ ‡æ³¨                                                       â”‚   â”‚
â”‚  â”‚ â€¢ åˆ†ç±»æ¨¡å‹è®­ç»ƒï¼ˆRF/XGBoostï¼‰                                             â”‚   â”‚
â”‚  â”‚ â€¢ å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒ                                                       â”‚   â”‚
â”‚  â”‚ â€¢ æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–                                                         â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚ Week 9-10: æ ¹å› åˆ†æå¼•æ“                                                  â”‚   â”‚
â”‚  â”‚ â€¢ çŸ¥è¯†å›¾è°±å»ºæ¨¡                                                           â”‚   â”‚
â”‚  â”‚ â€¢ å› æœå…³ç³»æ¢³ç†                                                           â”‚   â”‚
â”‚  â”‚ â€¢ æ ¹å› æ¨ç†ç®—æ³•å¼€å‘                                                       â”‚   â”‚
â”‚  â”‚ â€¢ æ¡ˆä¾‹åº“å»ºè®¾                                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                        â”‚
â”‚                                       â–¼                                        â”‚
â”‚  Phase 3: é¢„æµ‹èƒ½åŠ›å»ºè®¾ (ç¬¬11-14å‘¨)                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Week 11-12: RULé¢„æµ‹æ¨¡å‹                                                  â”‚   â”‚
â”‚  â”‚ â€¢ é€€åŒ–æ•°æ®æ”¶é›†ä¸æ ‡æ³¨                                                     â”‚   â”‚
â”‚  â”‚ â€¢ LSTM/Transformeræ¨¡å‹å¼€å‘                                               â”‚   â”‚
â”‚  â”‚ â€¢ æ¨¡å‹è®­ç»ƒä¸éªŒè¯                                                         â”‚   â”‚
â”‚  â”‚ â€¢ å¥åº·æŒ‡æ•°è®¡ç®—æ¨¡å—                                                       â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚ Week 13-14: å¤„ç½®å»ºè®®ç”Ÿæˆ                                                 â”‚   â”‚
â”‚  â”‚ â€¢ ç»´æŠ¤çŸ¥è¯†åº“å»ºè®¾                                                         â”‚   â”‚
â”‚  â”‚ â€¢ å»ºè®®ç”Ÿæˆæ¨¡å—å¼€å‘                                                       â”‚   â”‚
â”‚  â”‚ â€¢ LLMé›†æˆï¼ˆå¯é€‰ï¼‰                                                        â”‚   â”‚
â”‚  â”‚ â€¢ å»ºè®®è´¨é‡è¯„ä¼°                                                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                        â”‚
â”‚                                       â–¼                                        â”‚
â”‚  Phase 4: é›†æˆä¸ä¸Šçº¿ (ç¬¬15-18å‘¨)                                                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Week 15-16: ç³»ç»Ÿé›†æˆ                                                     â”‚   â”‚
â”‚  â”‚ â€¢ è¯Šæ–­è°ƒåº¦å™¨å¼€å‘                                                         â”‚   â”‚
â”‚  â”‚ â€¢ APIæœåŠ¡å¼€å‘                                                            â”‚   â”‚
â”‚  â”‚ â€¢ å‰ç«¯çœ‹æ¿å¼€å‘                                                           â”‚   â”‚
â”‚  â”‚ â€¢ ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ                                                         â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚ Week 17-18: æµ‹è¯•ä¸ä¸Šçº¿                                                   â”‚   â”‚
â”‚  â”‚ â€¢ åŠŸèƒ½æµ‹è¯•                                                               â”‚   â”‚
â”‚  â”‚ â€¢ æ€§èƒ½æµ‹è¯•                                                               â”‚   â”‚
â”‚  â”‚ â€¢ ç”¨æˆ·éªŒæ”¶æµ‹è¯•                                                           â”‚   â”‚
â”‚  â”‚ â€¢ ç°åº¦ä¸Šçº¿                                                               â”‚   â”‚
â”‚  â”‚ â€¢ åŸ¹è®­ä¸æ–‡æ¡£äº¤ä»˜                                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
~~~

### 9.2 å…³é”®äº¤ä»˜ç‰©æ¸…å•
|é˜¶æ®µ|äº¤ä»˜ç‰©|è¯´æ˜|
|---|---|---|
|**Phase 1**|æ•°æ®é‡‡é›†æ¨¡å—|OPC UA/Modbusæ•°æ®é‡‡é›†ã€æ•°æ®é¢„å¤„ç†|
||ç‰¹å¾å·¥ç¨‹æ¨¡å—|ç»Ÿè®¡ç‰¹å¾ã€è¶‹åŠ¿ç‰¹å¾ã€é¢‘åŸŸç‰¹å¾è®¡ç®—|
||æ—¶åºæ•°æ®åº“|InfluxDBéƒ¨ç½²ã€æ•°æ®æ¨¡å‹è®¾è®¡|
|**Phase 2**|è§„åˆ™è¯Šæ–­å¼•æ“|è§„åˆ™åº“ï¼ˆâ‰¥50æ¡ï¼‰ã€æ•…éšœæ ‘ï¼ˆâ‰¥10æ£µï¼‰|
||MLè¯Šæ–­å¼•æ“|åˆ†ç±»æ¨¡å‹ã€å¼‚å¸¸æ£€æµ‹æ¨¡å‹|
||æ ¹å› åˆ†æå¼•æ“|çŸ¥è¯†å›¾è°±ã€å› æœæ¨ç†ç®—æ³•|
|**Phase 3**|RULé¢„æµ‹æ¨¡å‹|LSTM/Transformeræ¨¡å‹|
||å¥åº·è¯„ä¼°æ¨¡å—|å¥åº·æŒ‡æ•°è®¡ç®—ã€é€€åŒ–åˆ†æ|
||å¤„ç½®å»ºè®®ç”Ÿæˆå™¨|çŸ¥è¯†åº“ã€å»ºè®®ç”Ÿæˆç®—æ³•|
|**Phase 4**|APIæœåŠ¡|REST APIã€WebSocket|
||è¯Šæ–­çœ‹æ¿|Webå‰ç«¯ã€å¯è§†åŒ–|
||ç”¨æˆ·æ–‡æ¡£|ç”¨æˆ·æ‰‹å†Œã€APIæ–‡æ¡£ã€è¿ç»´æ‰‹å†Œ|
### 9.3 é¢„æœŸæ•ˆæœæŒ‡æ ‡
|æŒ‡æ ‡|ç›®æ ‡å€¼|éªŒæ”¶æ–¹æ³•|
|---|---|---|
|æ•…éšœè¯Šæ–­å‡†ç¡®ç‡|â‰¥85%|100ä¸ªå†å²æ•…éšœæ¡ˆä¾‹éªŒè¯|
|æ•…éšœæ¼æŠ¥ç‡|â‰¤5%|1ä¸ªæœˆå®é™…è¿è¡Œç»Ÿè®¡|
|æ•…éšœè¯¯æŠ¥ç‡|â‰¤15%|1ä¸ªæœˆå®é™…è¿è¡Œç»Ÿè®¡|
|æ ¹å› å®šä½å‡†ç¡®ç‡|â‰¥75%|50ä¸ªæ•…éšœæ¡ˆä¾‹äººå·¥è¯„ä¼°|
|RULé¢„æµ‹è¯¯å·®|â‰¤20%|å¯¹æ¯”å®é™…æ•…éšœ|
# 4.DCSè¿è¡ŒAgentæ ·æœºÂ -Â 1-2äººç²¾ç®€å®ç°æ–¹æ¡ˆ
## ä¸€ã€æ–¹æ¡ˆè°ƒæ•´è¯´æ˜

é’ˆå¯¹1-2äººå›¢é˜Ÿã€ä¸€å¹´å‘¨æœŸçš„å®é™…æƒ…å†µï¼Œé‡‡ç”¨ä»¥ä¸‹ç­–ç•¥ï¼š

|åŸæ–¹æ¡ˆ|ç²¾ç®€æ–¹æ¡ˆ|è°ƒæ•´ç†ç”±|
|---|---|---|
|8äººå›¢é˜Ÿ|1-2äºº|å®é™…èµ„æº|
|10ä¸ªæœˆ|12ä¸ªæœˆ|äººåŠ›å‡å°‘ï¼Œå‘¨æœŸæ‹‰é•¿|
|å®Œæ•´ç”Ÿäº§ç³»ç»Ÿ|**å¯æ¼”ç¤ºæ ·æœº**|èšç„¦æ ¸å¿ƒä»·å€¼éªŒè¯|
|è‡ªç ”æ‰€æœ‰æ¨¡å—|**æœ€å¤§åŒ–ä½¿ç”¨ç°æˆå·¥å…·**|å‡å°‘å¼€å‘é‡|
|å¤æ‚å¾®æœåŠ¡æ¶æ„|**å•ä½“åº”ç”¨**|é™ä½å¤æ‚åº¦|
|3ä¸ªä¸“ä¸šAgent|**1ä¸ªé€šç”¨Agent**|å…ˆè·‘é€šå†æ‹†åˆ†|
## äºŒã€ç²¾ç®€æŠ€æœ¯æ¶æ„

~~~
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”¨æˆ·ç•Œé¢                                  â”‚
â”‚                  Streamlit / Gradio                             â”‚
â”‚                  (å¿«é€Ÿæ­å»ºï¼Œæ— éœ€å‰ç«¯å¼€å‘)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AgentæœåŠ¡ (å•ä½“åº”ç”¨)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              LangChain Agent + RAG                       â”‚   â”‚
â”‚  â”‚         æœ¬åœ°LLM (Ollama + Qwen2-7B/14B)                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  æ•°æ®æŸ¥è¯¢å·¥å…· â”‚  â”‚  çŸ¥è¯†æ£€ç´¢å·¥å…· â”‚  â”‚  è¯Šæ–­åˆ†æå·¥å…· â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ•°æ®å±‚ (è½»é‡åŒ–)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   SQLite     â”‚  â”‚  ChromaDB    â”‚  â”‚  CSV/JSON    â”‚         â”‚
â”‚  â”‚  (å†å²æ•°æ®)   â”‚  â”‚  (å‘é‡æ£€ç´¢)   â”‚  â”‚  (æ¨¡æ‹Ÿæ•°æ®)   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ•°æ®é‡‡é›† (ç®€åŒ–)                             â”‚
â”‚         OPC UAæ¨¡æ‹Ÿå™¨ / CSVæ•°æ®å¯¼å…¥ / æ‰‹åŠ¨å½•å…¥                    â”‚
â”‚              (å…ˆè·‘é€šæµç¨‹ï¼ŒåæœŸå†æ¥çœŸå®DCS)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
~~~

## ä¸‰ã€æŠ€æœ¯é€‰å‹ï¼ˆæœ€å°åŒ–åŸåˆ™ï¼‰
|æ¨¡å—|é€‰æ‹©|ç†ç”±|
|---|---|---|
|**LLM**|OllamaÂ +Â Qwen2-7B|ä¸€é”®éƒ¨ç½²ï¼Œèµ„æºå ç”¨å°|
|**Agentæ¡†æ¶**|LangChain|æ–‡æ¡£ä¸°å¯Œï¼Œç¤¾åŒºæ´»è·ƒ|
|**å‘é‡æ•°æ®åº“**|ChromaDB|åµŒå…¥å¼ï¼Œæ— éœ€å•ç‹¬éƒ¨ç½²|
|**æ•°æ®å­˜å‚¨**|SQLite|é›¶é…ç½®ï¼Œæ–‡ä»¶å‹æ•°æ®åº“|
|**Webç•Œé¢**|Streamlit|PythonåŸç”Ÿï¼Œå¿«é€Ÿå¼€å‘|
|**æ•°æ®æ¨¡æ‹Ÿ**|Pythonè„šæœ¬|çµæ´»ç”Ÿæˆæµ‹è¯•æ•°æ®|
|**å¼€å‘ç¯å¢ƒ**|VSÂ CodeÂ +Â Python|æ ‡å‡†å¼€å‘ç¯å¢ƒ|
### ç¡¬ä»¶éœ€æ±‚ï¼ˆæœ€ä½é…ç½®ï¼‰
|é…ç½®|è§„æ ¼|é¢„ç®—|
|---|---|---|
|**å¼€å‘æœºï¼ˆæ¨èï¼‰**|RTXÂ 4090Â 24GÂ +Â 64Gå†…å­˜Â +Â 1TBÂ SSD|2-3ä¸‡|
|**å¼€å‘æœºï¼ˆæœ€ä½ï¼‰**|RTXÂ 3090Â 24GÂ +Â 32Gå†…å­˜Â +Â 512GÂ SSD|1.Â 5ä¸‡|
|**äº‘GPUï¼ˆå¤‡é€‰ï¼‰**|AutoDL/çŸ©æ± äº‘æŒ‰éœ€ç§Ÿç”¨|çº¦5å…ƒ/å°æ—¶|
## å››ã€12ä¸ªæœˆè¯¦ç»†å·¥ä½œè®¡åˆ’
### é˜¶æ®µæ€»è§ˆ

~~~
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  M1-M2  â”‚  M3-M4  â”‚  M5-M6  â”‚  M7-M8  â”‚  M9-M10 â”‚ M11-M12 â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ ç¯å¢ƒæ­å»º â”‚ æ•°æ®å±‚  â”‚ Agent   â”‚ çŸ¥è¯†åº“  â”‚ ç•Œé¢ä¸  â”‚ ä¼˜åŒ–ä¸  â”‚
â”‚ æŠ€æœ¯éªŒè¯ â”‚ å¼€å‘    â”‚ æ ¸å¿ƒ    â”‚ å»ºè®¾    â”‚ é›†æˆ    â”‚ æ¼”ç¤º    â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
~~~

### ç¬¬1-2ä¸ªæœˆï¼šç¯å¢ƒæ­å»ºä¸æŠ€æœ¯éªŒè¯
#### ç›®æ ‡
- âœ… å¼€å‘ç¯å¢ƒå°±ç»ª
- âœ… æœ¬åœ°LLMå¯è¿è¡Œ
- âœ… éªŒè¯æ ¸å¿ƒæŠ€æœ¯å¯è¡Œæ€§
#### ç¬¬1ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|ç¡¬ä»¶å‡†å¤‡ï¼Œç³»ç»Ÿå®‰è£…|å¼€å‘æœºå°±ç»ª|8h|
|W1|Pythonç¯å¢ƒé…ç½®|è™šæ‹Ÿç¯å¢ƒ|4h|
|W2|Ollamaå®‰è£…ï¼Œæ¨¡å‹ä¸‹è½½|LLMå¯è¿è¡Œ|8h|
|W2|æµ‹è¯•ä¸åŒæ¨¡å‹æ•ˆæœ|æ¨¡å‹è¯„ä¼°æŠ¥å‘Š|16h|
|W3|LangChainåŸºç¡€å­¦ä¹ |å­¦ä¹ ç¬”è®°|20h|
|W3|ç®€å•Agent Demo|å¯è¿è¡ŒDemo|12h|
|W4|ChromaDBéƒ¨ç½²æµ‹è¯•|å‘é‡åº“å¯ç”¨|8h|
|W4|RAGåŸºç¡€æµç¨‹éªŒè¯|RAG Demo|16h|
#### ç¬¬2ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|Embeddingæ¨¡å‹éƒ¨ç½²|æœ¬åœ°Embedding|8h|
|W1|æ–‡æ¡£å‘é‡åŒ–æµ‹è¯•|å‘é‡åŒ–è„šæœ¬|12h|
|W2|Agentå·¥å…·è°ƒç”¨å­¦ä¹ |å­¦ä¹ ç¬”è®°|16h|
|W2|è‡ªå®šä¹‰å·¥å…·å¼€å‘æµ‹è¯•|å·¥å…·Demo|16h|
|W3|Streamlitå­¦ä¹ |å­¦ä¹ ç¬”è®°|12h|
|W3|ç®€å•å¯¹è¯ç•Œé¢|UIåŸå‹|12h|
|W4|æŠ€æœ¯éªŒè¯æ€»ç»“|æŠ€æœ¯æŠ¥å‘Š|8h|
|W4|åˆ¶å®šåç»­è¯¦ç»†è®¡åˆ’|è¯¦ç»†è®¡åˆ’|8h|
#### æ ¸å¿ƒä»£ç ï¼šç¯å¢ƒéªŒè¯

#### é‡Œç¨‹ç¢‘M2
~~~
ğŸ¯ é‡Œç¨‹ç¢‘ï¼šæŠ€æœ¯å¯è¡Œæ€§éªŒè¯å®Œæˆ
â”œâ”€â”€ æœ¬åœ°LLMå“åº”æ­£å¸¸ï¼ˆ<5ç§’ï¼‰
â”œâ”€â”€ RAGæ£€ç´¢å¯è¿”å›ç›¸å…³å†…å®¹
â”œâ”€â”€ ç®€å•å¯¹è¯ç•Œé¢å¯äº¤äº’
â””â”€â”€ è¾“å‡ºï¼šæŠ€æœ¯éªŒè¯æŠ¥å‘Š
~~~

### ç¬¬3-4ä¸ªæœˆï¼šæ•°æ®å±‚å¼€å‘
#### ç›®æ ‡
- âœ… å®ŒæˆDCSæ•°æ®æ¨¡æ‹Ÿå™¨
- âœ… å®Œæˆæ•°æ®å­˜å‚¨æ¨¡å—
- âœ… å®Œæˆæ•°æ®æŸ¥è¯¢æ¥å£
#### ç¬¬3ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|è®¾è®¡æ•°æ®æ¨¡å‹|æ•°æ®æ¨¡å‹æ–‡æ¡£|12h|
|W1|DCSç‚¹ä½æ¸…å•æ•´ç†|ç‚¹ä½é…ç½®è¡¨|8h|
|W2|æ•°æ®æ¨¡æ‹Ÿå™¨å¼€å‘|æ¨¡æ‹Ÿå™¨ä»£ç |20h|
|W2|æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ|æµ‹è¯•æ•°æ®é›†|8h|
|W3|SQLiteæ•°æ®åº“è®¾è®¡|æ•°æ®åº“è¡¨ç»“æ„|8h|
|W3|æ•°æ®å­˜å‚¨æ¨¡å—å¼€å‘|å­˜å‚¨ä»£ç |16h|
|W4|æ•°æ®æŸ¥è¯¢æ¥å£å¼€å‘|æŸ¥è¯¢API|16h|
|W4|æ•°æ®å±‚æµ‹è¯•|æµ‹è¯•æŠ¥å‘Š|8h|
#### æ ¸å¿ƒä»£ç ï¼šDCSæ•°æ®æ¨¡æ‹Ÿå™¨

#### ç¬¬4ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|æ•°æ®æŸ¥è¯¢æœåŠ¡å°è£…|æŸ¥è¯¢æœåŠ¡ç±»|16h|
|W1|ç»Ÿè®¡åˆ†æåŠŸèƒ½|ç»Ÿè®¡å‡½æ•°|12h|
|W2|è¶‹åŠ¿æ•°æ®æ¥å£|è¶‹åŠ¿API|12h|
|W2|æŠ¥è­¦æ•°æ®æ¥å£|æŠ¥è­¦API|8h|
|W3|æ•°æ®æœåŠ¡æµ‹è¯•å®Œå–„|æµ‹è¯•ç”¨ä¾‹|12h|
|W3|ç”Ÿæˆ1ä¸ªæœˆæ¨¡æ‹Ÿå†å²æ•°æ®|å†å²æ•°æ®æ–‡ä»¶|8h|
|W4|ç¼–å†™æ•°æ®å±‚æ–‡æ¡£|æ–‡æ¡£|8h|
|W4|ä»£ç é‡æ„ä¼˜åŒ–|ä¼˜åŒ–åä»£ç |12h|
#### æ ¸å¿ƒä»£ç ï¼šæ•°æ®æŸ¥è¯¢æœåŠ¡

#### é‡Œç¨‹ç¢‘M4

~~~
ğŸ¯ é‡Œç¨‹ç¢‘ï¼šæ•°æ®å±‚å®Œæˆ
â”œâ”€â”€ æ¨¡æ‹Ÿå™¨å¯ç”Ÿæˆé€¼çœŸæ•°æ®
â”œâ”€â”€ æ•°æ®å¯å­˜å‚¨å’ŒæŸ¥è¯¢
â”œâ”€â”€ æœ‰1ä¸ªæœˆçš„æ¨¡æ‹Ÿå†å²æ•°æ®
â””â”€â”€ è¾“å‡ºï¼šæ•°æ®å±‚ä»£ç å’Œæ–‡æ¡£
~~~
### ç¬¬5-6ä¸ªæœˆï¼šAgentæ ¸å¿ƒå¼€å‘
#### ç›®æ ‡
- âœ… å®ŒæˆAgentæ¡†æ¶æ­å»º
- âœ… å®ç°æ•°æ®æŸ¥è¯¢ã€çŸ¥è¯†æ£€ç´¢ã€è¯Šæ–­åˆ†æä¸‰å¤§èƒ½åŠ›
- âœ… Agentå¯è¿›è¡ŒåŸºæœ¬å¯¹è¯
#### ç¬¬5ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|Agentæ¡†æ¶è®¾è®¡|è®¾è®¡æ–‡æ¡£|12h|
|W1|æœ¬åœ°LLMå°è£…|LLMå°è£…ç±»|12h|
|W2|æ•°æ®æŸ¥è¯¢å·¥å…·å¼€å‘|Toolä»£ç |16h|
|W2|å·¥å…·è°ƒç”¨æµ‹è¯•|æµ‹è¯•æŠ¥å‘Š|8h|
|W3|çŸ¥è¯†æ£€ç´¢å·¥å…·å¼€å‘|Toolä»£ç |16h|
|W3|Promptå·¥ç¨‹åˆç‰ˆ|Promptæ¨¡æ¿|12h|
|W4|AgentåŸºç¡€ç‰ˆæœ¬|Agent V0.1|16h|
|W4|åŸºç¡€å¯¹è¯æµ‹è¯•|æµ‹è¯•è®°å½•|8h|
#### æ ¸å¿ƒä»£ç ï¼šAgentå®ç°

#### ç¬¬6ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|è¯Šæ–­åˆ†æå·¥å…·å¼€å‘|è¯Šæ–­Tool|20h|
|W1|è¯Šæ–­é€»è¾‘è§„åˆ™ç¼–å†™|è§„åˆ™åº“|12h|
|W2|Promptä¼˜åŒ–è¿­ä»£|ä¼˜åŒ–åPrompt|16h|
|W2|å¤šè½®å¯¹è¯æµ‹è¯•|æµ‹è¯•ç”¨ä¾‹|12h|
|W3|é”™è¯¯å¤„ç†å®Œå–„|å¥å£®æ€§æå‡|12h|
|W3|Agentå“åº”ä¼˜åŒ–|æ€§èƒ½æå‡|12h|
|W4|50ä¸ªé—®é¢˜æµ‹è¯•|æµ‹è¯•æŠ¥å‘Š|16h|
|W4|Agentç‰ˆæœ¬å‘å¸ƒ|V1.0|8h|
#### æ ¸å¿ƒä»£ç ï¼šè¯Šæ–­å·¥å…·
#### é‡Œç¨‹ç¢‘M6
~~~
ğŸ¯ é‡Œç¨‹ç¢‘ï¼šAgentæ ¸å¿ƒå®Œæˆ
â”œâ”€â”€ Agentå¯æ­£å¸¸å¯¹è¯
â”œâ”€â”€ æ•°æ®æŸ¥è¯¢åŠŸèƒ½å¯ç”¨
â”œâ”€â”€ è¯Šæ–­åŠŸèƒ½åŸºæœ¬å¯ç”¨
â”œâ”€â”€ 50ä¸ªæµ‹è¯•é—®é¢˜å‡†ç¡®ç‡>70%
â””â”€â”€ è¾“å‡ºï¼šAgent V1.0
~~~
### ç¬¬7-8ä¸ªæœˆï¼šçŸ¥è¯†åº“å»ºè®¾
#### ç›®æ ‡
- âœ… æ•´ç†æ ¸å¿ƒæ“ä½œè§„ç¨‹ï¼ˆSOPï¼‰
- âœ… å»ºç«‹æ•…éšœæ¡ˆä¾‹åº“
- âœ… RAGæ£€ç´¢æ•ˆæœä¼˜åŒ–
#### ç¬¬7ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|åˆ¶å®šçŸ¥è¯†æ•´ç†è®¡åˆ’|è®¡åˆ’æ–‡æ¡£|8h|
|W1|æ”¶é›†ç°æœ‰SOPæ–‡æ¡£|æ–‡æ¡£æ¸…å•|12h|
|W2|SOPæ–‡æ¡£ç»“æ„åŒ–æ•´ç†|ç»“æ„åŒ–SOPÂ 10ä»½|20h|
|W2|æ–‡æ¡£åˆ†å—ç­–ç•¥è®¾è®¡|åˆ†å—æ–¹æ¡ˆ|8h|
|W3|æ•…éšœæ¡ˆä¾‹æ”¶é›†æ•´ç†|æ¡ˆä¾‹30æ¡|20h|
|W3|æ¡ˆä¾‹æ ‡å‡†åŒ–æ¨¡æ¿|æ¨¡æ¿æ–‡æ¡£|8h|
|W4|çŸ¥è¯†å…¥åº“è„šæœ¬å¼€å‘|å…¥åº“å·¥å…·|16h|
|W4|ç¬¬ä¸€æ‰¹çŸ¥è¯†å…¥åº“|å…¥åº“å®Œæˆ|8h|
#### æ ¸å¿ƒä»£ç ï¼šçŸ¥è¯†åº“ç®¡ç†

#### ç¤ºä¾‹çŸ¥è¯†æ•°æ®

#### ç¬¬8ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|ç»§ç»­æ•´ç†SOPÂ (ç´¯è®¡20ä»½)|SOPæ–‡æ¡£|20h|
|W1|æ•…éšœæ¡ˆä¾‹æ‰©å……Â (ç´¯è®¡50æ¡)|æ¡ˆä¾‹æ–‡æ¡£|16h|
|W2|RAGæ£€ç´¢æ•ˆæœæµ‹è¯•|æµ‹è¯•æŠ¥å‘Š|12h|
|W2|æ£€ç´¢ä¼˜åŒ–ï¼ˆåˆ†å—/é‡æ’ï¼‰|ä¼˜åŒ–ä»£ç |16h|
|W3|AgentçŸ¥è¯†å·¥å…·ä¼˜åŒ–|å·¥å…·ä»£ç |16h|
|W3|çŸ¥è¯†æ£€ç´¢å‡†ç¡®æ€§æµ‹è¯•|æµ‹è¯•ç”¨ä¾‹|12h|
|W4|çŸ¥è¯†åº“ç®¡ç†ç•Œé¢ï¼ˆç®€å•ç‰ˆï¼‰|ç®¡ç†é¡µé¢|16h|
|W4|çŸ¥è¯†åº“æ–‡æ¡£|æ–‡æ¡£|8h|
#### æ ¸å¿ƒä»£ç ï¼šçŸ¥è¯†æ£€ç´¢ä¼˜åŒ–

#### é‡Œç¨‹ç¢‘M8
~~~
ğŸ¯ é‡Œç¨‹ç¢‘ï¼šçŸ¥è¯†åº“å¯ç”¨
â”œâ”€â”€ SOPæ–‡æ¡£ 20ä»½ä»¥ä¸Š
â”œâ”€â”€ æ•…éšœæ¡ˆä¾‹ 50æ¡ä»¥ä¸Š
â”œâ”€â”€ RAGæ£€ç´¢å‡†ç¡®ç‡>80%
â””â”€â”€ è¾“å‡ºï¼šå®Œæ•´çŸ¥è¯†åº“
~~~
### ç¬¬9-10ä¸ªæœˆï¼šç•Œé¢å¼€å‘ä¸é›†æˆ
#### ç›®æ ‡
- âœ…Â å®ŒæˆWebäº¤äº’ç•Œé¢
- âœ…Â ç³»ç»Ÿç«¯åˆ°ç«¯é›†æˆ
- âœ…Â åŸºæœ¬åŠŸèƒ½å…¨éƒ¨å¯ç”¨
#### ç¬¬9ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
| å‘¨   | ä»»åŠ¡            | äº§å‡º    | é¢„è®¡å·¥æ—¶ |
| --- | ------------- | ----- | ---- |
| W1  | Streamlitç•Œé¢æ¡†æ¶ | åŸºç¡€ç•Œé¢  | 16h  |
| W1  | å¯¹è¯äº¤äº’é¡µé¢        | èŠå¤©ç•Œé¢  | 12h  |
| W2  | å®æ—¶æ•°æ®å±•ç¤ºé¡µé¢      | æ•°æ®é¡µé¢  | 16h  |
| W2  | æŠ¥è­¦å±•ç¤ºé¡µé¢        | æŠ¥è­¦é¡µé¢  | 12h  |
| W3  | çŸ¥è¯†åº“æŸ¥è¯¢é¡µé¢       | çŸ¥è¯†é¡µé¢  | 12h  |
| W3  | é¡µé¢ç¾åŒ–å’Œäº¤äº’ä¼˜åŒ–     | ä¼˜åŒ–åç•Œé¢ | 12h  |
| W4  | å‰åç«¯è”è°ƒ         | è”è°ƒå®Œæˆ  | 16h  |
| W4  | Bugä¿®å¤         | ä¿®å¤è®°å½•  | 8h   |
#### æ ¸å¿ƒä»£ç ï¼šStreamlitç•Œé¢

#### ç¬¬10ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|ç³»ç»Ÿé›†æˆæµ‹è¯•|æµ‹è¯•æŠ¥å‘Š|16h|
|W1|Bugä¿®å¤å’Œä¼˜åŒ–|ä¿®å¤ä»£ç |16h|
|W2|æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–|æ€§èƒ½æŠ¥å‘Š|12h|
|W2|ç”¨æˆ·ä½“éªŒä¼˜åŒ–|ä¼˜åŒ–åç•Œé¢|12h|
|W3|ä½¿ç”¨æ–‡æ¡£ç¼–å†™|ç”¨æˆ·æ‰‹å†Œ|16h|
|W3|æ¼”ç¤ºPPTå‡†å¤‡|æ¼”ç¤ºææ–™|8h|
|W4|æœ€ç»ˆæµ‹è¯•å’ŒéªŒæ”¶|éªŒæ”¶æŠ¥å‘Š|12h|
|W4|é¡¹ç›®æ€»ç»“|æ€»ç»“æ–‡æ¡£|8h|
#### é‡Œç¨‹ç¢‘M10
~~~
ğŸ¯ é‡Œç¨‹ç¢‘ï¼šæ ·æœºå¯æ¼”ç¤º
â”œâ”€â”€ ç•Œé¢åŠŸèƒ½å®Œæ•´
â”œâ”€â”€ ç«¯åˆ°ç«¯æµç¨‹å¯ç”¨
â”œâ”€â”€ æ ¸å¿ƒåŠŸèƒ½å¯æ¼”ç¤º
â””â”€â”€ è¾“å‡ºï¼šå¯æ¼”ç¤ºæ ·æœº
~~~
### ç¬¬11-12ä¸ªæœˆï¼šä¼˜åŒ–å®Œå–„ä¸äº¤ä»˜
#### ç›®æ ‡
- âœ… ç³»ç»Ÿç¨³å®šæ€§ä¼˜åŒ–
- âœ… åŠŸèƒ½å®Œå–„å’Œä½“éªŒä¼˜åŒ–
- âœ… æ–‡æ¡£å®Œå–„å’Œäº¤ä»˜
#### ç¬¬11ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|Agentå‡†ç¡®æ€§ä¼˜åŒ–|ä¼˜åŒ–åAgent|20h|
|W1|Promptè¿­ä»£ä¼˜åŒ–|ä¼˜åŒ–åPrompt|12h|
|W2|çŸ¥è¯†åº“å†…å®¹æ‰©å……|æ–°å¢çŸ¥è¯†|16h|
|W2|æ£€ç´¢æ•ˆæœä¼˜åŒ–|ä¼˜åŒ–ä»£ç |12h|
|W3|å¼‚å¸¸å¤„ç†å®Œå–„|å¥å£®æ€§æå‡|16h|
|W3|æ—¥å¿—å’Œç›‘æ§å®Œå–„|ç›‘æ§åŠŸèƒ½|12h|
|W4|æ€§èƒ½ä¼˜åŒ–|æ€§èƒ½æå‡|16h|
|W4|ç¨³å®šæ€§æµ‹è¯•|æµ‹è¯•æŠ¥å‘Š|8h|
#### ç¬¬12ä¸ªæœˆè¯¦ç»†ä»»åŠ¡
|å‘¨|ä»»åŠ¡|äº§å‡º|é¢„è®¡å·¥æ—¶|
|---|---|---|---|
|W1|æœ€ç»ˆåŠŸèƒ½æµ‹è¯•|æµ‹è¯•æŠ¥å‘Š|16h|
|W1|ç¼ºé™·ä¿®å¤|ä¿®å¤ä»£ç |12h|
|W2|ç”¨æˆ·æ‰‹å†Œå®Œå–„|å®Œæ•´æ‰‹å†Œ|16h|
|W2|æŠ€æœ¯æ–‡æ¡£å®Œå–„|æŠ€æœ¯æ–‡æ¡£|12h|
|W3|æ¼”ç¤ºå‡†å¤‡å’Œæ’ç»ƒ|æ¼”ç¤ºReady|16h|
|W3|ä»£ç æ•´ç†å’Œæ³¨é‡Š|æ•´æ´ä»£ç |12h|
|W4|é¡¹ç›®éªŒæ”¶æ¼”ç¤º|éªŒæ”¶é€šè¿‡|8h|
|W4|é¡¹ç›®æ€»ç»“å’Œå½’æ¡£|å½’æ¡£æ–‡ä»¶|8h|
#### æœ€ç»ˆäº¤ä»˜ç‰©æ¸…å•
~~~
ğŸ“¦ DCSè¿è¡ŒAgentæ ·æœºäº¤ä»˜ç‰©
â”‚
â”œâ”€â”€ ğŸ’» ç³»ç»Ÿä»£ç 
â”‚   â”œâ”€â”€ /agent          # Agentæ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ /data           # æ•°æ®å±‚ä»£ç 
â”‚   â”œâ”€â”€ /knowledge      # çŸ¥è¯†åº“ä»£ç 
â”‚   â”œâ”€â”€ /ui             # ç•Œé¢ä»£ç 
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ“š çŸ¥è¯†åº“å†…å®¹
â”‚   â”œâ”€â”€ SOPæ–‡æ¡£ (20+ä»½)
â”‚   â”œâ”€â”€ æ•…éšœæ¡ˆä¾‹ (50+æ¡)
â”‚   â””â”€â”€ å‘é‡æ•°æ®åº“æ–‡ä»¶
â”‚
â”œâ”€â”€ ğŸ“Š æµ‹è¯•æ•°æ®
â”‚   â”œâ”€â”€ æ¨¡æ‹Ÿå™¨é…ç½®
â”‚   â””â”€â”€ å†å²æ•°æ®æ ·æœ¬
â”‚
â”œâ”€â”€ ğŸ“– æ–‡æ¡£èµ„æ–™
â”‚   â”œâ”€â”€ ç”¨æˆ·æ“ä½œæ‰‹å†Œ. md
â”‚   â”œâ”€â”€ æŠ€æœ¯è®¾è®¡æ–‡æ¡£.md
â”‚   â”œâ”€â”€ éƒ¨ç½²æŒ‡å—.md
â”‚   â””â”€â”€ APIæ¥å£æ–‡æ¡£. md
â”‚
â”œâ”€â”€ ğŸ¬ æ¼”ç¤ºææ–™
â”‚   â”œâ”€â”€ æ¼”ç¤ºPPT
â”‚   â”œâ”€â”€ æ¼”ç¤ºè„šæœ¬
â”‚   â””â”€â”€ æ¼”ç¤ºè§†é¢‘(å¯é€‰)
â”‚
â””â”€â”€ ğŸ“‹ é¡¹ç›®æ–‡æ¡£
    â”œâ”€â”€ é¡¹ç›®æ€»ç»“æŠ¥å‘Š
    â””â”€â”€ åç»­è§„åˆ’å»ºè®®
~~~
#### é‡Œç¨‹ç¢‘M12
~~~
ğŸ¯ é‡Œç¨‹ç¢‘ï¼šé¡¹ç›®å®Œæˆ
â”œâ”€â”€ æ ·æœºåŠŸèƒ½ç¨³å®šå¯ç”¨
â”œâ”€â”€ æ–‡æ¡£èµ„æ–™å®Œæ•´
â”œâ”€â”€ æ¼”ç¤ºéªŒæ”¶é€šè¿‡
â””â”€â”€ è¾“å‡ºï¼šå®Œæ•´æ ·æœºç³»ç»Ÿ
~~~
## 5.ç²¾ç®€ç‰ˆé¢„ç®—
### ç¡¬ä»¶é¢„ç®—
| é¡¹ç›®          | é…ç½®                    | ä»·æ ¼(ä¸‡å…ƒ) | å¤‡æ³¨          |
| ----------- | --------------------- | ------ | ----------- |
| **å¼€å‘æœº(æ¨è)** | RTX 4090 + 64G + 1TB  | 2. 5   | å¯è¿è¡Œ7B-14Bæ¨¡å‹ |
| **å¼€å‘æœº(æœ€ä½)** | RTX 3090 + 32G + 512G | 1.5    | åŸºæœ¬å¯ç”¨        |
| å¤‡é€‰ï¼šäº‘GPU     | AutoDLæŒ‰éœ€ç§Ÿç”¨            | 0.5/æœˆ  | çµæ´»ä½†æœ‰ç½‘ç»œä¾èµ–    |
### è½¯ä»¶é¢„ç®—
| ç›®    | è´¹ç”¨  | å¤‡æ³¨       |
| ---- | --- | -------- |
| æ‰€æœ‰è½¯ä»¶ | 0   | å…¨éƒ¨ä½¿ç”¨å¼€æºæ–¹æ¡ˆ |
### äººåŠ›é¢„ç®—
|é…ç½®|äººæ•°|æœˆè–ª(ä¸‡)|å‘¨æœŸ|æ€»è®¡|
|---|---|---|---|---|
|1äººé…ç½®|1|3-4|12æœˆ|36-48ä¸‡|
|2äººé…ç½®|2|3-4|12æœˆ|72-96ä¸‡|
### æ€»é¢„ç®—ä¼°ç®—
|æ–¹æ¡ˆ|ç¡¬ä»¶|äººåŠ›|å…¶ä»–|æ€»è®¡|
|---|---|---|---|---|
|**æœ€ä½é…ç½®(1äºº)**|1. 5ä¸‡|36ä¸‡|2ä¸‡|**~40ä¸‡**|
|**æ¨èé…ç½®(1äºº)**|2.5ä¸‡|48ä¸‡|3ä¸‡|**~54ä¸‡**|
|**2äººé…ç½®**|2.5ä¸‡|72-96ä¸‡|5ä¸‡|**~80-100ä¸‡**|
## 6.å·¥ä½œé‡ç»Ÿè®¡
### æœˆåº¦å·¥æ—¶åˆ†å¸ƒ
|æœˆä»½|ä¸»è¦å·¥ä½œ|å·¥æ—¶(h)|ç´¯è®¡(h)|
|---|---|---|---|
|M1-2|ç¯å¢ƒæ­å»ºã€æŠ€æœ¯éªŒè¯|160|160|
|M3-4|æ•°æ®å±‚å¼€å‘|200|360|
|M5-6|Agentæ ¸å¿ƒå¼€å‘|240|600|
|M7-8|çŸ¥è¯†åº“å»ºè®¾|200|800|
|M9-10|ç•Œé¢ä¸é›†æˆ|200|1000|
|M11-12|ä¼˜åŒ–ä¸äº¤ä»˜|200|1200|
### æŒ‰æ¨¡å—å·¥æ—¶åˆ†å¸ƒ
~~~
æ€»å·¥æ—¶: ~1200å°æ—¶ (12ä¸ªæœˆ)

Agentæ ¸å¿ƒå¼€å‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  35%  420h
çŸ¥è¯†åº“å»ºè®¾       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          20%  240h  
æ•°æ®å±‚å¼€å‘       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            17%  200h
ç•Œé¢å¼€å‘         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            17%  200h
æµ‹è¯•ä¸æ–‡æ¡£       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                11%  140h
~~~
## ä¸ƒã€å…³é”®é‡Œç¨‹ç¢‘æ€»ç»“
|æ—¶é—´|é‡Œç¨‹ç¢‘|éªŒæ”¶æ ‡å‡†|
|---|---|---|
|M2|æŠ€æœ¯éªŒè¯å®Œæˆ|LLMå¯è¿è¡Œï¼ŒRAGåŸå‹å¯ç”¨|
|M4|æ•°æ®å±‚å®Œæˆ|æ¨¡æ‹Ÿå™¨è¿è¡Œï¼Œæ•°æ®å¯æŸ¥è¯¢|
|M6|Agentæ ¸å¿ƒå®Œæˆ|50é—®æµ‹è¯•å‡†ç¡®ç‡>70%|
|M8|çŸ¥è¯†åº“å¯ç”¨|20ä»½SOPï¼Œ50æ¡æ¡ˆä¾‹|
|M10|æ ·æœºå¯æ¼”ç¤º|ç«¯åˆ°ç«¯åŠŸèƒ½å¯ç”¨|
|M12|é¡¹ç›®äº¤ä»˜|å®Œæ•´æ ·æœºï¼Œæ–‡æ¡£é½å…¨|
## 8.é£é™©ä¸å»ºè®®
### ä¸»è¦é£é™©
|é£é™©|å½±å“|åº”å¯¹|
|---|---|---|
|æœ¬åœ°LLMæ•ˆæœä¸ä½³|é«˜|å¤šæ¨¡å‹å¯¹æ¯”ï¼ŒæŒç»­ä¼˜åŒ–Prompt|
|å¼€å‘è¿›åº¦å»¶è¿Ÿ|ä¸­|ä¼˜å…ˆæ ¸å¿ƒåŠŸèƒ½ï¼Œé€‚å½“è£å‰ªèŒƒå›´|
|çŸ¥è¯†æ•´ç†å›°éš¾|ä¸­|ä»æœ€æ ¸å¿ƒçš„SOPå’Œæ¡ˆä¾‹å¼€å§‹|
|å•äººå¼€å‘ç“¶é¢ˆ|ä¸­|åˆç†è§„åˆ’ï¼Œé¿å…æŠ€æœ¯å€ºåŠ¡|
### æˆåŠŸå…³é”®å› ç´ 
1. **èšç„¦MVP**ï¼šå…ˆè·‘é€šæ ¸å¿ƒæµç¨‹ï¼Œå†é€æ­¥å®Œå–„
2. **å–„ç”¨ç°æˆå·¥å…·**ï¼šä¸é‡å¤é€ è½®å­ï¼Œæœ€å¤§åŒ–åˆ©ç”¨å¼€æº
3. **æŒç»­è¿­ä»£**ï¼šå°æ­¥å¿«è·‘ï¼Œå¿«é€ŸéªŒè¯ï¼ŒåŠæ—¶è°ƒæ•´
4. **çŸ¥è¯†ç§¯ç´¯**ï¼šçŸ¥è¯†åº“æ˜¯é•¿æœŸä»·å€¼ï¼ŒæŒç»­æŠ•å…¥